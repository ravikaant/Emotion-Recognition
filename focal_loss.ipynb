{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"focal_loss.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"2eWlqu5oOGR5","colab_type":"code","outputId":"455b926d-ad2c-45f8-e3d6-6bbb2c9a3e41","executionInfo":{"status":"ok","timestamp":1555309440026,"user_tz":-330,"elapsed":1262,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"YOwUmTTgOKK-","colab_type":"code","outputId":"126ae96c-af11-41ab-e048-3444c35b099f","executionInfo":{"status":"ok","timestamp":1555309443211,"user_tz":-330,"elapsed":1170,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["cd /content/drive/My Drive/Emotion Recogition/code/python_files"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Emotion Recogition/code/python_files\n"],"name":"stdout"}]},{"metadata":{"id":"pO4SIxQTOKIF","colab_type":"code","outputId":"490e5167-8788-40d3-a41f-f1800e1ee998","executionInfo":{"status":"ok","timestamp":1555309447670,"user_tz":-330,"elapsed":2684,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import numpy as np\n","import os\n","import sys\n","import pandas as pd\n","\n","import wave\n","from keras.callbacks import EarlyStopping\n","from sklearn.utils import class_weight\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","import keras\n","from keras.models import Sequential, Model\n","from keras.layers.core import Dense, Activation\n","from keras.layers import LSTM, Input, Flatten,Dropout,GlobalAveragePooling2D,MaxPooling2D\n","from keras.layers.convolutional import Conv2D\n","from keras.models import load_model\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing import sequence\n","from scipy import signal\n","import matplotlib.pyplot as plot\n","from sklearn.preprocessing import LabelEncoder\n","from keras import backend as K"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"6Ju8pMtS15__","colab_type":"code","colab":{}},"cell_type":"code","source":["from helper import *"],"execution_count":0,"outputs":[]},{"metadata":{"id":"koWvKufzOKE_","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","code_path = os.path.dirname(os.path.realpath(os.getcwd()))\n","emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n","data_path = code_path + \"/../data/sessions/\"\n","sessions = ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']\n","framerate = 16000"],"execution_count":0,"outputs":[]},{"metadata":{"id":"G7Nr_oXDOKDa","colab_type":"code","colab":{}},"cell_type":"code","source":["import pickle\n","with open(code_path + '/../data/'+'data_collected.pickle', 'rb') as handle:\n","    data2 = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7mA-h41QwT5h","colab_type":"code","outputId":"53ba1139-9752-414c-ca55-da52ac21b647","executionInfo":{"status":"ok","timestamp":1555309467533,"user_tz":-330,"elapsed":5008,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["!pip install python_speech_features  "],"execution_count":7,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: python_speech_features in /usr/local/lib/python3.6/dist-packages (0.6)\n"],"name":"stdout"}]},{"metadata":{"id":"0jdasYlywWgI","colab_type":"code","colab":{}},"cell_type":"code","source":["from python_speech_features import mfcc\n","from python_speech_features import logfbank\n","from python_speech_features import fbank\n","import scipy.io.wavfile as wav\n","from sklearn.preprocessing import scale"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FIArExDvwjMw","colab_type":"code","outputId":"e97afcfc-a98f-4569-9a67-749884ab9e71","executionInfo":{"status":"ok","timestamp":1555309642754,"user_tz":-330,"elapsed":45097,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"cell_type":"code","source":["X_train = []\n","X_test = []\n","Y_train = []\n","Y_test = []\n","fs = 16e3\n","counter = 0\n","counter1 = 0\n","for ses_mod in data2:\n","    if 'impro' in ses_mod['id'] and ses_mod['emotion'] in emotions_used:\n","        fbank_feat = logfbank(ses_mod['signal'],nfilt=40)\n","        Sxx = np.transpose(fbank_feat)\n","        Sxx = pad_sequence_into_array( Sxx,maxlen=300,value=0)\n","        Sxx = scale(Sxx)\n","       \n","        \n","        if ses_mod['id'][:5]==\"Ses05\":\n","            counter+=1\n","            X_test.append(Sxx)\n","            Y_test.append(ses_mod['emotion'])\n","        else:\n","            counter1+=1\n","            X_train.append(Sxx)\n","            Y_train.append(ses_mod['emotion'])\n","        \n","print(counter)\n","print(counter1)\n","\n","X_test = np.array(X_test)\n","X_train = np.array(X_train)\n","print(X_train.shape)\n","print(X_test.shape)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["625\n","2034\n","(2034, 40, 300)\n","(625, 40, 300)\n"],"name":"stdout"}]},{"metadata":{"id":"HR1K6NnEQwsG","colab_type":"code","colab":{}},"cell_type":"code","source":["import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"odDNiRMwOKAD","colab_type":"code","outputId":"65936f56-9896-4e01-881d-7d747c0123c1","executionInfo":{"status":"ok","timestamp":1554699600484,"user_tz":-330,"elapsed":17193,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"cell_type":"code","source":["X_train = []\n","X_test = []\n","Y_train = []\n","Y_test = []\n","fs = 16e3\n","counter = 0\n","counter1 = 0\n","for ses_mod in data2:\n","    if 'impro' in ses_mod['id'] and ses_mod['emotion'] in emotions_used:\n","        f, t, Sxx = signal.spectrogram(ses_mod['signal'], fs, nperseg=400,noverlap=200)\n","        Sxx = pad_sequence_into_array(Sxx,maxlen=300,value=0)\n","        \n","        if ses_mod['id'][:5]==\"Ses05\":\n","            counter+=1\n","            X_test.append(Sxx)\n","            Y_test.append(ses_mod['emotion'])\n","        else:\n","            counter1+=1\n","            X_train.append(Sxx)\n","            Y_train.append(ses_mod['emotion'])\n","        \n","print(counter)\n","print(counter1)\n","\n","X_test = np.array(X_test)\n","X_train = np.array(X_train)\n","print(X_train.shape)\n","print(X_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["625\n","2034\n","(2034, 201, 300)\n","(625, 201, 300)\n"],"name":"stdout"}]},{"metadata":{"id":"t7TIAuwjo0k1","colab_type":"code","colab":{}},"cell_type":"code","source":["y  = pd.get_dummies(Y_train+Y_test)\n","y_train = y[0:len(Y_train)]\n","y_test = y[len(Y_train):]\n","y_train = np.array(y_train)\n","y_test = np.array(y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BS1Ej-KVQPqE","colab_type":"code","colab":{}},"cell_type":"code","source":["def categorical_focal_loss(gamma=2., alpha=.25):\n","    \"\"\"\n","    Softmax version of focal loss.\n","           m\n","      FL = âˆ‘  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n","          c=1\n","      where m = number of classes, c = class and o = observation\n","    Parameters:\n","      alpha -- the same as weighing factor in balanced cross entropy\n","      gamma -- focusing parameter for modulating factor (1-p)\n","    Default value:\n","      gamma -- 2.0 as mentioned in the paper\n","      alpha -- 0.25 as mentioned in the paper\n","    References:\n","        Official paper: https://arxiv.org/pdf/1708.02002.pdf\n","        https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n","    Usage:\n","     model.compile(loss=[categorical_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n","    \"\"\"\n","    def categorical_focal_loss_fixed(y_true, y_pred):\n","        \"\"\"\n","        :param y_true: A tensor of the same shape as `y_pred`\n","        :param y_pred: A tensor resulting from a softmax\n","        :return: Output tensor.\n","        \"\"\"\n","\n","        # Scale predictions so that the class probas of each sample sum to 1\n","        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n","\n","        # Clip the prediction value to prevent NaN's and Inf's\n","        epsilon = K.epsilon()\n","        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n","\n","        # Calculate Cross Entropy\n","        cross_entropy = -y_true * K.log(y_pred)\n","\n","        # Calculate Focal Loss\n","        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n","\n","        # Sum the losses in mini_batch\n","        return K.sum(loss, axis=1)\n","\n","    return categorical_focal_loss_fixed"],"execution_count":0,"outputs":[]},{"metadata":{"id":"e9xkh_B_T82m","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = X_train.reshape(-1,40,300,1)\n","X_test = X_test.reshape(-1,40,300,1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pxYMc0_KCzjE","colab_type":"code","colab":{}},"cell_type":"code","source":["def make_model():\n","    in_layer = Input(shape=(40, 300,1))\n","    x = Conv2D(32,(5,5), activation = 'elu')(in_layer)  \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(64,(5,5), activation = 'elu')(x)         \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(64,(5,5), activation = 'elu')(x)         \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(128, (5,5))(x)                           \n","    x = GlobalAveragePooling2D()(x)                     \n","    x = Dense(64,activation='elu')(x)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(4, activation = \"softmax\")(x) # softmax output\n","    model = Model(inputs = in_layer, outputs=output_layer)\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s3nQfyaIC47x","colab_type":"code","outputId":"0eb76835-e40b-4d42-86fc-04916272daba","executionInfo":{"status":"ok","timestamp":1555045792721,"user_tz":-330,"elapsed":1571543,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":7041}},"cell_type":"code","source":["model  =  make_model()\n","model.compile(optimizer = \"adam\", loss = categorical_focal_loss(gamma=.25, alpha=1.),\n","                    metrics=[\"accuracy\"])\n","Y_label = ( [np.where(r==1)[0][0] for r in y_train] )\n","early_stopping_monitor = EarlyStopping( monitor='val_loss',patience=20,verbose=1)\n","m_check = keras.callbacks.ModelCheckpoint(filepath = './lstm_encoder.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1 )\n","hist = model.fit(X_train, y_train, \n","                 batch_size=32, validation_data=(X_test,y_test),nb_epoch=100, verbose=1, shuffle = True,callbacks=[m_check,early_stopping_monitor],class_weight = class_weight.compute_class_weight(\"balanced\", np.unique(Y_label), Y_label))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["Train on 2034 samples, validate on 625 samples\n","Epoch 1/100\n","2034/2034 [==============================] - 23s 12ms/step - loss: 1.1670 - acc: 0.4243 - val_loss: 1.0963 - val_acc: 0.4896\n","\n","Epoch 00001: val_acc improved from -inf to 0.48960, saving model to ./cnn_focalloss.h5\n","Epoch 2/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 1.0155 - acc: 0.4892 - val_loss: 1.0905 - val_acc: 0.4640\n","\n","Epoch 00002: val_acc did not improve from 0.48960\n","Epoch 3/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.9930 - acc: 0.5123 - val_loss: 0.9920 - val_acc: 0.5104\n","\n","Epoch 00003: val_acc improved from 0.48960 to 0.51040, saving model to ./cnn_focalloss.h5\n","Epoch 4/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.9523 - acc: 0.5334 - val_loss: 1.0058 - val_acc: 0.5296\n","\n","Epoch 00004: val_acc improved from 0.51040 to 0.52960, saving model to ./cnn_focalloss.h5\n","Epoch 5/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.9483 - acc: 0.5339 - val_loss: 1.1704 - val_acc: 0.4432\n","\n","Epoch 00005: val_acc did not improve from 0.52960\n","Epoch 6/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.9274 - acc: 0.5472 - val_loss: 0.9454 - val_acc: 0.5424\n","\n","Epoch 00006: val_acc improved from 0.52960 to 0.54240, saving model to ./cnn_focalloss.h5\n","Epoch 7/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.9273 - acc: 0.5531 - val_loss: 1.1458 - val_acc: 0.4560\n","\n","Epoch 00007: val_acc did not improve from 0.54240\n","Epoch 8/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.9315 - acc: 0.5418 - val_loss: 0.9644 - val_acc: 0.5248\n","\n","Epoch 00008: val_acc did not improve from 0.54240\n","Epoch 9/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.9041 - acc: 0.5624 - val_loss: 0.9537 - val_acc: 0.5744\n","\n","Epoch 00009: val_acc improved from 0.54240 to 0.57440, saving model to ./cnn_focalloss.h5\n","Epoch 10/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8893 - acc: 0.5737 - val_loss: 0.9455 - val_acc: 0.5584\n","\n","Epoch 00010: val_acc did not improve from 0.57440\n","Epoch 11/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8818 - acc: 0.5615 - val_loss: 0.9572 - val_acc: 0.5632\n","\n","Epoch 00011: val_acc did not improve from 0.57440\n","Epoch 12/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8727 - acc: 0.5762 - val_loss: 0.9662 - val_acc: 0.5968\n","\n","Epoch 00012: val_acc improved from 0.57440 to 0.59680, saving model to ./cnn_focalloss.h5\n","Epoch 13/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8513 - acc: 0.6018 - val_loss: 0.9718 - val_acc: 0.5760\n","\n","Epoch 00013: val_acc did not improve from 0.59680\n","Epoch 14/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8548 - acc: 0.5914 - val_loss: 1.0601 - val_acc: 0.5168\n","\n","Epoch 00014: val_acc did not improve from 0.59680\n","Epoch 15/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.8542 - acc: 0.5978 - val_loss: 0.9581 - val_acc: 0.5936\n","\n","Epoch 00015: val_acc did not improve from 0.59680\n","Epoch 16/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.8586 - acc: 0.5846 - val_loss: 0.9114 - val_acc: 0.5664\n","\n","Epoch 00016: val_acc did not improve from 0.59680\n","Epoch 17/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.8543 - acc: 0.5801 - val_loss: 1.0067 - val_acc: 0.5552\n","\n","Epoch 00017: val_acc did not improve from 0.59680\n","Epoch 18/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.8411 - acc: 0.5836 - val_loss: 0.8962 - val_acc: 0.6080\n","\n","Epoch 00018: val_acc improved from 0.59680 to 0.60800, saving model to ./cnn_focalloss.h5\n","Epoch 19/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8451 - acc: 0.5924 - val_loss: 0.9803 - val_acc: 0.5696\n","\n","Epoch 00019: val_acc did not improve from 0.60800\n","Epoch 20/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8158 - acc: 0.6091 - val_loss: 0.9713 - val_acc: 0.5920\n","\n","Epoch 00020: val_acc did not improve from 0.60800\n","Epoch 21/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8058 - acc: 0.6121 - val_loss: 0.9265 - val_acc: 0.5728\n","\n","Epoch 00021: val_acc did not improve from 0.60800\n","Epoch 22/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8106 - acc: 0.6096 - val_loss: 1.0004 - val_acc: 0.5568\n","\n","Epoch 00022: val_acc did not improve from 0.60800\n","Epoch 23/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8166 - acc: 0.5978 - val_loss: 0.9562 - val_acc: 0.5776\n","\n","Epoch 00023: val_acc did not improve from 0.60800\n","Epoch 24/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.8176 - acc: 0.6219 - val_loss: 1.0153 - val_acc: 0.5360\n","\n","Epoch 00024: val_acc did not improve from 0.60800\n","Epoch 25/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.8094 - acc: 0.6072 - val_loss: 1.0867 - val_acc: 0.5584\n","\n","Epoch 00025: val_acc did not improve from 0.60800\n","Epoch 26/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8211 - acc: 0.5998 - val_loss: 1.0470 - val_acc: 0.5744\n","\n","Epoch 00026: val_acc did not improve from 0.60800\n","Epoch 27/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8006 - acc: 0.6136 - val_loss: 0.9632 - val_acc: 0.5872\n","\n","Epoch 00027: val_acc did not improve from 0.60800\n","Epoch 28/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.8170 - acc: 0.6209 - val_loss: 0.9733 - val_acc: 0.5552\n","\n","Epoch 00028: val_acc did not improve from 0.60800\n","Epoch 29/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7919 - acc: 0.6224 - val_loss: 0.9885 - val_acc: 0.5840\n","\n","Epoch 00029: val_acc did not improve from 0.60800\n","Epoch 30/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7936 - acc: 0.6175 - val_loss: 0.9039 - val_acc: 0.5984\n","\n","Epoch 00030: val_acc did not improve from 0.60800\n","Epoch 31/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7784 - acc: 0.6318 - val_loss: 0.9226 - val_acc: 0.5920\n","\n","Epoch 00031: val_acc did not improve from 0.60800\n","Epoch 32/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.7661 - acc: 0.6421 - val_loss: 0.9073 - val_acc: 0.5984\n","\n","Epoch 00032: val_acc did not improve from 0.60800\n","Epoch 33/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.7700 - acc: 0.6382 - val_loss: 0.9907 - val_acc: 0.5744\n","\n","Epoch 00033: val_acc did not improve from 0.60800\n","Epoch 34/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7917 - acc: 0.6293 - val_loss: 0.9269 - val_acc: 0.5872\n","\n","Epoch 00034: val_acc did not improve from 0.60800\n","Epoch 35/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7966 - acc: 0.6101 - val_loss: 0.9224 - val_acc: 0.5984\n","\n","Epoch 00035: val_acc did not improve from 0.60800\n","Epoch 36/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7635 - acc: 0.6411 - val_loss: 0.9475 - val_acc: 0.5936\n","\n","Epoch 00036: val_acc did not improve from 0.60800\n","Epoch 37/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7613 - acc: 0.6445 - val_loss: 0.9237 - val_acc: 0.6000\n","\n","Epoch 00037: val_acc did not improve from 0.60800\n","Epoch 38/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7883 - acc: 0.6303 - val_loss: 0.9559 - val_acc: 0.5712\n","\n","Epoch 00038: val_acc did not improve from 0.60800\n","Epoch 39/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.7558 - acc: 0.6396 - val_loss: 0.8998 - val_acc: 0.6096\n","\n","Epoch 00039: val_acc improved from 0.60800 to 0.60960, saving model to ./cnn_focalloss.h5\n","Epoch 40/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7572 - acc: 0.6441 - val_loss: 0.9470 - val_acc: 0.5712\n","\n","Epoch 00040: val_acc did not improve from 0.60960\n","Epoch 41/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7492 - acc: 0.6450 - val_loss: 0.9004 - val_acc: 0.6112\n","\n","Epoch 00041: val_acc improved from 0.60960 to 0.61120, saving model to ./cnn_focalloss.h5\n","Epoch 42/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.7495 - acc: 0.6529 - val_loss: 0.9484 - val_acc: 0.5968\n","\n","Epoch 00042: val_acc did not improve from 0.61120\n","Epoch 43/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.7479 - acc: 0.6485 - val_loss: 0.9988 - val_acc: 0.5728\n","\n","Epoch 00043: val_acc did not improve from 0.61120\n","Epoch 44/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.7548 - acc: 0.6416 - val_loss: 0.9258 - val_acc: 0.6256\n","\n","Epoch 00044: val_acc improved from 0.61120 to 0.62560, saving model to ./cnn_focalloss.h5\n","Epoch 45/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7503 - acc: 0.6436 - val_loss: 0.9338 - val_acc: 0.5968\n","\n","Epoch 00045: val_acc did not improve from 0.62560\n","Epoch 46/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7402 - acc: 0.6441 - val_loss: 0.9190 - val_acc: 0.6176\n","\n","Epoch 00046: val_acc did not improve from 0.62560\n","Epoch 47/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.7374 - acc: 0.6583 - val_loss: 0.8880 - val_acc: 0.6224\n","\n","Epoch 00047: val_acc did not improve from 0.62560\n","Epoch 48/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.7256 - acc: 0.6667 - val_loss: 0.9101 - val_acc: 0.6128\n","\n","Epoch 00048: val_acc did not improve from 0.62560\n","Epoch 49/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7315 - acc: 0.6500 - val_loss: 0.9716 - val_acc: 0.5568\n","\n","Epoch 00049: val_acc did not improve from 0.62560\n","Epoch 50/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7138 - acc: 0.6672 - val_loss: 0.9248 - val_acc: 0.6032\n","\n","Epoch 00050: val_acc did not improve from 0.62560\n","Epoch 51/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7143 - acc: 0.6504 - val_loss: 0.8818 - val_acc: 0.6320\n","\n","Epoch 00051: val_acc improved from 0.62560 to 0.63200, saving model to ./cnn_focalloss.h5\n","Epoch 52/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6960 - acc: 0.6765 - val_loss: 0.9574 - val_acc: 0.5936\n","\n","Epoch 00052: val_acc did not improve from 0.63200\n","Epoch 53/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.7327 - acc: 0.6504 - val_loss: 0.9058 - val_acc: 0.6096\n","\n","Epoch 00053: val_acc did not improve from 0.63200\n","Epoch 54/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.7156 - acc: 0.6632 - val_loss: 1.0191 - val_acc: 0.5792\n","\n","Epoch 00054: val_acc did not improve from 0.63200\n","Epoch 55/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7126 - acc: 0.6647 - val_loss: 1.0066 - val_acc: 0.5776\n","\n","Epoch 00055: val_acc did not improve from 0.63200\n","Epoch 56/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6991 - acc: 0.6681 - val_loss: 0.9057 - val_acc: 0.6144\n","\n","Epoch 00056: val_acc did not improve from 0.63200\n","Epoch 57/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6956 - acc: 0.6780 - val_loss: 1.0603 - val_acc: 0.5456\n","\n","Epoch 00057: val_acc did not improve from 0.63200\n","Epoch 58/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.7162 - acc: 0.6696 - val_loss: 0.9172 - val_acc: 0.6272\n","\n","Epoch 00058: val_acc did not improve from 0.63200\n","Epoch 59/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7239 - acc: 0.6637 - val_loss: 0.9282 - val_acc: 0.6128\n","\n","Epoch 00059: val_acc did not improve from 0.63200\n","Epoch 60/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.7140 - acc: 0.6662 - val_loss: 1.0180 - val_acc: 0.5488\n","\n","Epoch 00060: val_acc did not improve from 0.63200\n","Epoch 61/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6977 - acc: 0.6760 - val_loss: 1.0230 - val_acc: 0.5680\n","\n","Epoch 00061: val_acc did not improve from 0.63200\n","Epoch 62/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.7091 - acc: 0.6667 - val_loss: 0.9355 - val_acc: 0.6064\n","\n","Epoch 00062: val_acc did not improve from 0.63200\n","Epoch 63/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.6993 - acc: 0.6716 - val_loss: 0.9611 - val_acc: 0.6080\n","\n","Epoch 00063: val_acc did not improve from 0.63200\n","Epoch 64/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.6895 - acc: 0.6760 - val_loss: 0.9785 - val_acc: 0.5872\n","\n","Epoch 00064: val_acc did not improve from 0.63200\n","Epoch 65/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.6934 - acc: 0.6691 - val_loss: 1.0134 - val_acc: 0.5664\n","\n","Epoch 00065: val_acc did not improve from 0.63200\n","Epoch 66/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6761 - acc: 0.6745 - val_loss: 0.9018 - val_acc: 0.6176\n","\n","Epoch 00066: val_acc did not improve from 0.63200\n","Epoch 67/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6586 - acc: 0.6971 - val_loss: 0.9866 - val_acc: 0.5952\n","\n","Epoch 00067: val_acc did not improve from 0.63200\n","Epoch 68/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6678 - acc: 0.6962 - val_loss: 0.9515 - val_acc: 0.6368\n","\n","Epoch 00068: val_acc improved from 0.63200 to 0.63680, saving model to ./cnn_focalloss.h5\n","Epoch 69/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6847 - acc: 0.6770 - val_loss: 1.0739 - val_acc: 0.5488\n","\n","Epoch 00069: val_acc did not improve from 0.63680\n","Epoch 70/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6498 - acc: 0.6991 - val_loss: 0.9902 - val_acc: 0.5664\n","\n","Epoch 00070: val_acc did not improve from 0.63680\n","Epoch 71/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.6733 - acc: 0.6922 - val_loss: 0.9261 - val_acc: 0.6400\n","\n","Epoch 00071: val_acc improved from 0.63680 to 0.64000, saving model to ./cnn_focalloss.h5\n","Epoch 72/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.6647 - acc: 0.6888 - val_loss: 1.0356 - val_acc: 0.5616\n","\n","Epoch 00072: val_acc did not improve from 0.64000\n","Epoch 73/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6722 - acc: 0.6883 - val_loss: 0.9505 - val_acc: 0.6048\n","\n","Epoch 00073: val_acc did not improve from 0.64000\n","Epoch 74/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.6712 - acc: 0.6932 - val_loss: 1.1172 - val_acc: 0.5088\n","\n","Epoch 00074: val_acc did not improve from 0.64000\n","Epoch 75/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6533 - acc: 0.6976 - val_loss: 1.0335 - val_acc: 0.5504\n","\n","Epoch 00075: val_acc did not improve from 0.64000\n","Epoch 76/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.6498 - acc: 0.7070 - val_loss: 0.9719 - val_acc: 0.5904\n","\n","Epoch 00076: val_acc did not improve from 0.64000\n","Epoch 77/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6541 - acc: 0.6888 - val_loss: 1.0219 - val_acc: 0.5632\n","\n","Epoch 00077: val_acc did not improve from 0.64000\n","Epoch 78/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6417 - acc: 0.7070 - val_loss: 1.1522 - val_acc: 0.5136\n","\n","Epoch 00078: val_acc did not improve from 0.64000\n","Epoch 79/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6216 - acc: 0.7065 - val_loss: 1.0260 - val_acc: 0.5808\n","\n","Epoch 00079: val_acc did not improve from 0.64000\n","Epoch 80/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.6570 - acc: 0.7035 - val_loss: 0.9190 - val_acc: 0.6256\n","\n","Epoch 00080: val_acc did not improve from 0.64000\n","Epoch 81/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.6290 - acc: 0.7030 - val_loss: 0.9543 - val_acc: 0.6064\n","\n","Epoch 00081: val_acc did not improve from 0.64000\n","Epoch 82/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6422 - acc: 0.7040 - val_loss: 1.1065 - val_acc: 0.5552\n","\n","Epoch 00082: val_acc did not improve from 0.64000\n","Epoch 83/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6064 - acc: 0.7173 - val_loss: 0.9918 - val_acc: 0.6000\n","\n","Epoch 00083: val_acc did not improve from 0.64000\n","Epoch 84/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6202 - acc: 0.7119 - val_loss: 0.9763 - val_acc: 0.5872\n","\n","Epoch 00084: val_acc did not improve from 0.64000\n","Epoch 85/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6157 - acc: 0.7173 - val_loss: 1.0378 - val_acc: 0.5808\n","\n","Epoch 00085: val_acc did not improve from 0.64000\n","Epoch 86/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6277 - acc: 0.7065 - val_loss: 0.9650 - val_acc: 0.6128\n","\n","Epoch 00086: val_acc did not improve from 0.64000\n","Epoch 87/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6001 - acc: 0.7237 - val_loss: 1.0838 - val_acc: 0.6064\n","\n","Epoch 00087: val_acc did not improve from 0.64000\n","Epoch 88/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.5829 - acc: 0.7384 - val_loss: 1.1749 - val_acc: 0.5312\n","\n","Epoch 00088: val_acc did not improve from 0.64000\n","Epoch 89/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.5963 - acc: 0.7198 - val_loss: 1.0579 - val_acc: 0.5584\n","\n","Epoch 00089: val_acc did not improve from 0.64000\n","Epoch 90/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6074 - acc: 0.7212 - val_loss: 0.9667 - val_acc: 0.6064\n","\n","Epoch 00090: val_acc did not improve from 0.64000\n","Epoch 91/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6197 - acc: 0.7114 - val_loss: 1.0680 - val_acc: 0.6160\n","\n","Epoch 00091: val_acc did not improve from 0.64000\n","Epoch 92/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.5914 - acc: 0.7286 - val_loss: 0.9492 - val_acc: 0.6208\n","\n","Epoch 00092: val_acc did not improve from 0.64000\n","Epoch 93/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.6106 - acc: 0.7276 - val_loss: 1.1145 - val_acc: 0.5344\n","\n","Epoch 00093: val_acc did not improve from 0.64000\n","Epoch 94/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.5934 - acc: 0.7193 - val_loss: 1.0553 - val_acc: 0.5504\n","\n","Epoch 00094: val_acc did not improve from 0.64000\n","Epoch 95/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.5775 - acc: 0.7404 - val_loss: 1.0388 - val_acc: 0.5568\n","\n","Epoch 00095: val_acc did not improve from 0.64000\n","Epoch 96/100\n","2034/2034 [==============================] - 16s 8ms/step - loss: 0.5877 - acc: 0.7281 - val_loss: 1.0632 - val_acc: 0.6112\n","\n","Epoch 00096: val_acc did not improve from 0.64000\n","Epoch 97/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.5742 - acc: 0.7301 - val_loss: 1.0181 - val_acc: 0.6160\n","\n","Epoch 00097: val_acc did not improve from 0.64000\n","Epoch 98/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.5607 - acc: 0.7409 - val_loss: 1.1184 - val_acc: 0.5584\n","\n","Epoch 00098: val_acc did not improve from 0.64000\n","Epoch 99/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.5638 - acc: 0.7409 - val_loss: 1.1043 - val_acc: 0.5584\n","\n","Epoch 00099: val_acc did not improve from 0.64000\n","Epoch 100/100\n","2034/2034 [==============================] - 15s 8ms/step - loss: 0.5575 - acc: 0.7424 - val_loss: 1.1423 - val_acc: 0.5712\n","\n","Epoch 00100: val_acc did not improve from 0.64000\n"],"name":"stdout"}]},{"metadata":{"id":"lmWZ64kM-dPb","colab_type":"code","colab":{}},"cell_type":"code","source":["model.save_weights('focalweight_complete.h5')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hcZ7ogP3IfGW","colab_type":"code","colab":{}},"cell_type":"code","source":["y_pred = model.predict(X_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mirRTczsIumt","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import classification_report, accuracy_score"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vhhA0cZuI22l","colab_type":"code","colab":{}},"cell_type":"code","source":["for i in range(len(y_pred)):\n","  for j in range(len(y_pred[i])) :\n","    if y_pred[i][j]==max(y_pred[i]) :\n","      y_pred[i][j] = 1\n","    else:\n","      y_pred[i][j]=0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"P52ZBRluI-sJ","colab_type":"code","outputId":"f953112c-752b-4ed4-be38-4e9be615ec20","executionInfo":{"status":"ok","timestamp":1555048990537,"user_tz":-330,"elapsed":1774,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"cell_type":"code","source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.09      0.23      0.13        31\n","           1       0.65      0.42      0.51       174\n","           2       0.62      0.72      0.67       287\n","           3       0.71      0.53      0.61       133\n","\n","   micro avg       0.57      0.57      0.57       625\n","   macro avg       0.52      0.47      0.48       625\n","weighted avg       0.62      0.57      0.58       625\n"," samples avg       0.57      0.57      0.57       625\n","\n"],"name":"stdout"}]},{"metadata":{"id":"98JoRejkHx4y","colab_type":"code","outputId":"96a9dc82-feb0-4c60-c907-aea4aea8d9f2","executionInfo":{"status":"error","timestamp":1555048731212,"user_tz":-330,"elapsed":1704,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":901}},"cell_type":"code","source":["best_model = load_model('./cnn_focalloss.h5')"],"execution_count":0,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-fcfc70112ef6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./cnn_focalloss.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    310\u001b[0m                       \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                       \u001b[0mloss_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                       sample_weight_mode=sample_weight_mode)\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;31m# Set optimizer weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss_function\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_functions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0midentifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/losses.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(name, custom_objects)\u001b[0m\n\u001b[1;32m    112\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                                     printable_module_name='loss function')\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 165\u001b[0;31m                                  ':' + function_name)\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unknown loss function:categorical_focal_loss_fixed"]}]},{"metadata":{"id":"-zsY8S21VNr3","colab_type":"code","colab":{}},"cell_type":"code","source":["y_pred = best_model.predict(X_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0G6lOstrVd8V","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.metrics import classification_report, accuracy_score"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UTeRPFirWRB1","colab_type":"code","colab":{}},"cell_type":"code","source":["for i in range(len(y_pred)):\n","  for j in range(len(y_pred[i])) :\n","    if y_pred[i][j]==max(y_pred[i]) :\n","      y_pred[i][j] = 1\n","    else:\n","      y_pred[i][j]=0"],"execution_count":0,"outputs":[]},{"metadata":{"id":"C01qBWAkW4T8","colab_type":"code","outputId":"a2ec257e-82bb-422b-c658-b458ee22747f","executionInfo":{"status":"ok","timestamp":1553971869158,"user_tz":-330,"elapsed":3362,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"cell_type":"code","source":["print(y_pred)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0. 0. 1. 0.]\n"," [1. 0. 0. 0.]\n"," [1. 0. 0. 0.]\n"," ...\n"," [0. 0. 1. 0.]\n"," [0. 0. 1. 0.]\n"," [0. 1. 0. 0.]]\n"],"name":"stdout"}]},{"metadata":{"id":"gpLk_uYlV_Su","colab_type":"code","outputId":"57b72d92-9306-42ee-c41f-299b6178eb9b","executionInfo":{"status":"ok","timestamp":1551810757359,"user_tz":-330,"elapsed":1276,"user":{"displayName":"Rahul Kumar","photoUrl":"","userId":"17651844698397356196"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"cell_type":"code","source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.34      0.45      0.39        31\n","           1       0.65      0.48      0.55       174\n","           2       0.65      0.78      0.71       287\n","           3       0.77      0.64      0.70       133\n","\n","   micro avg       0.65      0.65      0.65       625\n","   macro avg       0.60      0.59      0.59       625\n","weighted avg       0.66      0.65      0.65       625\n"," samples avg       0.65      0.65      0.65       625\n","\n"],"name":"stdout"}]},{"metadata":{"id":"B-Opj0t0Y2Z8","colab_type":"code","outputId":"f2224932-b379-4f36-d394-54f57bb24038","executionInfo":{"status":"ok","timestamp":1551811276766,"user_tz":-330,"elapsed":2300,"user":{"displayName":"Rahul Kumar","photoUrl":"","userId":"17651844698397356196"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["accuracy_score(y_pred, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6512"]},"metadata":{"tags":[]},"execution_count":75}]},{"metadata":{"id":"PuWMXIPOA8OB","colab_type":"code","colab":{}},"cell_type":"code","source":["import theano.tensor as T\n","import theano\n","import numpy as np\n","from theano.compile.ops import as_op\n","\n","\n","@as_op(itypes=[theano.tensor.ivector],\n","       otypes=[theano.tensor.ivector])\n","def numpy_unique(a):\n","    return np.unique(a)\n","\n","\n","def lda_loss(n_components, margin):\n","    \"\"\"\n","    The main loss function (inner_lda_objective) is wrapped in this function due to\n","    the constraints imposed by Keras on objective functions\n","    \"\"\"\n","    def inner_lda_objective(y_true, y_pred):\n","        \"\"\"\n","        It is the loss function of LDA as introduced in the original paper. \n","        It is adopted from the the original implementation in the following link:\n","        https://github.com/CPJKU/deep_lda\n","        Note: it is implemented by Theano tensor operations, and does not work on Tensorflow backend\n","        \"\"\"\n","        r = 1e-4\n","\n","        # init groups\n","        yt = T.cast(y_true.flatten(), \"int32\")\n","        groups = numpy_unique(yt)\n","\n","        def compute_cov(group, Xt, yt):\n","            Xgt = Xt[T.eq(yt, group).nonzero()[0], :]\n","            Xgt_bar = Xgt - T.mean(Xgt, axis=0)\n","            m = T.cast(Xgt_bar.shape[0], 'float32')\n","            return (1.0 / (m - 1)) * T.dot(Xgt_bar.T, Xgt_bar)\n","\n","        # scan over groups\n","        covs_t, updates = theano.scan(fn=compute_cov, outputs_info=None,\n","                                      sequences=[groups], non_sequences=[y_pred, yt])\n","\n","        # compute average covariance matrix (within scatter)\n","        Sw_t = T.mean(covs_t, axis=0)\n","\n","        # compute total scatter\n","        Xt_bar = y_pred - T.mean(y_pred, axis=0)\n","        m = T.cast(Xt_bar.shape[0], 'float32')\n","        St_t = (1.0 / (m - 1)) * T.dot(Xt_bar.T, Xt_bar)\n","\n","        # compute between scatter\n","        Sb_t = St_t - Sw_t\n","\n","        # cope for numerical instability (regularize)\n","        Sw_t += T.identity_like(Sw_t) * r\n","\n","        # return T.cast(T.neq(yt[0], -1), 'float32')*T.nlinalg.trace(T.dot(T.nlinalg.matrix_inverse(St_t), Sb_t))\n","\n","        # compute eigenvalues\n","        evals_t = T.slinalg.eigvalsh(Sb_t, Sw_t)\n","\n","        # get eigenvalues\n","        top_k_evals = evals_t[-n_components:]\n","\n","        # maximize variance between classes\n","        # (k smallest eigenvalues below threshold)\n","        thresh = T.min(top_k_evals) + margin\n","        top_k_evals = top_k_evals[(top_k_evals <= thresh).nonzero()]\n","        costs = T.mean(top_k_evals)\n","\n","        return -costs\n","\n","    return inner_lda_objective"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0QKGss5gA6Xe","colab_type":"code","outputId":"be87911f-182f-4cfb-acff-3d22a05f37f1","executionInfo":{"status":"error","timestamp":1554665177422,"user_tz":-330,"elapsed":3565,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":739}},"cell_type":"code","source":["model  =  make_model()\n","model.compile(optimizer = \"adam\", loss = lda_loss(3,1),\n","                    metrics=[\"accuracy\"])\n","m_check = keras.callbacks.ModelCheckpoint(filepath = './cnn_spectrogram1.h5', monitor='val_acc', save_best_only=True, mode='max', verbose=1 )\n","hist = model.fit(X_train, y_train, \n","                 batch_size=32, validation_data=(X_test,y_test),nb_epoch=100, verbose=1, shuffle = True,callbacks=[m_check] \n","                )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-8c51a61aee59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m  \u001b[0;34m=\u001b[0m  \u001b[0mmake_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.compile(optimizer = \"adam\", loss = lda_loss(3,1),\n\u001b[0;32m----> 3\u001b[0;31m                     metrics=[\"accuracy\"])\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mm_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./cnn_spectrogram1.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m hist = model.fit(X_train, y_train, \n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 342\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-ed74a6957c7c>\u001b[0m in \u001b[0;36minner_lda_objective\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# init groups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"int32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'flatten'"]}]},{"metadata":{"id":"O3Z_WK5cpa4U","colab_type":"code","colab":{}},"cell_type":"code","source":["model = best_model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"28-3z24RVNpP","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.models import Model\n","\n","layer_name = 'global_average_pooling2d_7'\n","intermediate_layer_model = Model(inputs=model.input,\n","                                 outputs=model.get_layer(layer_name).output)\n","output_train = intermediate_layer_model.predict(X_train)\n","output_test =  intermediate_layer_model.predict(X_test)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NodYNJTAxLRZ","colab_type":"code","outputId":"4762fde6-f00c-4e9e-fdcc-641c886f91d2","executionInfo":{"status":"ok","timestamp":1553970000087,"user_tz":-330,"elapsed":2540,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"cell_type":"code","source":["print(output_train.shape)\n","print(output_test.shape)\n","print(y_train.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2034, 128)\n","(625, 128)\n","(2034, 4)\n"],"name":"stdout"}]},{"metadata":{"id":"DzOkgq8I1P8N","colab_type":"code","colab":{}},"cell_type":"code","source":["labelencoder = LabelEncoder()\n","y_train = labelencoder.fit_transform(Y_train)\n","y_test = labelencoder.transform(Y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OxPjVLNM__lz","colab_type":"code","outputId":"9e2d4d70-e227-4fe0-f4cd-35426afa7cdc","executionInfo":{"status":"ok","timestamp":1554039973019,"user_tz":-330,"elapsed":1192,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["y_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034,)"]},"metadata":{"tags":[]},"execution_count":10}]},{"metadata":{"id":"qHv3MDCAykqP","colab_type":"code","colab":{}},"cell_type":"code","source":["from xgboost import XGBClassifier\n","from xgboost import plot_importance\n","from sklearn.feature_selection import SelectFromModel\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ssplSzhgy3-I","colab_type":"code","colab":{}},"cell_type":"code","source":["xg_model = XGBClassifier(n_estimators=100,learning_rate=0.2,max_depth=7,objective = 'multi:softmax',\n","                       num_class=4,n_jobs=-1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"feeWa5sHzmRD","colab_type":"code","outputId":"331ba57f-1393-4f8c-f1fe-2ed3e3f6f024","executionInfo":{"status":"ok","timestamp":1554041257936,"user_tz":-330,"elapsed":10283,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"cell_type":"code","source":["xg_model.fit(output_train,y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","       colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n","       max_depth=7, min_child_weight=1, missing=None, n_estimators=100,\n","       n_jobs=-1, nthread=None, num_class=4, objective='multi:softprob',\n","       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n","       seed=None, silent=True, subsample=1)"]},"metadata":{"tags":[]},"execution_count":42}]},{"metadata":{"id":"26Ly1lhWCiRt","colab_type":"code","colab":{}},"cell_type":"code","source":["plot_importance(xg_model)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sZXfX2BHDGa2","colab_type":"code","colab":{}},"cell_type":"code","source":["thresholds = np.sort(xg_model.feature_importances_)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7HTrtqHQDMuf","colab_type":"code","colab":{}},"cell_type":"code","source":["# select features using threshold\n","selection = SelectFromModel(xg_model, threshold=0.005, prefit=True)\n","X_train = selection.transform(output_train)\n","X_test = selection.transform(output_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6vowSx-kEGoU","colab_type":"code","colab":{}},"cell_type":"code","source":["xg_model1 = XGBClassifier(n_estimators=100,learning_rate=0.2,max_depth=7,objective = 'multi:softmax',\n","                       num_class=4,n_jobs=-1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Uyt9tRRfENRV","colab_type":"code","outputId":"ea021eba-a78a-4612-bb19-ccab04877b3f","executionInfo":{"status":"ok","timestamp":1554041319404,"user_tz":-330,"elapsed":8136,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"cell_type":"code","source":["xg_model1.fit(X_train,y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","       colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n","       max_depth=7, min_child_weight=1, missing=None, n_estimators=100,\n","       n_jobs=-1, nthread=None, num_class=4, objective='multi:softprob',\n","       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n","       seed=None, silent=True, subsample=1)"]},"metadata":{"tags":[]},"execution_count":48}]},{"metadata":{"id":"vllJ4a_dEV6I","colab_type":"code","colab":{}},"cell_type":"code","source":["y_pred = xg_model1.predict(X_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"csjndJ7lEmzA","colab_type":"code","outputId":"6e0d17eb-92f3-4bc4-af0b-f9fc89ba5fb5","executionInfo":{"status":"ok","timestamp":1554041292290,"user_tz":-330,"elapsed":1351,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["X_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034, 114)"]},"metadata":{"tags":[]},"execution_count":46}]},{"metadata":{"id":"KeORDK-0EgWD","colab_type":"code","outputId":"98f7b1b1-db64-4add-f220-2b44f6d3be84","executionInfo":{"status":"ok","timestamp":1554041331067,"user_tz":-330,"elapsed":1102,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"cell_type":"code","source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.20      0.26      0.22        31\n","           1       0.64      0.44      0.52       174\n","           2       0.63      0.69      0.66       287\n","           3       0.64      0.71      0.67       133\n","\n","   micro avg       0.60      0.60      0.60       625\n","   macro avg       0.53      0.52      0.52       625\n","weighted avg       0.61      0.60      0.60       625\n","\n"],"name":"stdout"}]},{"metadata":{"id":"Bw34TJnSy3yW","colab_type":"code","colab":{}},"cell_type":"code","source":["y_pred = xg_model.predict(output_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-n5JEZxR4OcE","colab_type":"code","outputId":"119415b4-4b54-4bd1-a414-ca6ea5828367","executionInfo":{"status":"ok","timestamp":1553972240881,"user_tz":-330,"elapsed":1930,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"cell_type":"code","source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.23      0.29      0.26        31\n","           1       0.62      0.44      0.51       174\n","           2       0.63      0.68      0.65       287\n","           3       0.63      0.72      0.67       133\n","\n","   micro avg       0.60      0.60      0.60       625\n","   macro avg       0.53      0.53      0.52       625\n","weighted avg       0.61      0.60      0.60       625\n","\n"],"name":"stdout"}]},{"metadata":{"id":"SRaIvOWzAjTo","colab_type":"code","colab":{}},"cell_type":"code","source":["# Fitting Random Forest Classification to the Training set\n","from sklearn.ensemble import RandomForestClassifier\n","classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0,n_jobs=-1)\n","#classifier.fit(output_train, y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Mm32c--oBRJH","colab_type":"code","colab":{}},"cell_type":"code","source":["y_pred = classifier.predict(output_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"nGeLqCwJBoZG","colab_type":"code","outputId":"6661c282-dedd-4879-c201-6bece0ef9400","executionInfo":{"status":"ok","timestamp":1554041388593,"user_tz":-330,"elapsed":1859,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"cell_type":"code","source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.24      0.26      0.25        31\n","           1       0.63      0.45      0.52       174\n","           2       0.65      0.72      0.68       287\n","           3       0.67      0.74      0.70       133\n","\n","   micro avg       0.63      0.63      0.63       625\n","   macro avg       0.55      0.54      0.54       625\n","weighted avg       0.63      0.63      0.62       625\n","\n"],"name":"stdout"}]},{"metadata":{"id":"IwmeZ7OBFpL6","colab_type":"code","colab":{}},"cell_type":"code","source":["from mlxtend.evaluate import confusion_matrix\n","m = confusion_matrix(y_target=y_test, \n","                      y_predicted=y_pred, \n","                      binary=False)\n","print(m)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ayCfbRlZFs2R","colab_type":"code","colab":{}},"cell_type":"code","source":["# Applying Grid Search to find the best model and the best parameters\n","from sklearn.model_selection import GridSearchCV\n","parameters = {'bootstrap': [True, False],\n"," 'max_depth': [10, 20, 40,None],\n"," 'max_features': ['auto', 'sqrt'],\n"," 'n_estimators': [80,100,150,400]}\n","grid_search = GridSearchCV(estimator = classifier,\n","                           param_grid = parameters,\n","                           scoring = 'accuracy',\n","                           cv = 10,\n","                           n_jobs = -1)\n","grid_search = grid_search.fit(output_train, y_train)\n","best_accuracy = grid_search.best_score_\n","best_parameters = grid_search.best_params_\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DXVhzY8lk8Ou","colab_type":"code","outputId":"774077f5-8206-438a-a561-0b4b5af9dd4f","executionInfo":{"status":"ok","timestamp":1554222011254,"user_tz":-330,"elapsed":771381,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"cell_type":"code","source":["best_parameters"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bootstrap': True,\n"," 'max_depth': 20,\n"," 'max_features': 'auto',\n"," 'n_estimators': 80}"]},"metadata":{"tags":[]},"execution_count":25}]},{"metadata":{"id":"vKHc8leSEwLQ","colab_type":"code","outputId":"a2bac56d-6dc1-4012-b46b-09c05974aa5e","executionInfo":{"status":"ok","timestamp":1554225781286,"user_tz":-330,"elapsed":4030,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["best_accuracy"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6647000983284169"]},"metadata":{"tags":[]},"execution_count":26}]},{"metadata":{"id":"SbK_rhZsE4kd","colab_type":"code","outputId":"8d2ffcb7-047c-4580-99c5-0a4fb634fb77","executionInfo":{"status":"ok","timestamp":1554225966955,"user_tz":-330,"elapsed":5148,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"cell_type":"code","source":["classifier = RandomForestClassifier(n_estimators = 80, bootstrap=True,criterion = 'entropy', max_depth=20,max_features='auto',n_jobs=-1)\n","classifier.fit(output_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","            max_depth=20, max_features='auto', max_leaf_nodes=None,\n","            min_impurity_decrease=0.0, min_impurity_split=None,\n","            min_samples_leaf=1, min_samples_split=2,\n","            min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=-1,\n","            oob_score=False, random_state=None, verbose=0,\n","            warm_start=False)"]},"metadata":{"tags":[]},"execution_count":29}]},{"metadata":{"id":"wsc67rvAFUwb","colab_type":"code","colab":{}},"cell_type":"code","source":["y_pred = classifier.predict(output_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZYToa7mBFoK_","colab_type":"code","outputId":"56eb6c74-06b3-4ceb-ce5c-fc070f15ae07","executionInfo":{"status":"ok","timestamp":1554226034384,"user_tz":-330,"elapsed":4051,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"cell_type":"code","source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.24      0.26      0.25        31\n","           1       0.64      0.43      0.51       174\n","           2       0.64      0.73      0.68       287\n","           3       0.66      0.73      0.70       133\n","\n","   micro avg       0.62      0.62      0.62       625\n","   macro avg       0.55      0.54      0.53       625\n","weighted avg       0.62      0.62      0.62       625\n","\n"],"name":"stdout"}]},{"metadata":{"id":"WDvOGt6AHUph","colab_type":"code","colab":{}},"cell_type":"code","source":["# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train_scaled = sc.fit_transform(output_train)\n","X_test_scaled = sc.transform(output_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rV4NuPziIKUq","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn.svm import SVC\n","classifier = SVC(kernel = 'rbf', random_state = 0)\n","#classifier.fit(X_train_scaled, y_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T6H-Ld7BIdpl","colab_type":"code","colab":{}},"cell_type":"code","source":["y_pred = classifier.predict(X_test_scaled)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jNWu9thcIqi3","colab_type":"code","outputId":"fd2241bb-5502-4261-d2cc-3c8050063b36","executionInfo":{"status":"ok","timestamp":1554226826594,"user_tz":-330,"elapsed":5021,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"cell_type":"code","source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.30      0.23      0.26        31\n","           1       0.65      0.41      0.50       174\n","           2       0.62      0.76      0.69       287\n","           3       0.67      0.72      0.70       133\n","\n","   micro avg       0.63      0.63      0.63       625\n","   macro avg       0.56      0.53      0.54       625\n","weighted avg       0.62      0.63      0.61       625\n","\n"],"name":"stdout"}]},{"metadata":{"id":"kRHYjop8JHhX","colab_type":"code","outputId":"fa0eddb7-5279-486e-e15c-c9ff2b72f901","executionInfo":{"status":"ok","timestamp":1554230827690,"user_tz":-330,"elapsed":3883285,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"cell_type":"code","source":["# Applying Grid Search to find the best model and the best parameters\n","from sklearn.model_selection import GridSearchCV\n","parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n","              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n","grid_search = GridSearchCV(estimator = classifier,\n","                           param_grid = parameters,\n","                           scoring = 'accuracy',\n","                           cv = 10,\n","                           n_jobs = -1)\n","grid_search = grid_search.fit(X_train_scaled, y_train)\n","best_accuracy = grid_search.best_score_\n","best_parameters = grid_search.best_params_"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n","  DeprecationWarning)\n"],"name":"stderr"}]},{"metadata":{"id":"k1GB7NM6ZuJW","colab_type":"code","outputId":"5912bb8e-b8cb-442d-b5ef-d28e58dd1862","executionInfo":{"status":"ok","timestamp":1554231272008,"user_tz":-330,"elapsed":3481,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["best_parameters"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'C': 1, 'kernel': 'linear'}"]},"metadata":{"tags":[]},"execution_count":47}]},{"metadata":{"id":"M4Jq3n-mZXgy","colab_type":"code","outputId":"76307d9d-6391-44cb-8889-ec241fcbe316","executionInfo":{"status":"ok","timestamp":1554231282577,"user_tz":-330,"elapsed":2885,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"cell_type":"code","source":["from sklearn.svm import SVC\n","classifier = SVC(kernel = 'linear', C=1)\n","classifier.fit(X_train_scaled, y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n","  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n","  kernel='linear', max_iter=-1, probability=False, random_state=None,\n","  shrinking=True, tol=0.001, verbose=False)"]},"metadata":{"tags":[]},"execution_count":48}]},{"metadata":{"id":"fAqmsFXFZ14a","colab_type":"code","colab":{}},"cell_type":"code","source":["y_pred = classifier.predict(X_test_scaled)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"np3Bhx0oZ88r","colab_type":"code","outputId":"04bbf180-82a5-4148-ae96-07978ceefebe","executionInfo":{"status":"ok","timestamp":1554231321543,"user_tz":-330,"elapsed":2156,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"cell_type":"code","source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.38      0.42      0.40        31\n","           1       0.74      0.36      0.49       174\n","           2       0.61      0.78      0.69       287\n","           3       0.65      0.70      0.67       133\n","\n","   micro avg       0.63      0.63      0.63       625\n","   macro avg       0.60      0.56      0.56       625\n","weighted avg       0.65      0.63      0.61       625\n","\n"],"name":"stdout"}]},{"metadata":{"id":"Bwin4oJnUqdX","colab_type":"code","outputId":"1fac52d4-484a-4f63-e416-313d89ceaeb2","executionInfo":{"status":"error","timestamp":1554179621074,"user_tz":-330,"elapsed":2061,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"cell_type":"code","source":["import pickle\n","with open(filename, â€˜wbâ€™) as f:\n","    pickle.dump(y_train, f)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-e60395f05fb9>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    with open(filename, â€˜wbâ€™) as f:\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"]}]}]}