{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"male_female.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"kIgKrGt8NuD8","colab_type":"code","outputId":"24796f00-f5f4-454e-e148-ee38a09fb904","executionInfo":{"status":"ok","timestamp":1556081911223,"user_tz":-330,"elapsed":27117,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"metadata":{"id":"Jf9aAELjPs8B","colab_type":"code","outputId":"698f0886-f77d-444c-86ac-6411df635456","executionInfo":{"status":"ok","timestamp":1556081923052,"user_tz":-330,"elapsed":1489,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["cd /content/drive/My Drive/Emotion Recogition/code/python_files"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Emotion Recogition/code/python_files\n"],"name":"stdout"}]},{"metadata":{"id":"sq6QPZe4Ps5I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"45bee771-443f-4290-d4be-b450ca67f3f0","executionInfo":{"status":"ok","timestamp":1556081928828,"user_tz":-330,"elapsed":3892,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}}},"cell_type":"code","source":["import numpy as np\n","import os\n","import sys\n","import pandas as pd\n","\n","import wave\n","\n","import keras\n","from keras.models import Sequential, Model\n","from keras.layers.core import Dense, Activation\n","from keras.layers import LSTM, Input, Flatten,Dropout,GlobalAveragePooling2D,MaxPooling2D\n","from keras.layers.convolutional import Conv2D\n","from keras.models import load_model\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing import sequence\n","from scipy import signal\n","import matplotlib.pyplot as plot\n","from helper import *\n","from sklearn.preprocessing import LabelEncoder\n","from keras import backend as K\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"HiqeYBbnPs2e","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","code_path = os.path.dirname(os.path.realpath(os.getcwd()))\n","emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n","data_path = code_path + \"/../data/sessions/\"\n","sessions = ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']\n","framerate = 16000"],"execution_count":0,"outputs":[]},{"metadata":{"id":"85YCM0lGPsvQ","colab_type":"code","colab":{}},"cell_type":"code","source":["import pickle\n","with open(code_path + '/../data/'+'data_collected.pickle', 'rb') as handle:\n","    data2 = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"mKEvEzLkP5p9","colab_type":"code","outputId":"e6614e74-fbe1-4977-876b-a9701c1803f5","executionInfo":{"status":"ok","timestamp":1556042918812,"user_tz":-330,"elapsed":13192,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"cell_type":"code","source":["X_train = []\n","X_test = []\n","Y_train = []\n","Y_test = []\n","fs = 16e3\n","counter = 0\n","counter1 = 0\n","for ses_mod in data2:\n","    if 'impro' in ses_mod['id'] and ses_mod['emotion'] in emotions_used:\n","        f, t, Sxx = signal.spectrogram(ses_mod['signal'], fs, nperseg=400,noverlap=200)\n","        Sxx = pad_sequence_into_array(Sxx,maxlen=300,value=0)\n","        \n","        if ses_mod['id'][:5]==\"Ses05\":\n","            counter+=1\n","            X_test.append(Sxx)\n","            Y_test.append(ses_mod['id'][-4])\n","        else:\n","            counter1+=1\n","            X_train.append(Sxx)\n","            Y_train.append(ses_mod['id'][-4])\n","        \n","print(counter)\n","print(counter1)\n","\n","X_test = np.array(X_test)\n","X_train = np.array(X_train)\n","print(X_train.shape)\n","print(X_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["625\n","2034\n","(2034, 201, 300)\n","(625, 201, 300)\n"],"name":"stdout"}]},{"metadata":{"id":"6JCDcGjOTV2t","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = X_train.reshape(-1,201,300,1)\n","X_test = X_test.reshape(-1,201,300,1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kj_scHXqTkqY","colab_type":"code","colab":{}},"cell_type":"code","source":["from sklearn import preprocessing\n","le = preprocessing.LabelEncoder()\n","y_train=le.fit_transform(Y_train)\n","y_test=le.transform(Y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JkZHRa7FT7ji","colab_type":"code","colab":{}},"cell_type":"code","source":["def make_model():\n","    in_layer = Input(shape=(201, 300,1))\n","    x = Conv2D(32,(5,5), activation = 'elu')(in_layer)  \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(64,(5,5), activation = 'elu')(x)         \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(64,(5,5), activation = 'elu')(x)         \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(128, (5,5))(x)                           \n","    x = GlobalAveragePooling2D()(x)                     \n","    x = Dense(64,activation='elu')(x)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(1, activation = \"sigmoid\")(x) \n","    model = Model(inputs = in_layer, outputs=output_layer)\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Cs9Kiz11UFty","colab_type":"code","outputId":"4f9c33c5-46f3-4f85-b29e-81e4ee50df0c","executionInfo":{"status":"ok","timestamp":1556047810760,"user_tz":-330,"elapsed":858490,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":6787}},"cell_type":"code","source":["model  =  make_model()\n","model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\",\n","                    metrics=[\"accuracy\"])\n","m_check = keras.callbacks.ModelCheckpoint(filepath = './cnn_spectrogram_mf.h5', monitor='val_acc', save_best_only=True, mode='max', verbose=1 )\n","hist = model.fit(X_train, y_train, \n","                 batch_size=32, validation_data=(X_test,y_test),nb_epoch=100, verbose=1, shuffle = True,callbacks=[m_check] \n","                )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["Train on 2034 samples, validate on 625 samples\n","Epoch 1/100\n","2034/2034 [==============================] - 47s 23ms/step - loss: 1.6091 - acc: 0.5000 - val_loss: 0.6660 - val_acc: 0.6208\n","\n","Epoch 00001: val_acc improved from -inf to 0.62080, saving model to ./cnn_spectrogram_mf.h5\n","Epoch 2/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.8218 - acc: 0.5147 - val_loss: 0.6668 - val_acc: 0.5680\n","\n","Epoch 00002: val_acc did not improve from 0.62080\n","Epoch 3/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.7389 - acc: 0.5005 - val_loss: 0.6531 - val_acc: 0.6496\n","\n","Epoch 00003: val_acc improved from 0.62080 to 0.64960, saving model to ./cnn_spectrogram_mf.h5\n","Epoch 4/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.7544 - acc: 0.5221 - val_loss: 0.6941 - val_acc: 0.5104\n","\n","Epoch 00004: val_acc did not improve from 0.64960\n","Epoch 5/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.7118 - acc: 0.5182 - val_loss: 0.6677 - val_acc: 0.6704\n","\n","Epoch 00005: val_acc improved from 0.64960 to 0.67040, saving model to ./cnn_spectrogram_mf.h5\n","Epoch 6/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.7178 - acc: 0.5300 - val_loss: 0.6557 - val_acc: 0.6272\n","\n","Epoch 00006: val_acc did not improve from 0.67040\n","Epoch 7/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.7061 - acc: 0.5541 - val_loss: 0.6523 - val_acc: 0.6112\n","\n","Epoch 00007: val_acc did not improve from 0.67040\n","Epoch 8/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.6970 - acc: 0.5693 - val_loss: 0.6745 - val_acc: 0.5712\n","\n","Epoch 00008: val_acc did not improve from 0.67040\n","Epoch 9/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.7213 - acc: 0.5379 - val_loss: 0.6698 - val_acc: 0.7376\n","\n","Epoch 00009: val_acc improved from 0.67040 to 0.73760, saving model to ./cnn_spectrogram_mf.h5\n","Epoch 10/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.7015 - acc: 0.5649 - val_loss: 0.6050 - val_acc: 0.7072\n","\n","Epoch 00010: val_acc did not improve from 0.73760\n","Epoch 11/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.6683 - acc: 0.5944 - val_loss: 0.5817 - val_acc: 0.7472\n","\n","Epoch 00011: val_acc improved from 0.73760 to 0.74720, saving model to ./cnn_spectrogram_mf.h5\n","Epoch 12/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.6999 - acc: 0.5855 - val_loss: 0.6697 - val_acc: 0.5664\n","\n","Epoch 00012: val_acc did not improve from 0.74720\n","Epoch 13/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.6740 - acc: 0.5880 - val_loss: 0.5844 - val_acc: 0.7280\n","\n","Epoch 00013: val_acc did not improve from 0.74720\n","Epoch 14/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.6652 - acc: 0.6318 - val_loss: 0.6082 - val_acc: 0.6480\n","\n","Epoch 00014: val_acc did not improve from 0.74720\n","Epoch 15/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.6545 - acc: 0.6254 - val_loss: 0.5531 - val_acc: 0.6672\n","\n","Epoch 00015: val_acc did not improve from 0.74720\n","Epoch 16/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.6305 - acc: 0.6534 - val_loss: 0.5724 - val_acc: 0.6848\n","\n","Epoch 00016: val_acc did not improve from 0.74720\n","Epoch 17/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.6623 - acc: 0.6445 - val_loss: 0.5488 - val_acc: 0.7024\n","\n","Epoch 00017: val_acc did not improve from 0.74720\n","Epoch 18/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.6476 - acc: 0.6441 - val_loss: 0.5212 - val_acc: 0.7488\n","\n","Epoch 00018: val_acc improved from 0.74720 to 0.74880, saving model to ./cnn_spectrogram_mf.h5\n","Epoch 19/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.6057 - acc: 0.6824 - val_loss: 0.5407 - val_acc: 0.7312\n","\n","Epoch 00019: val_acc did not improve from 0.74880\n","Epoch 20/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.6068 - acc: 0.6745 - val_loss: 0.4736 - val_acc: 0.7824\n","\n","Epoch 00020: val_acc improved from 0.74880 to 0.78240, saving model to ./cnn_spectrogram_mf.h5\n","Epoch 21/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5828 - acc: 0.6903 - val_loss: 0.4763 - val_acc: 0.7632\n","\n","Epoch 00021: val_acc did not improve from 0.78240\n","Epoch 22/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5911 - acc: 0.6760 - val_loss: 0.4804 - val_acc: 0.7376\n","\n","Epoch 00022: val_acc did not improve from 0.78240\n","Epoch 23/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5838 - acc: 0.6883 - val_loss: 0.4726 - val_acc: 0.7696\n","\n","Epoch 00023: val_acc did not improve from 0.78240\n","Epoch 24/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5849 - acc: 0.6878 - val_loss: 0.6513 - val_acc: 0.6288\n","\n","Epoch 00024: val_acc did not improve from 0.78240\n","Epoch 25/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5697 - acc: 0.6829 - val_loss: 0.5206 - val_acc: 0.6976\n","\n","Epoch 00025: val_acc did not improve from 0.78240\n","Epoch 26/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5543 - acc: 0.7045 - val_loss: 0.4526 - val_acc: 0.8064\n","\n","Epoch 00026: val_acc improved from 0.78240 to 0.80640, saving model to ./cnn_spectrogram_mf.h5\n","Epoch 27/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5523 - acc: 0.7089 - val_loss: 0.4997 - val_acc: 0.7104\n","\n","Epoch 00027: val_acc did not improve from 0.80640\n","Epoch 28/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5767 - acc: 0.6706 - val_loss: 0.4671 - val_acc: 0.7904\n","\n","Epoch 00028: val_acc did not improve from 0.80640\n","Epoch 29/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5367 - acc: 0.7089 - val_loss: 0.4694 - val_acc: 0.7376\n","\n","Epoch 00029: val_acc did not improve from 0.80640\n","Epoch 30/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5563 - acc: 0.6927 - val_loss: 0.4967 - val_acc: 0.7376\n","\n","Epoch 00030: val_acc did not improve from 0.80640\n","Epoch 31/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5596 - acc: 0.6863 - val_loss: 0.4733 - val_acc: 0.7584\n","\n","Epoch 00031: val_acc did not improve from 0.80640\n","Epoch 32/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5217 - acc: 0.7080 - val_loss: 0.4271 - val_acc: 0.8016\n","\n","Epoch 00032: val_acc did not improve from 0.80640\n","Epoch 33/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5274 - acc: 0.7227 - val_loss: 0.4803 - val_acc: 0.7776\n","\n","Epoch 00033: val_acc did not improve from 0.80640\n","Epoch 34/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5481 - acc: 0.7085 - val_loss: 0.4847 - val_acc: 0.7408\n","\n","Epoch 00034: val_acc did not improve from 0.80640\n","Epoch 35/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5660 - acc: 0.7006 - val_loss: 0.4836 - val_acc: 0.7616\n","\n","Epoch 00035: val_acc did not improve from 0.80640\n","Epoch 36/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5270 - acc: 0.7144 - val_loss: 0.4309 - val_acc: 0.8096\n","\n","Epoch 00036: val_acc improved from 0.80640 to 0.80960, saving model to ./cnn_spectrogram_mf.h5\n","Epoch 37/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5226 - acc: 0.7030 - val_loss: 0.7108 - val_acc: 0.6720\n","\n","Epoch 00037: val_acc did not improve from 0.80960\n","Epoch 38/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5254 - acc: 0.7055 - val_loss: 0.4998 - val_acc: 0.7488\n","\n","Epoch 00038: val_acc did not improve from 0.80960\n","Epoch 39/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5382 - acc: 0.6947 - val_loss: 0.4645 - val_acc: 0.7584\n","\n","Epoch 00039: val_acc did not improve from 0.80960\n","Epoch 40/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5187 - acc: 0.7139 - val_loss: 0.5123 - val_acc: 0.7408\n","\n","Epoch 00040: val_acc did not improve from 0.80960\n","Epoch 41/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5421 - acc: 0.6996 - val_loss: 0.4580 - val_acc: 0.7984\n","\n","Epoch 00041: val_acc did not improve from 0.80960\n","Epoch 42/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5223 - acc: 0.7089 - val_loss: 0.5068 - val_acc: 0.7520\n","\n","Epoch 00042: val_acc did not improve from 0.80960\n","Epoch 43/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5225 - acc: 0.7035 - val_loss: 0.4788 - val_acc: 0.7376\n","\n","Epoch 00043: val_acc did not improve from 0.80960\n","Epoch 44/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4978 - acc: 0.7242 - val_loss: 0.4621 - val_acc: 0.7600\n","\n","Epoch 00044: val_acc did not improve from 0.80960\n","Epoch 45/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5090 - acc: 0.7193 - val_loss: 0.4835 - val_acc: 0.7376\n","\n","Epoch 00045: val_acc did not improve from 0.80960\n","Epoch 46/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5075 - acc: 0.7188 - val_loss: 0.4289 - val_acc: 0.7776\n","\n","Epoch 00046: val_acc did not improve from 0.80960\n","Epoch 47/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4885 - acc: 0.7384 - val_loss: 0.4593 - val_acc: 0.7568\n","\n","Epoch 00047: val_acc did not improve from 0.80960\n","Epoch 48/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5038 - acc: 0.7247 - val_loss: 0.4141 - val_acc: 0.8096\n","\n","Epoch 00048: val_acc did not improve from 0.80960\n","Epoch 49/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4914 - acc: 0.7296 - val_loss: 0.4391 - val_acc: 0.7872\n","\n","Epoch 00049: val_acc did not improve from 0.80960\n","Epoch 50/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4967 - acc: 0.7345 - val_loss: 0.4348 - val_acc: 0.7808\n","\n","Epoch 00050: val_acc did not improve from 0.80960\n","Epoch 51/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4796 - acc: 0.7335 - val_loss: 0.4400 - val_acc: 0.7856\n","\n","Epoch 00051: val_acc did not improve from 0.80960\n","Epoch 52/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5054 - acc: 0.7158 - val_loss: 0.5688 - val_acc: 0.7328\n","\n","Epoch 00052: val_acc did not improve from 0.80960\n","Epoch 53/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5417 - acc: 0.7060 - val_loss: 0.4339 - val_acc: 0.8128\n","\n","Epoch 00053: val_acc improved from 0.80960 to 0.81280, saving model to ./cnn_spectrogram_mf.h5\n","Epoch 54/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5279 - acc: 0.7021 - val_loss: 0.4846 - val_acc: 0.7392\n","\n","Epoch 00054: val_acc did not improve from 0.81280\n","Epoch 55/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5315 - acc: 0.6976 - val_loss: 0.4616 - val_acc: 0.7744\n","\n","Epoch 00055: val_acc did not improve from 0.81280\n","Epoch 56/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5140 - acc: 0.7129 - val_loss: 0.5138 - val_acc: 0.7168\n","\n","Epoch 00056: val_acc did not improve from 0.81280\n","Epoch 57/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5092 - acc: 0.7139 - val_loss: 0.4603 - val_acc: 0.7536\n","\n","Epoch 00057: val_acc did not improve from 0.81280\n","Epoch 58/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4973 - acc: 0.7257 - val_loss: 0.4884 - val_acc: 0.7536\n","\n","Epoch 00058: val_acc did not improve from 0.81280\n","Epoch 59/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5037 - acc: 0.7203 - val_loss: 0.4958 - val_acc: 0.7792\n","\n","Epoch 00059: val_acc did not improve from 0.81280\n","Epoch 60/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4779 - acc: 0.7434 - val_loss: 0.4624 - val_acc: 0.7872\n","\n","Epoch 00060: val_acc did not improve from 0.81280\n","Epoch 61/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4733 - acc: 0.7488 - val_loss: 0.5012 - val_acc: 0.7664\n","\n","Epoch 00061: val_acc did not improve from 0.81280\n","Epoch 62/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5069 - acc: 0.7153 - val_loss: 0.4837 - val_acc: 0.7728\n","\n","Epoch 00062: val_acc did not improve from 0.81280\n","Epoch 63/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.5051 - acc: 0.7247 - val_loss: 0.4524 - val_acc: 0.7904\n","\n","Epoch 00063: val_acc did not improve from 0.81280\n","Epoch 64/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4959 - acc: 0.7360 - val_loss: 0.4650 - val_acc: 0.7616\n","\n","Epoch 00064: val_acc did not improve from 0.81280\n","Epoch 65/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4707 - acc: 0.7291 - val_loss: 0.4789 - val_acc: 0.7408\n","\n","Epoch 00065: val_acc did not improve from 0.81280\n","Epoch 66/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4829 - acc: 0.7247 - val_loss: 0.4520 - val_acc: 0.7952\n","\n","Epoch 00066: val_acc did not improve from 0.81280\n","Epoch 67/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4602 - acc: 0.7439 - val_loss: 0.4435 - val_acc: 0.7952\n","\n","Epoch 00067: val_acc did not improve from 0.81280\n","Epoch 68/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4802 - acc: 0.7296 - val_loss: 0.4408 - val_acc: 0.7888\n","\n","Epoch 00068: val_acc did not improve from 0.81280\n","Epoch 69/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4635 - acc: 0.7463 - val_loss: 0.4864 - val_acc: 0.7632\n","\n","Epoch 00069: val_acc did not improve from 0.81280\n","Epoch 70/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4785 - acc: 0.7389 - val_loss: 0.4263 - val_acc: 0.7968\n","\n","Epoch 00070: val_acc did not improve from 0.81280\n","Epoch 71/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4569 - acc: 0.7429 - val_loss: 0.5068 - val_acc: 0.7520\n","\n","Epoch 00071: val_acc did not improve from 0.81280\n","Epoch 72/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4919 - acc: 0.7321 - val_loss: 0.4640 - val_acc: 0.7600\n","\n","Epoch 00072: val_acc did not improve from 0.81280\n","Epoch 73/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4633 - acc: 0.7370 - val_loss: 0.4248 - val_acc: 0.7984\n","\n","Epoch 00073: val_acc did not improve from 0.81280\n","Epoch 74/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4540 - acc: 0.7507 - val_loss: 0.4291 - val_acc: 0.7808\n","\n","Epoch 00074: val_acc did not improve from 0.81280\n","Epoch 75/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4609 - acc: 0.7478 - val_loss: 0.5102 - val_acc: 0.7440\n","\n","Epoch 00075: val_acc did not improve from 0.81280\n","Epoch 76/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4735 - acc: 0.7478 - val_loss: 0.4815 - val_acc: 0.7808\n","\n","Epoch 00076: val_acc did not improve from 0.81280\n","Epoch 77/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4554 - acc: 0.7478 - val_loss: 0.4307 - val_acc: 0.8080\n","\n","Epoch 00077: val_acc did not improve from 0.81280\n","Epoch 78/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4691 - acc: 0.7424 - val_loss: 0.4560 - val_acc: 0.8096\n","\n","Epoch 00078: val_acc did not improve from 0.81280\n","Epoch 79/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4612 - acc: 0.7424 - val_loss: 0.4459 - val_acc: 0.7968\n","\n","Epoch 00079: val_acc did not improve from 0.81280\n","Epoch 80/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4469 - acc: 0.7581 - val_loss: 0.4321 - val_acc: 0.8048\n","\n","Epoch 00080: val_acc did not improve from 0.81280\n","Epoch 81/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4625 - acc: 0.7443 - val_loss: 0.4338 - val_acc: 0.8176\n","\n","Epoch 00081: val_acc improved from 0.81280 to 0.81760, saving model to ./cnn_spectrogram_mf.h5\n","Epoch 82/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4597 - acc: 0.7498 - val_loss: 0.4819 - val_acc: 0.7616\n","\n","Epoch 00082: val_acc did not improve from 0.81760\n","Epoch 83/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4513 - acc: 0.7512 - val_loss: 0.4181 - val_acc: 0.8176\n","\n","Epoch 00083: val_acc improved from 0.81760 to 0.81760, saving model to ./cnn_spectrogram_mf.h5\n","Epoch 84/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4462 - acc: 0.7370 - val_loss: 0.4580 - val_acc: 0.7568\n","\n","Epoch 00084: val_acc did not improve from 0.81760\n","Epoch 85/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4693 - acc: 0.7345 - val_loss: 0.5209 - val_acc: 0.7536\n","\n","Epoch 00085: val_acc did not improve from 0.81760\n","Epoch 86/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4984 - acc: 0.7247 - val_loss: 0.4313 - val_acc: 0.8080\n","\n","Epoch 00086: val_acc did not improve from 0.81760\n","Epoch 87/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4536 - acc: 0.7566 - val_loss: 0.4460 - val_acc: 0.8144\n","\n","Epoch 00087: val_acc did not improve from 0.81760\n","Epoch 88/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4545 - acc: 0.7557 - val_loss: 0.4355 - val_acc: 0.7968\n","\n","Epoch 00088: val_acc did not improve from 0.81760\n","Epoch 89/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4357 - acc: 0.7675 - val_loss: 0.4535 - val_acc: 0.7696\n","\n","Epoch 00089: val_acc did not improve from 0.81760\n","Epoch 90/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4575 - acc: 0.7620 - val_loss: 0.4308 - val_acc: 0.8064\n","\n","Epoch 00090: val_acc did not improve from 0.81760\n","Epoch 91/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4622 - acc: 0.7507 - val_loss: 0.4965 - val_acc: 0.7888\n","\n","Epoch 00091: val_acc did not improve from 0.81760\n","Epoch 92/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4479 - acc: 0.7527 - val_loss: 0.4911 - val_acc: 0.7568\n","\n","Epoch 00092: val_acc did not improve from 0.81760\n","Epoch 93/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4590 - acc: 0.7591 - val_loss: 0.4814 - val_acc: 0.7776\n","\n","Epoch 00093: val_acc did not improve from 0.81760\n","Epoch 94/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4512 - acc: 0.7601 - val_loss: 0.4387 - val_acc: 0.7888\n","\n","Epoch 00094: val_acc did not improve from 0.81760\n","Epoch 95/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4556 - acc: 0.7419 - val_loss: 0.4506 - val_acc: 0.7920\n","\n","Epoch 00095: val_acc did not improve from 0.81760\n","Epoch 96/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4345 - acc: 0.7650 - val_loss: 0.4107 - val_acc: 0.8000\n","\n","Epoch 00096: val_acc did not improve from 0.81760\n","Epoch 97/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4357 - acc: 0.7625 - val_loss: 0.5175 - val_acc: 0.7648\n","\n","Epoch 00097: val_acc did not improve from 0.81760\n","Epoch 98/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4554 - acc: 0.7537 - val_loss: 0.4809 - val_acc: 0.7360\n","\n","Epoch 00098: val_acc did not improve from 0.81760\n","Epoch 99/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4574 - acc: 0.7502 - val_loss: 0.4466 - val_acc: 0.7936\n","\n","Epoch 00099: val_acc did not improve from 0.81760\n","Epoch 100/100\n","2034/2034 [==============================] - 49s 24ms/step - loss: 0.4538 - acc: 0.7581 - val_loss: 0.4954 - val_acc: 0.8000\n","\n","Epoch 00100: val_acc did not improve from 0.81760\n"],"name":"stdout"}]},{"metadata":{"id":"XzjjD9MirXvH","colab_type":"code","outputId":"984b0c25-32e2-4548-d375-acb50cf0eda2","executionInfo":{"status":"ok","timestamp":1556048042499,"user_tz":-330,"elapsed":1337,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["data2[0]['emotion']"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'neu'"]},"metadata":{"tags":[]},"execution_count":30}]},{"metadata":{"id":"ckd_ZycFq51H","colab_type":"code","outputId":"2f97751d-ab9a-4f20-db91-1db9845a398c","executionInfo":{"status":"ok","timestamp":1556048070181,"user_tz":-330,"elapsed":8876,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"cell_type":"code","source":["X_train = []\n","X_test = []\n","Y_train = []\n","Y_test = []\n","fs = 16e3\n","counter = 0\n","counter1 = 0\n","for ses_mod in data2:\n","    if 'impro' in ses_mod['id'] and ses_mod['emotion'] in emotions_used and ses_mod['id'][-4]=='M' :\n","        f, t, Sxx = signal.spectrogram(ses_mod['signal'], fs, nperseg=400,noverlap=200)\n","        Sxx = pad_sequence_into_array(Sxx,maxlen=300,value=0)\n","        \n","        if ses_mod['id'][:5]==\"Ses05\":\n","            counter+=1\n","            X_test.append(Sxx)\n","            Y_test.append(ses_mod['emotion'])\n","        else:\n","            counter1+=1\n","            X_train.append(Sxx)\n","            Y_train.append(ses_mod['emotion'])\n","        \n","print(counter)\n","print(counter1)\n","\n","X_test = np.array(X_test)\n","X_train = np.array(X_train)\n","print(X_train.shape)\n","print(X_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["315\n","1009\n","(1009, 201, 300)\n","(315, 201, 300)\n"],"name":"stdout"}]},{"metadata":{"id":"u6JiIUZtr2WF","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = X_train.reshape(-1,201,300,1)\n","X_test = X_test.reshape(-1,201,300,1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"WnE1sy1IsmgR","colab_type":"code","colab":{}},"cell_type":"code","source":["y  = pd.get_dummies(Y_train+Y_test)\n","y_train = y[0:len(Y_train)]\n","y_test = y[len(Y_train):]\n","y_train = np.array(y_train)\n","y_test = np.array(y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gcMsTMWrsqqF","colab_type":"code","colab":{}},"cell_type":"code","source":["def make_model():\n","    in_layer = Input(shape=(201, 300,1))\n","    x = Conv2D(32,(5,5), activation = 'elu')(in_layer)  \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(64,(5,5), activation = 'elu')(x)         \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(64,(5,5), activation = 'elu')(x)         \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(128, (5,5))(x)                           \n","    x = GlobalAveragePooling2D()(x)                     \n","    x = Dense(64,activation='elu')(x)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(4, activation = \"softmax\")(x) \n","    model = Model(inputs = in_layer, outputs=output_layer)\n","    return model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2yuOYI1Ws0An","colab_type":"code","outputId":"43b63eeb-2b50-448f-c171-9341d70a501c","executionInfo":{"status":"ok","timestamp":1556050808276,"user_tz":-330,"elapsed":2424976,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":6787}},"cell_type":"code","source":["model  =  make_model()\n","model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\",\n","                    metrics=[\"accuracy\"])\n","m_check = keras.callbacks.ModelCheckpoint(filepath = './cnn_spectrogram_male.h5', monitor='val_acc', save_best_only=True, mode='max', verbose=1 )\n","hist = model.fit(X_train, y_train, \n","                 batch_size=32, validation_data=(X_test,y_test),nb_epoch=100, verbose=1, shuffle = True,callbacks=[m_check] \n","                )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["Train on 1009 samples, validate on 315 samples\n","Epoch 1/100\n","1009/1009 [==============================] - 31s 30ms/step - loss: 4.3861 - acc: 0.3994 - val_loss: 1.5528 - val_acc: 0.4159\n","\n","Epoch 00001: val_acc improved from -inf to 0.41587, saving model to ./cnn_spectrogram_male.h5\n","Epoch 2/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.6424 - acc: 0.4103 - val_loss: 1.1777 - val_acc: 0.4762\n","\n","Epoch 00002: val_acc improved from 0.41587 to 0.47619, saving model to ./cnn_spectrogram_male.h5\n","Epoch 3/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.2917 - acc: 0.4757 - val_loss: 1.2221 - val_acc: 0.5016\n","\n","Epoch 00003: val_acc improved from 0.47619 to 0.50159, saving model to ./cnn_spectrogram_male.h5\n","Epoch 4/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.1749 - acc: 0.5015 - val_loss: 1.1022 - val_acc: 0.5556\n","\n","Epoch 00004: val_acc improved from 0.50159 to 0.55556, saving model to ./cnn_spectrogram_male.h5\n","Epoch 5/100\n","1009/1009 [==============================] - 25s 24ms/step - loss: 1.1392 - acc: 0.5342 - val_loss: 1.4065 - val_acc: 0.5016\n","\n","Epoch 00005: val_acc did not improve from 0.55556\n","Epoch 6/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.1145 - acc: 0.5094 - val_loss: 1.1996 - val_acc: 0.5079\n","\n","Epoch 00006: val_acc did not improve from 0.55556\n","Epoch 7/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.1040 - acc: 0.5282 - val_loss: 1.1416 - val_acc: 0.5079\n","\n","Epoch 00007: val_acc did not improve from 0.55556\n","Epoch 8/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.1016 - acc: 0.5411 - val_loss: 1.3188 - val_acc: 0.4698\n","\n","Epoch 00008: val_acc did not improve from 0.55556\n","Epoch 9/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.1032 - acc: 0.5302 - val_loss: 1.1070 - val_acc: 0.5302\n","\n","Epoch 00009: val_acc did not improve from 0.55556\n","Epoch 10/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0733 - acc: 0.5382 - val_loss: 1.2276 - val_acc: 0.4984\n","\n","Epoch 00010: val_acc did not improve from 0.55556\n","Epoch 11/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0491 - acc: 0.5649 - val_loss: 1.1460 - val_acc: 0.5079\n","\n","Epoch 00011: val_acc did not improve from 0.55556\n","Epoch 12/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0577 - acc: 0.5461 - val_loss: 1.2415 - val_acc: 0.4857\n","\n","Epoch 00012: val_acc did not improve from 0.55556\n","Epoch 13/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0571 - acc: 0.5461 - val_loss: 1.1671 - val_acc: 0.4984\n","\n","Epoch 00013: val_acc did not improve from 0.55556\n","Epoch 14/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0366 - acc: 0.5500 - val_loss: 1.2252 - val_acc: 0.4952\n","\n","Epoch 00014: val_acc did not improve from 0.55556\n","Epoch 15/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0525 - acc: 0.5570 - val_loss: 1.1544 - val_acc: 0.4603\n","\n","Epoch 00015: val_acc did not improve from 0.55556\n","Epoch 16/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0761 - acc: 0.5600 - val_loss: 1.1798 - val_acc: 0.4984\n","\n","Epoch 00016: val_acc did not improve from 0.55556\n","Epoch 17/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0340 - acc: 0.5312 - val_loss: 1.1543 - val_acc: 0.5048\n","\n","Epoch 00017: val_acc did not improve from 0.55556\n","Epoch 18/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0087 - acc: 0.5659 - val_loss: 1.1816 - val_acc: 0.5111\n","\n","Epoch 00018: val_acc did not improve from 0.55556\n","Epoch 19/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0408 - acc: 0.5580 - val_loss: 1.1712 - val_acc: 0.4857\n","\n","Epoch 00019: val_acc did not improve from 0.55556\n","Epoch 20/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9948 - acc: 0.5679 - val_loss: 1.1204 - val_acc: 0.5206\n","\n","Epoch 00020: val_acc did not improve from 0.55556\n","Epoch 21/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0495 - acc: 0.5590 - val_loss: 1.2046 - val_acc: 0.4857\n","\n","Epoch 00021: val_acc did not improve from 0.55556\n","Epoch 22/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0308 - acc: 0.5510 - val_loss: 1.1305 - val_acc: 0.4984\n","\n","Epoch 00022: val_acc did not improve from 0.55556\n","Epoch 23/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9900 - acc: 0.5699 - val_loss: 1.2870 - val_acc: 0.5048\n","\n","Epoch 00023: val_acc did not improve from 0.55556\n","Epoch 24/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0326 - acc: 0.5590 - val_loss: 1.1377 - val_acc: 0.5175\n","\n","Epoch 00024: val_acc did not improve from 0.55556\n","Epoch 25/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0318 - acc: 0.5768 - val_loss: 1.1022 - val_acc: 0.5270\n","\n","Epoch 00025: val_acc did not improve from 0.55556\n","Epoch 26/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9665 - acc: 0.5867 - val_loss: 1.2022 - val_acc: 0.4921\n","\n","Epoch 00026: val_acc did not improve from 0.55556\n","Epoch 27/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0161 - acc: 0.5778 - val_loss: 1.1452 - val_acc: 0.4952\n","\n","Epoch 00027: val_acc did not improve from 0.55556\n","Epoch 28/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0174 - acc: 0.5679 - val_loss: 1.2463 - val_acc: 0.4889\n","\n","Epoch 00028: val_acc did not improve from 0.55556\n","Epoch 29/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0584 - acc: 0.5451 - val_loss: 1.4691 - val_acc: 0.4032\n","\n","Epoch 00029: val_acc did not improve from 0.55556\n","Epoch 30/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0340 - acc: 0.5372 - val_loss: 1.0337 - val_acc: 0.5556\n","\n","Epoch 00030: val_acc did not improve from 0.55556\n","Epoch 31/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9374 - acc: 0.5966 - val_loss: 1.1727 - val_acc: 0.5048\n","\n","Epoch 00031: val_acc did not improve from 0.55556\n","Epoch 32/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 1.0083 - acc: 0.5679 - val_loss: 1.1992 - val_acc: 0.4857\n","\n","Epoch 00032: val_acc did not improve from 0.55556\n","Epoch 33/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9629 - acc: 0.5758 - val_loss: 1.1127 - val_acc: 0.5079\n","\n","Epoch 00033: val_acc did not improve from 0.55556\n","Epoch 34/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9387 - acc: 0.6016 - val_loss: 1.1812 - val_acc: 0.4921\n","\n","Epoch 00034: val_acc did not improve from 0.55556\n","Epoch 35/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9596 - acc: 0.5738 - val_loss: 1.1594 - val_acc: 0.4984\n","\n","Epoch 00035: val_acc did not improve from 0.55556\n","Epoch 36/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9472 - acc: 0.5897 - val_loss: 1.1026 - val_acc: 0.5175\n","\n","Epoch 00036: val_acc did not improve from 0.55556\n","Epoch 37/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9577 - acc: 0.5778 - val_loss: 1.1434 - val_acc: 0.5048\n","\n","Epoch 00037: val_acc did not improve from 0.55556\n","Epoch 38/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8973 - acc: 0.5996 - val_loss: 1.1339 - val_acc: 0.4921\n","\n","Epoch 00038: val_acc did not improve from 0.55556\n","Epoch 39/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9010 - acc: 0.6105 - val_loss: 1.1344 - val_acc: 0.4825\n","\n","Epoch 00039: val_acc did not improve from 0.55556\n","Epoch 40/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8806 - acc: 0.6165 - val_loss: 1.1799 - val_acc: 0.5079\n","\n","Epoch 00040: val_acc did not improve from 0.55556\n","Epoch 41/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9098 - acc: 0.6095 - val_loss: 1.2656 - val_acc: 0.4730\n","\n","Epoch 00041: val_acc did not improve from 0.55556\n","Epoch 42/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9288 - acc: 0.5897 - val_loss: 1.2265 - val_acc: 0.4794\n","\n","Epoch 00042: val_acc did not improve from 0.55556\n","Epoch 43/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8802 - acc: 0.6244 - val_loss: 1.2218 - val_acc: 0.4857\n","\n","Epoch 00043: val_acc did not improve from 0.55556\n","Epoch 44/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8803 - acc: 0.6264 - val_loss: 1.3540 - val_acc: 0.4921\n","\n","Epoch 00044: val_acc did not improve from 0.55556\n","Epoch 45/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8899 - acc: 0.6155 - val_loss: 1.1130 - val_acc: 0.5206\n","\n","Epoch 00045: val_acc did not improve from 0.55556\n","Epoch 46/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9023 - acc: 0.6095 - val_loss: 1.1963 - val_acc: 0.4730\n","\n","Epoch 00046: val_acc did not improve from 0.55556\n","Epoch 47/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9289 - acc: 0.5867 - val_loss: 1.1587 - val_acc: 0.5079\n","\n","Epoch 00047: val_acc did not improve from 0.55556\n","Epoch 48/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9161 - acc: 0.6046 - val_loss: 1.0757 - val_acc: 0.5302\n","\n","Epoch 00048: val_acc did not improve from 0.55556\n","Epoch 49/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.9000 - acc: 0.6125 - val_loss: 1.1672 - val_acc: 0.4889\n","\n","Epoch 00049: val_acc did not improve from 0.55556\n","Epoch 50/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8642 - acc: 0.6293 - val_loss: 1.1723 - val_acc: 0.5048\n","\n","Epoch 00050: val_acc did not improve from 0.55556\n","Epoch 51/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8459 - acc: 0.6313 - val_loss: 1.1963 - val_acc: 0.4794\n","\n","Epoch 00051: val_acc did not improve from 0.55556\n","Epoch 52/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8529 - acc: 0.6264 - val_loss: 1.2169 - val_acc: 0.4921\n","\n","Epoch 00052: val_acc did not improve from 0.55556\n","Epoch 53/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8571 - acc: 0.6323 - val_loss: 1.2389 - val_acc: 0.4730\n","\n","Epoch 00053: val_acc did not improve from 0.55556\n","Epoch 54/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8369 - acc: 0.6472 - val_loss: 1.1282 - val_acc: 0.5270\n","\n","Epoch 00054: val_acc did not improve from 0.55556\n","Epoch 55/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8287 - acc: 0.6323 - val_loss: 1.3172 - val_acc: 0.4381\n","\n","Epoch 00055: val_acc did not improve from 0.55556\n","Epoch 56/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8526 - acc: 0.6264 - val_loss: 1.1806 - val_acc: 0.4794\n","\n","Epoch 00056: val_acc did not improve from 0.55556\n","Epoch 57/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8794 - acc: 0.6075 - val_loss: 1.1446 - val_acc: 0.5016\n","\n","Epoch 00057: val_acc did not improve from 0.55556\n","Epoch 58/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8566 - acc: 0.6105 - val_loss: 1.2486 - val_acc: 0.4667\n","\n","Epoch 00058: val_acc did not improve from 0.55556\n","Epoch 59/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8609 - acc: 0.6105 - val_loss: 1.1685 - val_acc: 0.5048\n","\n","Epoch 00059: val_acc did not improve from 0.55556\n","Epoch 60/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8443 - acc: 0.6274 - val_loss: 1.2891 - val_acc: 0.4857\n","\n","Epoch 00060: val_acc did not improve from 0.55556\n","Epoch 61/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8407 - acc: 0.6462 - val_loss: 1.1588 - val_acc: 0.4762\n","\n","Epoch 00061: val_acc did not improve from 0.55556\n","Epoch 62/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8473 - acc: 0.6254 - val_loss: 1.1045 - val_acc: 0.5333\n","\n","Epoch 00062: val_acc did not improve from 0.55556\n","Epoch 63/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8599 - acc: 0.6274 - val_loss: 1.2274 - val_acc: 0.4794\n","\n","Epoch 00063: val_acc did not improve from 0.55556\n","Epoch 64/100\n","1009/1009 [==============================] - 24s 23ms/step - loss: 0.8897 - acc: 0.6214 - val_loss: 1.1972 - val_acc: 0.4921\n","\n","Epoch 00064: val_acc did not improve from 0.55556\n","Epoch 65/100\n","1009/1009 [==============================] - 24s 23ms/step - loss: 0.8363 - acc: 0.6333 - val_loss: 1.1521 - val_acc: 0.5016\n","\n","Epoch 00065: val_acc did not improve from 0.55556\n","Epoch 66/100\n","1009/1009 [==============================] - 24s 23ms/step - loss: 0.8387 - acc: 0.6561 - val_loss: 1.1807 - val_acc: 0.5016\n","\n","Epoch 00066: val_acc did not improve from 0.55556\n","Epoch 67/100\n","1009/1009 [==============================] - 24s 23ms/step - loss: 0.8105 - acc: 0.6303 - val_loss: 1.3233 - val_acc: 0.4571\n","\n","Epoch 00067: val_acc did not improve from 0.55556\n","Epoch 68/100\n","1009/1009 [==============================] - 24s 23ms/step - loss: 0.8408 - acc: 0.6432 - val_loss: 1.1413 - val_acc: 0.5143\n","\n","Epoch 00068: val_acc did not improve from 0.55556\n","Epoch 69/100\n","1009/1009 [==============================] - 24s 23ms/step - loss: 0.8527 - acc: 0.6244 - val_loss: 1.2433 - val_acc: 0.4635\n","\n","Epoch 00069: val_acc did not improve from 0.55556\n","Epoch 70/100\n","1009/1009 [==============================] - 24s 23ms/step - loss: 0.8156 - acc: 0.6501 - val_loss: 1.1324 - val_acc: 0.4794\n","\n","Epoch 00070: val_acc did not improve from 0.55556\n","Epoch 71/100\n","1009/1009 [==============================] - 24s 23ms/step - loss: 0.8114 - acc: 0.6482 - val_loss: 1.3986 - val_acc: 0.4222\n","\n","Epoch 00071: val_acc did not improve from 0.55556\n","Epoch 72/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.8067 - acc: 0.6492 - val_loss: 1.3287 - val_acc: 0.4603\n","\n","Epoch 00072: val_acc did not improve from 0.55556\n","Epoch 73/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.8093 - acc: 0.6462 - val_loss: 1.0851 - val_acc: 0.5079\n","\n","Epoch 00073: val_acc did not improve from 0.55556\n","Epoch 74/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.8408 - acc: 0.6501 - val_loss: 1.2105 - val_acc: 0.4857\n","\n","Epoch 00074: val_acc did not improve from 0.55556\n","Epoch 75/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.8509 - acc: 0.6135 - val_loss: 1.1356 - val_acc: 0.4984\n","\n","Epoch 00075: val_acc did not improve from 0.55556\n","Epoch 76/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.8310 - acc: 0.6442 - val_loss: 1.1336 - val_acc: 0.5016\n","\n","Epoch 00076: val_acc did not improve from 0.55556\n","Epoch 77/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.8591 - acc: 0.6274 - val_loss: 1.1814 - val_acc: 0.4730\n","\n","Epoch 00077: val_acc did not improve from 0.55556\n","Epoch 78/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.7845 - acc: 0.6630 - val_loss: 1.2235 - val_acc: 0.4857\n","\n","Epoch 00078: val_acc did not improve from 0.55556\n","Epoch 79/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.7729 - acc: 0.6739 - val_loss: 1.3168 - val_acc: 0.4794\n","\n","Epoch 00079: val_acc did not improve from 0.55556\n","Epoch 80/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.8753 - acc: 0.6353 - val_loss: 1.1581 - val_acc: 0.4825\n","\n","Epoch 00080: val_acc did not improve from 0.55556\n","Epoch 81/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.7790 - acc: 0.6680 - val_loss: 1.1405 - val_acc: 0.5048\n","\n","Epoch 00081: val_acc did not improve from 0.55556\n","Epoch 82/100\n","1009/1009 [==============================] - 24s 23ms/step - loss: 0.8389 - acc: 0.6363 - val_loss: 1.3057 - val_acc: 0.5048\n","\n","Epoch 00082: val_acc did not improve from 0.55556\n","Epoch 83/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.8698 - acc: 0.6293 - val_loss: 1.1155 - val_acc: 0.5048\n","\n","Epoch 00083: val_acc did not improve from 0.55556\n","Epoch 84/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.8024 - acc: 0.6640 - val_loss: 1.3771 - val_acc: 0.4571\n","\n","Epoch 00084: val_acc did not improve from 0.55556\n","Epoch 85/100\n","1009/1009 [==============================] - 23s 23ms/step - loss: 0.8168 - acc: 0.6501 - val_loss: 1.1506 - val_acc: 0.5079\n","\n","Epoch 00085: val_acc did not improve from 0.55556\n","Epoch 86/100\n","1009/1009 [==============================] - 25s 24ms/step - loss: 0.8107 - acc: 0.6482 - val_loss: 1.3372 - val_acc: 0.4730\n","\n","Epoch 00086: val_acc did not improve from 0.55556\n","Epoch 87/100\n","1009/1009 [==============================] - 25s 25ms/step - loss: 0.9039 - acc: 0.6452 - val_loss: 1.1316 - val_acc: 0.4984\n","\n","Epoch 00087: val_acc did not improve from 0.55556\n","Epoch 88/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.7874 - acc: 0.6601 - val_loss: 1.2459 - val_acc: 0.4698\n","\n","Epoch 00088: val_acc did not improve from 0.55556\n","Epoch 89/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.7684 - acc: 0.6700 - val_loss: 1.2962 - val_acc: 0.4984\n","\n","Epoch 00089: val_acc did not improve from 0.55556\n","Epoch 90/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8033 - acc: 0.6482 - val_loss: 1.2705 - val_acc: 0.5492\n","\n","Epoch 00090: val_acc did not improve from 0.55556\n","Epoch 91/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.8209 - acc: 0.6482 - val_loss: 1.2887 - val_acc: 0.4381\n","\n","Epoch 00091: val_acc did not improve from 0.55556\n","Epoch 92/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.7947 - acc: 0.6541 - val_loss: 1.2871 - val_acc: 0.4825\n","\n","Epoch 00092: val_acc did not improve from 0.55556\n","Epoch 93/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.7942 - acc: 0.6551 - val_loss: 1.1486 - val_acc: 0.4921\n","\n","Epoch 00093: val_acc did not improve from 0.55556\n","Epoch 94/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.7663 - acc: 0.6710 - val_loss: 1.3511 - val_acc: 0.4762\n","\n","Epoch 00094: val_acc did not improve from 0.55556\n","Epoch 95/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.7968 - acc: 0.6640 - val_loss: 1.3659 - val_acc: 0.4667\n","\n","Epoch 00095: val_acc did not improve from 0.55556\n","Epoch 96/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.7755 - acc: 0.6620 - val_loss: 1.1313 - val_acc: 0.5333\n","\n","Epoch 00096: val_acc did not improve from 0.55556\n","Epoch 97/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.7787 - acc: 0.6660 - val_loss: 1.3119 - val_acc: 0.4762\n","\n","Epoch 00097: val_acc did not improve from 0.55556\n","Epoch 98/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.7581 - acc: 0.6591 - val_loss: 1.1851 - val_acc: 0.4825\n","\n","Epoch 00098: val_acc did not improve from 0.55556\n","Epoch 99/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.7850 - acc: 0.6729 - val_loss: 1.1349 - val_acc: 0.5397\n","\n","Epoch 00099: val_acc did not improve from 0.55556\n","Epoch 100/100\n","1009/1009 [==============================] - 24s 24ms/step - loss: 0.7803 - acc: 0.6670 - val_loss: 1.1940 - val_acc: 0.4952\n","\n","Epoch 00100: val_acc did not improve from 0.55556\n"],"name":"stdout"}]},{"metadata":{"id":"whUudQPysZhd","colab_type":"code","outputId":"c47ab513-d0bf-43fa-bbea-0918c37f9684","executionInfo":{"status":"ok","timestamp":1556082002843,"user_tz":-330,"elapsed":7266,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"cell_type":"code","source":["X_train = []\n","X_test = []\n","Y_train = []\n","Y_test = []\n","fs = 16e3\n","counter = 0\n","counter1 = 0\n","for ses_mod in data2:\n","    if 'impro' in ses_mod['id'] and ses_mod['emotion'] in emotions_used and ses_mod['id'][-4]=='F' :\n","        f, t, Sxx = signal.spectrogram(ses_mod['signal'], fs, nperseg=400,noverlap=200)\n","        Sxx = pad_sequence_into_array(Sxx,maxlen=300,value=0)\n","        \n","        if ses_mod['id'][:5]==\"Ses05\":\n","            counter+=1\n","            X_test.append(Sxx)\n","            Y_test.append(ses_mod['emotion'])\n","        else:\n","            counter1+=1\n","            X_train.append(Sxx)\n","            Y_train.append(ses_mod['emotion'])\n","        \n","print(counter)\n","print(counter1)\n","\n","X_test = np.array(X_test)\n","X_train = np.array(X_train)\n","print(X_train.shape)\n","print(X_test.shape)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["310\n","1025\n","(1025, 201, 300)\n","(310, 201, 300)\n"],"name":"stdout"}]},{"metadata":{"id":"JnMTDBOSt2v7","colab_type":"code","colab":{}},"cell_type":"code","source":["X_train = X_train.reshape(-1,201,300,1)\n","X_test = X_test.reshape(-1,201,300,1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qN9wiWTot-6q","colab_type":"code","colab":{}},"cell_type":"code","source":["y  = pd.get_dummies(Y_train+Y_test)\n","y_train = y[0:len(Y_train)]\n","y_test = y[len(Y_train):]\n","y_train = np.array(y_train)\n","y_test = np.array(y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9iATAGu7sd70","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":7192},"outputId":"5463b435-a10d-4954-c640-fd4f00df5b59","executionInfo":{"status":"ok","timestamp":1556084512754,"user_tz":-330,"elapsed":2334741,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}}},"cell_type":"code","source":["model  =  make_model()\n","model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\",\n","                    metrics=[\"accuracy\"])\n","m_check = keras.callbacks.ModelCheckpoint(filepath = './cnn_spectrogram_female.h5', monitor='val_acc', save_best_only=True, mode='max', verbose=1 )\n","hist = model.fit(X_train, y_train, \n","                 batch_size=32, validation_data=(X_test,y_test),nb_epoch=100, verbose=1, shuffle = True,callbacks=[m_check] \n","                )"],"execution_count":14,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["Train on 1025 samples, validate on 310 samples\n","Epoch 1/100\n","1025/1025 [==============================] - 35s 35ms/step - loss: 5.0200 - acc: 0.3639 - val_loss: 1.2857 - val_acc: 0.4484\n","\n","Epoch 00001: val_acc improved from -inf to 0.44839, saving model to ./cnn_spectrogram_female.h5\n","Epoch 2/100\n","1025/1025 [==============================] - 22s 21ms/step - loss: 1.5970 - acc: 0.4195 - val_loss: 1.1515 - val_acc: 0.5387\n","\n","Epoch 00002: val_acc improved from 0.44839 to 0.53871, saving model to ./cnn_spectrogram_female.h5\n","Epoch 3/100\n","1025/1025 [==============================] - 22s 22ms/step - loss: 1.4108 - acc: 0.4439 - val_loss: 1.3166 - val_acc: 0.4484\n","\n","Epoch 00003: val_acc did not improve from 0.53871\n","Epoch 4/100\n","1025/1025 [==============================] - 22s 22ms/step - loss: 1.4080 - acc: 0.4566 - val_loss: 1.2648 - val_acc: 0.4065\n","\n","Epoch 00004: val_acc did not improve from 0.53871\n","Epoch 5/100\n","1025/1025 [==============================] - 22s 22ms/step - loss: 1.2718 - acc: 0.4527 - val_loss: 1.0855 - val_acc: 0.5032\n","\n","Epoch 00005: val_acc did not improve from 0.53871\n","Epoch 6/100\n","1025/1025 [==============================] - 23s 22ms/step - loss: 1.2716 - acc: 0.4615 - val_loss: 1.0987 - val_acc: 0.5548\n","\n","Epoch 00006: val_acc improved from 0.53871 to 0.55484, saving model to ./cnn_spectrogram_female.h5\n","Epoch 7/100\n","1025/1025 [==============================] - 23s 22ms/step - loss: 1.1865 - acc: 0.4712 - val_loss: 1.0324 - val_acc: 0.5097\n","\n","Epoch 00007: val_acc did not improve from 0.55484\n","Epoch 8/100\n","1025/1025 [==============================] - 23s 22ms/step - loss: 1.1801 - acc: 0.4868 - val_loss: 1.0843 - val_acc: 0.5290\n","\n","Epoch 00008: val_acc did not improve from 0.55484\n","Epoch 9/100\n","1025/1025 [==============================] - 23s 22ms/step - loss: 1.1336 - acc: 0.5122 - val_loss: 1.2450 - val_acc: 0.4000\n","\n","Epoch 00009: val_acc did not improve from 0.55484\n","Epoch 10/100\n","1025/1025 [==============================] - 23s 22ms/step - loss: 1.1703 - acc: 0.5034 - val_loss: 1.0587 - val_acc: 0.5226\n","\n","Epoch 00010: val_acc did not improve from 0.55484\n","Epoch 11/100\n","1025/1025 [==============================] - 23s 22ms/step - loss: 1.1015 - acc: 0.5161 - val_loss: 1.0245 - val_acc: 0.5419\n","\n","Epoch 00011: val_acc did not improve from 0.55484\n","Epoch 12/100\n","1025/1025 [==============================] - 23s 22ms/step - loss: 1.0826 - acc: 0.5093 - val_loss: 1.0042 - val_acc: 0.5839\n","\n","Epoch 00012: val_acc improved from 0.55484 to 0.58387, saving model to ./cnn_spectrogram_female.h5\n","Epoch 13/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.1370 - acc: 0.5200 - val_loss: 1.0226 - val_acc: 0.6161\n","\n","Epoch 00013: val_acc improved from 0.58387 to 0.61613, saving model to ./cnn_spectrogram_female.h5\n","Epoch 14/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0977 - acc: 0.5151 - val_loss: 0.9921 - val_acc: 0.6355\n","\n","Epoch 00014: val_acc improved from 0.61613 to 0.63548, saving model to ./cnn_spectrogram_female.h5\n","Epoch 15/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.1360 - acc: 0.5249 - val_loss: 0.9672 - val_acc: 0.6000\n","\n","Epoch 00015: val_acc did not improve from 0.63548\n","Epoch 16/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.1001 - acc: 0.5327 - val_loss: 1.3272 - val_acc: 0.4516\n","\n","Epoch 00016: val_acc did not improve from 0.63548\n","Epoch 17/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.3714 - acc: 0.4683 - val_loss: 0.9910 - val_acc: 0.5839\n","\n","Epoch 00017: val_acc did not improve from 0.63548\n","Epoch 18/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0997 - acc: 0.5200 - val_loss: 0.9701 - val_acc: 0.6065\n","\n","Epoch 00018: val_acc did not improve from 0.63548\n","Epoch 19/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0865 - acc: 0.5424 - val_loss: 1.0215 - val_acc: 0.5516\n","\n","Epoch 00019: val_acc did not improve from 0.63548\n","Epoch 20/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0437 - acc: 0.5571 - val_loss: 1.0266 - val_acc: 0.5516\n","\n","Epoch 00020: val_acc did not improve from 0.63548\n","Epoch 21/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0938 - acc: 0.5376 - val_loss: 0.9940 - val_acc: 0.5581\n","\n","Epoch 00021: val_acc did not improve from 0.63548\n","Epoch 22/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0401 - acc: 0.5395 - val_loss: 0.9369 - val_acc: 0.6129\n","\n","Epoch 00022: val_acc did not improve from 0.63548\n","Epoch 23/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0387 - acc: 0.5824 - val_loss: 1.0794 - val_acc: 0.5161\n","\n","Epoch 00023: val_acc did not improve from 0.63548\n","Epoch 24/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0373 - acc: 0.5580 - val_loss: 1.0174 - val_acc: 0.5935\n","\n","Epoch 00024: val_acc did not improve from 0.63548\n","Epoch 25/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0947 - acc: 0.5337 - val_loss: 0.9389 - val_acc: 0.6290\n","\n","Epoch 00025: val_acc did not improve from 0.63548\n","Epoch 26/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0418 - acc: 0.5571 - val_loss: 1.3363 - val_acc: 0.4065\n","\n","Epoch 00026: val_acc did not improve from 0.63548\n","Epoch 27/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.1109 - acc: 0.5395 - val_loss: 0.9922 - val_acc: 0.5710\n","\n","Epoch 00027: val_acc did not improve from 0.63548\n","Epoch 28/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0259 - acc: 0.5815 - val_loss: 1.1173 - val_acc: 0.5194\n","\n","Epoch 00028: val_acc did not improve from 0.63548\n","Epoch 29/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.1128 - acc: 0.5171 - val_loss: 1.1058 - val_acc: 0.5161\n","\n","Epoch 00029: val_acc did not improve from 0.63548\n","Epoch 30/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0013 - acc: 0.5698 - val_loss: 0.9490 - val_acc: 0.6194\n","\n","Epoch 00030: val_acc did not improve from 0.63548\n","Epoch 31/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0173 - acc: 0.5522 - val_loss: 0.9636 - val_acc: 0.5871\n","\n","Epoch 00031: val_acc did not improve from 0.63548\n","Epoch 32/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9898 - acc: 0.5815 - val_loss: 0.9152 - val_acc: 0.6645\n","\n","Epoch 00032: val_acc improved from 0.63548 to 0.66452, saving model to ./cnn_spectrogram_female.h5\n","Epoch 33/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9677 - acc: 0.5961 - val_loss: 0.9232 - val_acc: 0.6484\n","\n","Epoch 00033: val_acc did not improve from 0.66452\n","Epoch 34/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9751 - acc: 0.5922 - val_loss: 0.9453 - val_acc: 0.6194\n","\n","Epoch 00034: val_acc did not improve from 0.66452\n","Epoch 35/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9444 - acc: 0.5893 - val_loss: 0.8786 - val_acc: 0.6677\n","\n","Epoch 00035: val_acc improved from 0.66452 to 0.66774, saving model to ./cnn_spectrogram_female.h5\n","Epoch 36/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0222 - acc: 0.5961 - val_loss: 1.0221 - val_acc: 0.5419\n","\n","Epoch 00036: val_acc did not improve from 0.66774\n","Epoch 37/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0259 - acc: 0.5668 - val_loss: 1.0101 - val_acc: 0.5419\n","\n","Epoch 00037: val_acc did not improve from 0.66774\n","Epoch 38/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9822 - acc: 0.5795 - val_loss: 0.8768 - val_acc: 0.6806\n","\n","Epoch 00038: val_acc improved from 0.66774 to 0.68065, saving model to ./cnn_spectrogram_female.h5\n","Epoch 39/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9642 - acc: 0.6049 - val_loss: 1.0346 - val_acc: 0.5806\n","\n","Epoch 00039: val_acc did not improve from 0.68065\n","Epoch 40/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9629 - acc: 0.6244 - val_loss: 0.9253 - val_acc: 0.6452\n","\n","Epoch 00040: val_acc did not improve from 0.68065\n","Epoch 41/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0255 - acc: 0.5707 - val_loss: 0.9266 - val_acc: 0.5935\n","\n","Epoch 00041: val_acc did not improve from 0.68065\n","Epoch 42/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0050 - acc: 0.5590 - val_loss: 0.8894 - val_acc: 0.6484\n","\n","Epoch 00042: val_acc did not improve from 0.68065\n","Epoch 43/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9821 - acc: 0.5815 - val_loss: 0.8886 - val_acc: 0.6710\n","\n","Epoch 00043: val_acc did not improve from 0.68065\n","Epoch 44/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9598 - acc: 0.6039 - val_loss: 0.8997 - val_acc: 0.6290\n","\n","Epoch 00044: val_acc did not improve from 0.68065\n","Epoch 45/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9503 - acc: 0.6020 - val_loss: 0.9246 - val_acc: 0.6452\n","\n","Epoch 00045: val_acc did not improve from 0.68065\n","Epoch 46/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9179 - acc: 0.6127 - val_loss: 0.9295 - val_acc: 0.6290\n","\n","Epoch 00046: val_acc did not improve from 0.68065\n","Epoch 47/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9093 - acc: 0.6049 - val_loss: 1.0486 - val_acc: 0.5871\n","\n","Epoch 00047: val_acc did not improve from 0.68065\n","Epoch 48/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.1619 - acc: 0.5063 - val_loss: 0.9257 - val_acc: 0.6839\n","\n","Epoch 00048: val_acc improved from 0.68065 to 0.68387, saving model to ./cnn_spectrogram_female.h5\n","Epoch 49/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9983 - acc: 0.5639 - val_loss: 0.9377 - val_acc: 0.6226\n","\n","Epoch 00049: val_acc did not improve from 0.68387\n","Epoch 50/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9365 - acc: 0.6166 - val_loss: 0.9764 - val_acc: 0.5871\n","\n","Epoch 00050: val_acc did not improve from 0.68387\n","Epoch 51/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9254 - acc: 0.5873 - val_loss: 0.8553 - val_acc: 0.6613\n","\n","Epoch 00051: val_acc did not improve from 0.68387\n","Epoch 52/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9250 - acc: 0.6049 - val_loss: 0.8895 - val_acc: 0.6710\n","\n","Epoch 00052: val_acc did not improve from 0.68387\n","Epoch 53/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8618 - acc: 0.6322 - val_loss: 0.8784 - val_acc: 0.6710\n","\n","Epoch 00053: val_acc did not improve from 0.68387\n","Epoch 54/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8971 - acc: 0.6263 - val_loss: 1.0309 - val_acc: 0.5710\n","\n","Epoch 00054: val_acc did not improve from 0.68387\n","Epoch 55/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8865 - acc: 0.6312 - val_loss: 0.9172 - val_acc: 0.6194\n","\n","Epoch 00055: val_acc did not improve from 0.68387\n","Epoch 56/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9062 - acc: 0.6039 - val_loss: 0.8880 - val_acc: 0.6677\n","\n","Epoch 00056: val_acc did not improve from 0.68387\n","Epoch 57/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8642 - acc: 0.6293 - val_loss: 0.9092 - val_acc: 0.6323\n","\n","Epoch 00057: val_acc did not improve from 0.68387\n","Epoch 58/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9634 - acc: 0.5893 - val_loss: 1.0131 - val_acc: 0.5194\n","\n","Epoch 00058: val_acc did not improve from 0.68387\n","Epoch 59/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9524 - acc: 0.5990 - val_loss: 0.9853 - val_acc: 0.6000\n","\n","Epoch 00059: val_acc did not improve from 0.68387\n","Epoch 60/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8748 - acc: 0.6312 - val_loss: 0.9291 - val_acc: 0.6097\n","\n","Epoch 00060: val_acc did not improve from 0.68387\n","Epoch 61/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9539 - acc: 0.6156 - val_loss: 0.8869 - val_acc: 0.6742\n","\n","Epoch 00061: val_acc did not improve from 0.68387\n","Epoch 62/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9578 - acc: 0.5854 - val_loss: 0.9312 - val_acc: 0.6258\n","\n","Epoch 00062: val_acc did not improve from 0.68387\n","Epoch 63/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8981 - acc: 0.6283 - val_loss: 0.9418 - val_acc: 0.6258\n","\n","Epoch 00063: val_acc did not improve from 0.68387\n","Epoch 64/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9108 - acc: 0.6146 - val_loss: 0.8393 - val_acc: 0.6839\n","\n","Epoch 00064: val_acc did not improve from 0.68387\n","Epoch 65/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8715 - acc: 0.6254 - val_loss: 0.9029 - val_acc: 0.6129\n","\n","Epoch 00065: val_acc did not improve from 0.68387\n","Epoch 66/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8785 - acc: 0.6273 - val_loss: 0.8828 - val_acc: 0.6581\n","\n","Epoch 00066: val_acc did not improve from 0.68387\n","Epoch 67/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8563 - acc: 0.6546 - val_loss: 0.9018 - val_acc: 0.6452\n","\n","Epoch 00067: val_acc did not improve from 0.68387\n","Epoch 68/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8345 - acc: 0.6400 - val_loss: 0.8705 - val_acc: 0.6806\n","\n","Epoch 00068: val_acc did not improve from 0.68387\n","Epoch 69/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8608 - acc: 0.6322 - val_loss: 0.8582 - val_acc: 0.6774\n","\n","Epoch 00069: val_acc did not improve from 0.68387\n","Epoch 70/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8577 - acc: 0.6390 - val_loss: 0.9170 - val_acc: 0.6129\n","\n","Epoch 00070: val_acc did not improve from 0.68387\n","Epoch 71/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0418 - acc: 0.5434 - val_loss: 0.9695 - val_acc: 0.6194\n","\n","Epoch 00071: val_acc did not improve from 0.68387\n","Epoch 72/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.0124 - acc: 0.5815 - val_loss: 0.9658 - val_acc: 0.6161\n","\n","Epoch 00072: val_acc did not improve from 0.68387\n","Epoch 73/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9158 - acc: 0.6205 - val_loss: 1.1983 - val_acc: 0.5226\n","\n","Epoch 00073: val_acc did not improve from 0.68387\n","Epoch 74/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 1.1731 - acc: 0.5307 - val_loss: 0.9595 - val_acc: 0.6194\n","\n","Epoch 00074: val_acc did not improve from 0.68387\n","Epoch 75/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9259 - acc: 0.6059 - val_loss: 0.8881 - val_acc: 0.6710\n","\n","Epoch 00075: val_acc did not improve from 0.68387\n","Epoch 76/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8925 - acc: 0.6293 - val_loss: 0.8892 - val_acc: 0.6484\n","\n","Epoch 00076: val_acc did not improve from 0.68387\n","Epoch 77/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8654 - acc: 0.6098 - val_loss: 0.9117 - val_acc: 0.6645\n","\n","Epoch 00077: val_acc did not improve from 0.68387\n","Epoch 78/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8977 - acc: 0.6156 - val_loss: 0.9265 - val_acc: 0.6452\n","\n","Epoch 00078: val_acc did not improve from 0.68387\n","Epoch 79/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8924 - acc: 0.6127 - val_loss: 0.9648 - val_acc: 0.6032\n","\n","Epoch 00079: val_acc did not improve from 0.68387\n","Epoch 80/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8965 - acc: 0.6185 - val_loss: 0.8730 - val_acc: 0.6484\n","\n","Epoch 00080: val_acc did not improve from 0.68387\n","Epoch 81/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8730 - acc: 0.6498 - val_loss: 0.8814 - val_acc: 0.6516\n","\n","Epoch 00081: val_acc did not improve from 0.68387\n","Epoch 82/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8605 - acc: 0.6351 - val_loss: 0.9498 - val_acc: 0.6129\n","\n","Epoch 00082: val_acc did not improve from 0.68387\n","Epoch 83/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8645 - acc: 0.6254 - val_loss: 0.9948 - val_acc: 0.5613\n","\n","Epoch 00083: val_acc did not improve from 0.68387\n","Epoch 84/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8357 - acc: 0.6429 - val_loss: 0.9020 - val_acc: 0.6613\n","\n","Epoch 00084: val_acc did not improve from 0.68387\n","Epoch 85/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8536 - acc: 0.6468 - val_loss: 0.8596 - val_acc: 0.6613\n","\n","Epoch 00085: val_acc did not improve from 0.68387\n","Epoch 86/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8963 - acc: 0.6312 - val_loss: 0.9156 - val_acc: 0.6355\n","\n","Epoch 00086: val_acc did not improve from 0.68387\n","Epoch 87/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8499 - acc: 0.6332 - val_loss: 0.8515 - val_acc: 0.6710\n","\n","Epoch 00087: val_acc did not improve from 0.68387\n","Epoch 88/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8465 - acc: 0.6371 - val_loss: 0.9047 - val_acc: 0.6355\n","\n","Epoch 00088: val_acc did not improve from 0.68387\n","Epoch 89/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8309 - acc: 0.6449 - val_loss: 0.9048 - val_acc: 0.6452\n","\n","Epoch 00089: val_acc did not improve from 0.68387\n","Epoch 90/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8239 - acc: 0.6556 - val_loss: 1.1488 - val_acc: 0.5290\n","\n","Epoch 00090: val_acc did not improve from 0.68387\n","Epoch 91/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8646 - acc: 0.6429 - val_loss: 1.0543 - val_acc: 0.5484\n","\n","Epoch 00091: val_acc did not improve from 0.68387\n","Epoch 92/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8839 - acc: 0.6088 - val_loss: 0.9591 - val_acc: 0.6097\n","\n","Epoch 00092: val_acc did not improve from 0.68387\n","Epoch 93/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8397 - acc: 0.6449 - val_loss: 0.9190 - val_acc: 0.6226\n","\n","Epoch 00093: val_acc did not improve from 0.68387\n","Epoch 94/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8235 - acc: 0.6624 - val_loss: 0.9262 - val_acc: 0.6097\n","\n","Epoch 00094: val_acc did not improve from 0.68387\n","Epoch 95/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8589 - acc: 0.6312 - val_loss: 0.8706 - val_acc: 0.6710\n","\n","Epoch 00095: val_acc did not improve from 0.68387\n","Epoch 96/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8305 - acc: 0.6371 - val_loss: 0.9174 - val_acc: 0.6097\n","\n","Epoch 00096: val_acc did not improve from 0.68387\n","Epoch 97/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8292 - acc: 0.6517 - val_loss: 0.9322 - val_acc: 0.5710\n","\n","Epoch 00097: val_acc did not improve from 0.68387\n","Epoch 98/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8067 - acc: 0.6556 - val_loss: 1.1409 - val_acc: 0.5484\n","\n","Epoch 00098: val_acc did not improve from 0.68387\n","Epoch 99/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.9507 - acc: 0.6039 - val_loss: 1.0369 - val_acc: 0.5645\n","\n","Epoch 00099: val_acc did not improve from 0.68387\n","Epoch 100/100\n","1025/1025 [==============================] - 23s 23ms/step - loss: 0.8531 - acc: 0.6312 - val_loss: 0.8936 - val_acc: 0.6290\n","\n","Epoch 00100: val_acc did not improve from 0.68387\n"],"name":"stdout"}]}]}