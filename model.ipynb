{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2eWlqu5oOGR5","colab_type":"code","outputId":"6708628d-5233-4fe8-80b3-5270e0deaae3","executionInfo":{"status":"ok","timestamp":1558674096363,"user_tz":-330,"elapsed":39727,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YOwUmTTgOKK-","colab_type":"code","outputId":"fb8dc1a3-ccf0-40c8-e919-d076a27bbb78","executionInfo":{"status":"ok","timestamp":1558674123889,"user_tz":-330,"elapsed":1453,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/ML Projects/Emotion Recogition/code/python_files"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/ML Projects/Emotion Recogition/code/python_files\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pO4SIxQTOKIF","colab_type":"code","outputId":"aa4804af-f7b4-4b70-f62c-a0d98ebbb032","executionInfo":{"status":"ok","timestamp":1558674131466,"user_tz":-330,"elapsed":5252,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import os\n","import sys\n","import pandas as pd\n","\n","import wave\n","\n","import keras\n","from keras.models import Sequential, Model\n","from keras.layers.core import Dense, Activation\n","from keras.layers import LSTM, Input, Flatten,Dropout,GlobalAveragePooling2D,MaxPooling2D\n","from keras.layers.convolutional import Conv2D\n","from keras.models import load_model\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing import sequence\n","from scipy import signal\n","import matplotlib.pyplot as plot\n","from helper import *\n","from sklearn.preprocessing import LabelEncoder\n","from keras import backend as K\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"6Ju8pMtS15__","colab_type":"code","colab":{}},"source":["from helper import *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"koWvKufzOKE_","colab_type":"code","colab":{}},"source":["\n","code_path = os.path.dirname(os.path.realpath(os.getcwd()))\n","emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n","data_path = code_path + \"/../data/sessions/\"\n","sessions = ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']\n","framerate = 16000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7Nr_oXDOKDa","colab_type":"code","colab":{}},"source":["import pickle\n","with open(code_path + '/../data/'+'data_collected.pickle', 'rb') as handle:\n","    data2 = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HR1K6NnEQwsG","colab_type":"code","outputId":"aec50156-85eb-4f51-fd76-6b40d9257804","executionInfo":{"status":"ok","timestamp":1556167548105,"user_tz":-330,"elapsed":6861,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":176}},"source":["!pip install python_speech_features  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting python_speech_features\n","  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n","Building wheels for collected packages: python-speech-features\n","  Building wheel for python-speech-features (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n","Successfully built python-speech-features\n","Installing collected packages: python-speech-features\n","Successfully installed python-speech-features-0.6\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ooDAcWDBQ7Nm","colab_type":"code","colab":{}},"source":["from python_speech_features import mfcc\n","from python_speech_features import logfbank\n","import scipy.io.wavfile as wav"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"odDNiRMwOKAD","colab_type":"code","outputId":"4740a667-4ca6-4568-e15e-5bb72a3f8677","executionInfo":{"status":"ok","timestamp":1558674184522,"user_tz":-330,"elapsed":12038,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["X_train = []\n","X_test = []\n","Y_train = []\n","Y_test = []\n","fs = 16e3\n","counter = 0\n","counter1 = 0\n","for ses_mod in data2:\n","    if 'impro' in ses_mod['id'] and ses_mod['emotion'] in emotions_used:\n","        f, t, Sxx = signal.spectrogram(ses_mod['signal'], fs, nperseg=400,noverlap=200)\n","        #fbank_feat = logfbank(ses_mod['signal'],nfilt=40)\n","        #Sxx = np.transpose(fbank_feat)\n","        Sxx = pad_sequence_into_array(Sxx,maxlen=300,value=0)\n","        \n","        if ses_mod['id'][:5]==\"Ses05\":\n","            counter+=1\n","            X_test.append(Sxx)\n","            Y_test.append(ses_mod['emotion'])\n","        else:\n","            counter1+=1\n","            X_train.append(Sxx)\n","            Y_train.append(ses_mod['emotion'])\n","        \n","print(counter)\n","print(counter1)\n","\n","X_test = np.array(X_test)\n","X_train = np.array(X_train)\n","print(X_train.shape)\n","print(X_test.shape)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["625\n","2034\n","(2034, 201, 300)\n","(625, 201, 300)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BUqoBSGu0S9u","colab_type":"code","outputId":"68e8430c-28fc-48e5-ed35-4c9655a5a5cc","executionInfo":{"status":"error","timestamp":1556167616076,"user_tz":-330,"elapsed":1259,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":167}},"source":["print(Y_train.shape)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-623d374537fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"]}]},{"cell_type":"code","metadata":{"id":"t7TIAuwjo0k1","colab_type":"code","colab":{}},"source":["y  = pd.get_dummies(Y_train+Y_test)\n","y_train = y[0:len(Y_train)]\n","y_test = y[len(Y_train):]\n","y_train = np.array(y_train)\n","y_test = np.array(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AtW62R81jp8n","colab_type":"code","colab":{}},"source":["def lstm_model():\n","    model = Sequential()\n","    model.add(LSTM(256, return_sequences=True, input_shape=(201, 300)))\n","    model.add(LSTM(256, return_sequences=False))\n","    model.add(Dense(512))\n","    model.add(Activation('relu'))\n","    model.add(Dense(4))\n","    model.add(Activation('softmax'))\n","\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BS1Ej-KVQPqE","colab_type":"code","colab":{}},"source":["def categorical_focal_loss(gamma=2., alpha=.25):\n","    \"\"\"\n","    Softmax version of focal loss.\n","           m\n","      FL = ∑  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n","          c=1\n","      where m = number of classes, c = class and o = observation\n","    Parameters:\n","      alpha -- the same as weighing factor in balanced cross entropy\n","      gamma -- focusing parameter for modulating factor (1-p)\n","    Default value:\n","      gamma -- 2.0 as mentioned in the paper\n","      alpha -- 0.25 as mentioned in the paper\n","    References:\n","        Official paper: https://arxiv.org/pdf/1708.02002.pdf\n","        https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n","    Usage:\n","     model.compile(loss=[categorical_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n","    \"\"\"\n","    def categorical_focal_loss_fixed(y_true, y_pred):\n","        \"\"\"\n","        :param y_true: A tensor of the same shape as `y_pred`\n","        :param y_pred: A tensor resulting from a softmax\n","        :return: Output tensor.\n","        \"\"\"\n","\n","        # Scale predictions so that the class probas of each sample sum to 1\n","        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n","\n","        # Clip the prediction value to prevent NaN's and Inf's\n","        epsilon = K.epsilon()\n","        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n","\n","        # Calculate Cross Entropy\n","        cross_entropy = -y_true * K.log(y_pred)\n","\n","        # Calculate Focal Loss\n","        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n","\n","        # Sum the losses in mini_batch\n","        return K.sum(loss, axis=1)\n","\n","    return categorical_focal_loss_fixed"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZrOFtkLvjrn7","colab_type":"code","outputId":"16082dc4-3296-48c5-9d6f-aea39b582334","executionInfo":{"status":"ok","timestamp":1550777817244,"user_tz":-330,"elapsed":1857,"user":{"displayName":"Rahul Kumar","photoUrl":"","userId":"17651844698397356196"}},"colab":{"base_uri":"https://localhost:8080/","height":406}},"source":["model = lstm_model()\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_1 (LSTM)                (None, 201, 256)          570368    \n","_________________________________________________________________\n","lstm_2 (LSTM)                (None, 256)               525312    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               131584    \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4)                 2052      \n","_________________________________________________________________\n","activation_2 (Activation)    (None, 4)                 0         \n","=================================================================\n","Total params: 1,229,316\n","Trainable params: 1,229,316\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"McJH7czDjxaQ","colab_type":"code","outputId":"f448c8b0-50b6-4500-d4e2-ebfc48678122","executionInfo":{"status":"ok","timestamp":1550779939415,"user_tz":-330,"elapsed":2115837,"user":{"displayName":"Rahul Kumar","photoUrl":"","userId":"17651844698397356196"}},"colab":{"base_uri":"https://localhost:8080/","height":1482}},"source":["hist = model.fit(X_train,y_train, \n","                 batch_size=32, nb_epoch=40, verbose=1, shuffle = True, \n","                 validation_data=(X_test,y_test))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 2034 samples, validate on 625 samples\n","Epoch 1/40\n","2034/2034 [==============================] - 57s 28ms/step - loss: 1.2499 - acc: 0.4326 - val_loss: 1.1600 - val_acc: 0.4704\n","Epoch 2/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 1.1487 - acc: 0.4936 - val_loss: 1.1249 - val_acc: 0.4864\n","Epoch 3/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 1.0938 - acc: 0.5103 - val_loss: 1.1629 - val_acc: 0.4864\n","Epoch 4/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 1.0491 - acc: 0.5590 - val_loss: 1.1536 - val_acc: 0.4912\n","Epoch 5/40\n","2034/2034 [==============================] - 54s 26ms/step - loss: 1.0086 - acc: 0.5831 - val_loss: 1.1460 - val_acc: 0.5056\n","Epoch 6/40\n","2034/2034 [==============================] - 54s 26ms/step - loss: 0.9928 - acc: 0.5919 - val_loss: 1.1286 - val_acc: 0.4976\n","Epoch 7/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.9415 - acc: 0.6268 - val_loss: 1.1749 - val_acc: 0.5088\n","Epoch 8/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.8946 - acc: 0.6578 - val_loss: 1.2124 - val_acc: 0.5088\n","Epoch 9/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.8376 - acc: 0.6755 - val_loss: 1.2149 - val_acc: 0.5296\n","Epoch 10/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.7693 - acc: 0.7065 - val_loss: 1.2838 - val_acc: 0.4944\n","Epoch 11/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.7260 - acc: 0.7193 - val_loss: 1.4001 - val_acc: 0.4736\n","Epoch 12/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.7300 - acc: 0.7203 - val_loss: 1.3469 - val_acc: 0.4896\n","Epoch 13/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.6435 - acc: 0.7527 - val_loss: 1.4862 - val_acc: 0.4736\n","Epoch 14/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.6113 - acc: 0.7689 - val_loss: 1.5235 - val_acc: 0.5040\n","Epoch 15/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.6229 - acc: 0.7552 - val_loss: 1.4199 - val_acc: 0.5056\n","Epoch 16/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.5361 - acc: 0.7925 - val_loss: 1.4964 - val_acc: 0.4896\n","Epoch 17/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.5420 - acc: 0.7915 - val_loss: 1.5324 - val_acc: 0.4816\n","Epoch 18/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.5168 - acc: 0.8142 - val_loss: 1.7124 - val_acc: 0.4592\n","Epoch 19/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.4781 - acc: 0.8092 - val_loss: 1.6752 - val_acc: 0.4928\n","Epoch 20/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.4077 - acc: 0.8392 - val_loss: 1.8061 - val_acc: 0.4496\n","Epoch 21/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.3586 - acc: 0.8618 - val_loss: 1.9902 - val_acc: 0.4848\n","Epoch 22/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.3703 - acc: 0.8550 - val_loss: 2.0626 - val_acc: 0.4432\n","Epoch 23/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.3894 - acc: 0.8559 - val_loss: 1.7213 - val_acc: 0.4736\n","Epoch 24/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.3548 - acc: 0.8618 - val_loss: 2.3893 - val_acc: 0.4160\n","Epoch 25/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.3499 - acc: 0.8687 - val_loss: 2.3158 - val_acc: 0.4160\n","Epoch 26/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.3420 - acc: 0.8702 - val_loss: 2.1062 - val_acc: 0.4032\n","Epoch 27/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.3061 - acc: 0.8889 - val_loss: 2.3230 - val_acc: 0.4320\n","Epoch 28/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.2892 - acc: 0.8972 - val_loss: 2.0691 - val_acc: 0.4128\n","Epoch 29/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.2325 - acc: 0.9169 - val_loss: 2.5804 - val_acc: 0.4208\n","Epoch 30/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.2556 - acc: 0.9130 - val_loss: 2.2819 - val_acc: 0.4592\n","Epoch 31/40\n","2034/2034 [==============================] - 52s 25ms/step - loss: 0.2476 - acc: 0.9194 - val_loss: 2.1463 - val_acc: 0.4560\n","Epoch 32/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.2246 - acc: 0.9258 - val_loss: 2.4883 - val_acc: 0.4096\n","Epoch 33/40\n","2034/2034 [==============================] - 52s 26ms/step - loss: 0.2176 - acc: 0.9267 - val_loss: 2.1882 - val_acc: 0.4528\n","Epoch 34/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.2590 - acc: 0.9090 - val_loss: 2.2512 - val_acc: 0.4400\n","Epoch 35/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.2463 - acc: 0.9135 - val_loss: 2.3518 - val_acc: 0.4496\n","Epoch 36/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.2211 - acc: 0.9297 - val_loss: 2.0667 - val_acc: 0.4864\n","Epoch 37/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.2297 - acc: 0.9248 - val_loss: 2.3450 - val_acc: 0.4400\n","Epoch 38/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.2039 - acc: 0.9302 - val_loss: 2.2446 - val_acc: 0.4528\n","Epoch 39/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.1840 - acc: 0.9351 - val_loss: 2.4307 - val_acc: 0.4032\n","Epoch 40/40\n","2034/2034 [==============================] - 53s 26ms/step - loss: 0.1993 - acc: 0.9346 - val_loss: 2.6934 - val_acc: 0.4288\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e9xkh_B_T82m","colab_type":"code","colab":{}},"source":["X_train = X_train.reshape(-1,201,300,1)\n","X_test = X_test.reshape(-1,201,300,1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"y3NkoywIOJ7L","colab_type":"code","colab":{}},"source":["def make_model():\n","    in_layer = Input(shape=(201, 300,1))\n","    x = Conv2D(32,(5,5), activation = 'elu')(in_layer)  \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(64,(5,5), activation = 'elu')(x)         \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(128, (5,5))(x)                           \n","    x = GlobalAveragePooling2D()(x)                    \n","    x = Dense(64,activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(4, activation = \"softmax\")(x) \n","    model = Model(inputs = in_layer, outputs=output_layer)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zKysFc4QOJ51","colab_type":"code","colab":{}},"source":["model  =  make_model()\n","model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\",\n","                    metrics=[\"accuracy\"])\n","hist = model.fit(X_train, y_train, \n","                 batch_size=32, validation_data=(X_test,y_test),nb_epoch=100, verbose=1, shuffle = True, \n","                )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bXD5GzRcQxBK","colab_type":"code","outputId":"f5124089-6127-4895-9e93-1dcb87d39ff2","executionInfo":{"status":"ok","timestamp":1554708253267,"user_tz":-330,"elapsed":8202982,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":3542}},"source":["model  =  make_model()\n","model.compile(optimizer = \"adam\", loss = [categorical_focal_loss(gamma=2., alpha=.25)],\n","                    metrics=[\"accuracy\"])\n","hist = model.fit(X_train, y_train, \n","                 batch_size=32, validation_data=(X_test,y_test),nb_epoch=100, verbose=1, shuffle = True, \n","                )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \"\"\"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 2034 samples, validate on 625 samples\n","Epoch 1/100\n","2034/2034 [==============================] - 86s 42ms/step - loss: 1.3047 - acc: 0.4218 - val_loss: 0.1865 - val_acc: 0.1888\n","Epoch 2/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.2371 - acc: 0.3943 - val_loss: 0.1497 - val_acc: 0.5360\n","Epoch 3/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1626 - acc: 0.4676 - val_loss: 0.1395 - val_acc: 0.5024\n","Epoch 4/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1442 - acc: 0.4921 - val_loss: 0.1345 - val_acc: 0.5392\n","Epoch 5/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1399 - acc: 0.5064 - val_loss: 0.1311 - val_acc: 0.5664\n","Epoch 6/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1357 - acc: 0.4936 - val_loss: 0.1317 - val_acc: 0.5472\n","Epoch 7/100\n","2034/2034 [==============================] - 81s 40ms/step - loss: 0.1342 - acc: 0.5143 - val_loss: 0.1295 - val_acc: 0.5632\n","Epoch 8/100\n","2034/2034 [==============================] - 81s 40ms/step - loss: 0.1312 - acc: 0.5020 - val_loss: 0.1324 - val_acc: 0.5360\n","Epoch 9/100\n","2034/2034 [==============================] - 81s 40ms/step - loss: 0.1348 - acc: 0.5079 - val_loss: 0.1353 - val_acc: 0.5312\n","Epoch 10/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1322 - acc: 0.5143 - val_loss: 0.1326 - val_acc: 0.5456\n","Epoch 11/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1306 - acc: 0.5177 - val_loss: 0.1278 - val_acc: 0.5664\n","Epoch 12/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1279 - acc: 0.5246 - val_loss: 0.1394 - val_acc: 0.5008\n","Epoch 13/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1334 - acc: 0.5187 - val_loss: 0.1322 - val_acc: 0.5392\n","Epoch 14/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1265 - acc: 0.5364 - val_loss: 0.1227 - val_acc: 0.5632\n","Epoch 15/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1240 - acc: 0.5310 - val_loss: 0.1231 - val_acc: 0.5648\n","Epoch 16/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1279 - acc: 0.5256 - val_loss: 0.1331 - val_acc: 0.5712\n","Epoch 17/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1290 - acc: 0.5285 - val_loss: 0.1233 - val_acc: 0.5904\n","Epoch 18/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1256 - acc: 0.5315 - val_loss: 0.1383 - val_acc: 0.5344\n","Epoch 19/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1267 - acc: 0.5261 - val_loss: 0.1300 - val_acc: 0.5728\n","Epoch 20/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1245 - acc: 0.5246 - val_loss: 0.1233 - val_acc: 0.5568\n","Epoch 21/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1263 - acc: 0.5187 - val_loss: 0.1269 - val_acc: 0.5568\n","Epoch 22/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1278 - acc: 0.5275 - val_loss: 0.1280 - val_acc: 0.5728\n","Epoch 23/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1269 - acc: 0.5221 - val_loss: 0.1367 - val_acc: 0.5360\n","Epoch 24/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1289 - acc: 0.5202 - val_loss: 0.1314 - val_acc: 0.5600\n","Epoch 25/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1287 - acc: 0.5162 - val_loss: 0.1221 - val_acc: 0.5744\n","Epoch 26/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1243 - acc: 0.5270 - val_loss: 0.1231 - val_acc: 0.5680\n","Epoch 27/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1234 - acc: 0.5310 - val_loss: 0.1199 - val_acc: 0.6016\n","Epoch 28/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1240 - acc: 0.5329 - val_loss: 0.1217 - val_acc: 0.6000\n","Epoch 29/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1232 - acc: 0.5344 - val_loss: 0.1249 - val_acc: 0.5696\n","Epoch 30/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1213 - acc: 0.5344 - val_loss: 0.1292 - val_acc: 0.5152\n","Epoch 31/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1224 - acc: 0.5433 - val_loss: 0.1219 - val_acc: 0.5936\n","Epoch 32/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1280 - acc: 0.5231 - val_loss: 0.1373 - val_acc: 0.5376\n","Epoch 33/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1242 - acc: 0.5305 - val_loss: 0.1215 - val_acc: 0.6000\n","Epoch 34/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1198 - acc: 0.5487 - val_loss: 0.1217 - val_acc: 0.5808\n","Epoch 35/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1242 - acc: 0.5428 - val_loss: 0.1300 - val_acc: 0.5744\n","Epoch 36/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1269 - acc: 0.5374 - val_loss: 0.1332 - val_acc: 0.5472\n","Epoch 37/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1260 - acc: 0.5216 - val_loss: 0.1235 - val_acc: 0.5840\n","Epoch 38/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1228 - acc: 0.5423 - val_loss: 0.1217 - val_acc: 0.5856\n","Epoch 39/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1248 - acc: 0.5226 - val_loss: 0.1223 - val_acc: 0.5952\n","Epoch 40/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1247 - acc: 0.5206 - val_loss: 0.1312 - val_acc: 0.5696\n","Epoch 41/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1229 - acc: 0.5403 - val_loss: 0.1230 - val_acc: 0.5712\n","Epoch 42/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1219 - acc: 0.5339 - val_loss: 0.1235 - val_acc: 0.5824\n","Epoch 43/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1245 - acc: 0.5477 - val_loss: 0.1362 - val_acc: 0.5136\n","Epoch 44/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1240 - acc: 0.5251 - val_loss: 0.1224 - val_acc: 0.5888\n","Epoch 45/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1222 - acc: 0.5300 - val_loss: 0.1210 - val_acc: 0.5632\n","Epoch 46/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1238 - acc: 0.5438 - val_loss: 0.1290 - val_acc: 0.5648\n","Epoch 47/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1202 - acc: 0.5438 - val_loss: 0.1228 - val_acc: 0.5920\n","Epoch 48/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1258 - acc: 0.5265 - val_loss: 0.1385 - val_acc: 0.5536\n","Epoch 49/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1230 - acc: 0.5398 - val_loss: 0.1231 - val_acc: 0.5776\n","Epoch 50/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1264 - acc: 0.5265 - val_loss: 0.1285 - val_acc: 0.5312\n","Epoch 51/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1269 - acc: 0.5310 - val_loss: 0.1222 - val_acc: 0.5696\n","Epoch 52/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1212 - acc: 0.5364 - val_loss: 0.1236 - val_acc: 0.5504\n","Epoch 53/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1193 - acc: 0.5487 - val_loss: 0.1189 - val_acc: 0.5792\n","Epoch 54/100\n","2034/2034 [==============================] - 81s 40ms/step - loss: 0.1218 - acc: 0.5383 - val_loss: 0.1230 - val_acc: 0.5504\n","Epoch 55/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1196 - acc: 0.5457 - val_loss: 0.1234 - val_acc: 0.5840\n","Epoch 56/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1211 - acc: 0.5182 - val_loss: 0.1276 - val_acc: 0.5504\n","Epoch 57/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1204 - acc: 0.5339 - val_loss: 0.1219 - val_acc: 0.5680\n","Epoch 58/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1234 - acc: 0.5388 - val_loss: 0.1229 - val_acc: 0.5696\n","Epoch 59/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1278 - acc: 0.5462 - val_loss: 0.1249 - val_acc: 0.5888\n","Epoch 60/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1244 - acc: 0.5246 - val_loss: 0.1254 - val_acc: 0.5728\n","Epoch 61/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1223 - acc: 0.5300 - val_loss: 0.1225 - val_acc: 0.5856\n","Epoch 62/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1268 - acc: 0.5388 - val_loss: 0.1246 - val_acc: 0.5696\n","Epoch 63/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1256 - acc: 0.5359 - val_loss: 0.1244 - val_acc: 0.5600\n","Epoch 64/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1227 - acc: 0.5383 - val_loss: 0.1249 - val_acc: 0.5744\n","Epoch 65/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1201 - acc: 0.5487 - val_loss: 0.1233 - val_acc: 0.5680\n","Epoch 66/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1183 - acc: 0.5418 - val_loss: 0.1287 - val_acc: 0.5808\n","Epoch 67/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1277 - acc: 0.5177 - val_loss: 0.1246 - val_acc: 0.5888\n","Epoch 68/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1212 - acc: 0.5236 - val_loss: 0.1279 - val_acc: 0.5936\n","Epoch 69/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1245 - acc: 0.5256 - val_loss: 0.1220 - val_acc: 0.5872\n","Epoch 70/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1230 - acc: 0.5477 - val_loss: 0.1282 - val_acc: 0.5920\n","Epoch 71/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1201 - acc: 0.5310 - val_loss: 0.1234 - val_acc: 0.5936\n","Epoch 72/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1225 - acc: 0.5462 - val_loss: 0.1235 - val_acc: 0.5840\n","Epoch 73/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1188 - acc: 0.5393 - val_loss: 0.1339 - val_acc: 0.5904\n","Epoch 74/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1262 - acc: 0.5300 - val_loss: 0.1302 - val_acc: 0.5616\n","Epoch 75/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1237 - acc: 0.5236 - val_loss: 0.1236 - val_acc: 0.5776\n","Epoch 76/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1252 - acc: 0.5320 - val_loss: 0.1224 - val_acc: 0.5968\n","Epoch 77/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1247 - acc: 0.5280 - val_loss: 0.1207 - val_acc: 0.5920\n","Epoch 78/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.2067 - acc: 0.5054 - val_loss: 0.1251 - val_acc: 0.5632\n","Epoch 79/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1264 - acc: 0.5202 - val_loss: 0.1263 - val_acc: 0.5712\n","Epoch 80/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1216 - acc: 0.5236 - val_loss: 0.1219 - val_acc: 0.5696\n","Epoch 81/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1194 - acc: 0.5315 - val_loss: 0.1204 - val_acc: 0.5840\n","Epoch 82/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1263 - acc: 0.5398 - val_loss: 0.1230 - val_acc: 0.5872\n","Epoch 83/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1197 - acc: 0.5339 - val_loss: 0.1250 - val_acc: 0.6032\n","Epoch 84/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1205 - acc: 0.5334 - val_loss: 0.1245 - val_acc: 0.5680\n","Epoch 85/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1176 - acc: 0.5423 - val_loss: 0.1195 - val_acc: 0.6000\n","Epoch 86/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1178 - acc: 0.5320 - val_loss: 0.1253 - val_acc: 0.5760\n","Epoch 87/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1213 - acc: 0.5315 - val_loss: 0.1224 - val_acc: 0.5792\n","Epoch 88/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1170 - acc: 0.5521 - val_loss: 0.1197 - val_acc: 0.5840\n","Epoch 89/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1151 - acc: 0.5477 - val_loss: 0.1251 - val_acc: 0.5840\n","Epoch 90/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1157 - acc: 0.5388 - val_loss: 0.1210 - val_acc: 0.5936\n","Epoch 91/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1209 - acc: 0.5359 - val_loss: 0.1196 - val_acc: 0.5888\n","Epoch 92/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1151 - acc: 0.5501 - val_loss: 0.1240 - val_acc: 0.5936\n","Epoch 93/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1163 - acc: 0.5482 - val_loss: 0.1218 - val_acc: 0.6032\n","Epoch 94/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1202 - acc: 0.5492 - val_loss: 0.1343 - val_acc: 0.5536\n","Epoch 95/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1216 - acc: 0.5329 - val_loss: 0.1329 - val_acc: 0.5632\n","Epoch 96/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1184 - acc: 0.5231 - val_loss: 0.1306 - val_acc: 0.5536\n","Epoch 97/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1169 - acc: 0.5482 - val_loss: 0.1219 - val_acc: 0.6000\n","Epoch 98/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1157 - acc: 0.5447 - val_loss: 0.1227 - val_acc: 0.6208\n","Epoch 99/100\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.1178 - acc: 0.5428 - val_loss: 0.1214 - val_acc: 0.6048\n","Epoch 100/100\n","2034/2034 [==============================] - 81s 40ms/step - loss: 0.1189 - acc: 0.5251 - val_loss: 0.1237 - val_acc: 0.5760\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VGshnSiEOJzv","colab_type":"code","colab":{}},"source":["def make_model():\n","    in_layer = Input(shape=(201, 300,1))\n","    x = Conv2D(16,(5,5), activation = 'elu')(in_layer)  \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(32,(5,5), activation = 'elu')(x)         \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(64, (5,5))(x)                           \n","    x = GlobalAveragePooling2D()(x)                     \n","    x = Dense(64,activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(4, activation = \"softmax\")(x) \n","    model = Model(inputs = in_layer, outputs=output_layer)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xAXD8K8p0Oud","colab_type":"code","outputId":"10134a51-0e53-47dd-d32e-881804bef9e6","executionInfo":{"status":"ok","timestamp":1550348876786,"user_tz":-330,"elapsed":2982496,"user":{"displayName":"Rahul Kumar","photoUrl":"","userId":"17651844698397356196"}},"colab":{"base_uri":"https://localhost:8080/","height":3427}},"source":["model  =  make_model()\n","model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\",\n","                    metrics=[\"accuracy\"])\n","hist = model.fit(X_train, y_train, \n","                 batch_size=32, validation_data=(X_test,y_test),nb_epoch=100, verbose=1, shuffle = True, \n","                )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \"\"\"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 2034 samples, validate on 625 samples\n","Epoch 1/100\n","2034/2034 [==============================] - 35s 17ms/step - loss: 5.0466 - acc: 0.4086 - val_loss: 1.8293 - val_acc: 0.2176\n","Epoch 2/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.6041 - acc: 0.4149 - val_loss: 1.1262 - val_acc: 0.5040\n","Epoch 3/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.2910 - acc: 0.4543 - val_loss: 1.0889 - val_acc: 0.5264\n","Epoch 4/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.1510 - acc: 0.4877 - val_loss: 1.0663 - val_acc: 0.5584\n","Epoch 5/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.1289 - acc: 0.5010 - val_loss: 1.0708 - val_acc: 0.5648\n","Epoch 6/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.1168 - acc: 0.5084 - val_loss: 1.0649 - val_acc: 0.5184\n","Epoch 7/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0890 - acc: 0.5177 - val_loss: 1.0439 - val_acc: 0.5824\n","Epoch 8/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0828 - acc: 0.5123 - val_loss: 1.0313 - val_acc: 0.5552\n","Epoch 9/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0803 - acc: 0.5128 - val_loss: 1.0595 - val_acc: 0.5296\n","Epoch 10/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0711 - acc: 0.5147 - val_loss: 1.0557 - val_acc: 0.5296\n","Epoch 11/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0722 - acc: 0.5202 - val_loss: 1.0400 - val_acc: 0.5840\n","Epoch 12/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0360 - acc: 0.5147 - val_loss: 1.0119 - val_acc: 0.5952\n","Epoch 13/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0369 - acc: 0.5295 - val_loss: 1.0089 - val_acc: 0.5808\n","Epoch 14/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0374 - acc: 0.5206 - val_loss: 1.0159 - val_acc: 0.5424\n","Epoch 15/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0638 - acc: 0.5246 - val_loss: 1.0259 - val_acc: 0.5712\n","Epoch 16/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0425 - acc: 0.5305 - val_loss: 1.0188 - val_acc: 0.5760\n","Epoch 17/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0367 - acc: 0.5285 - val_loss: 0.9978 - val_acc: 0.5872\n","Epoch 18/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0386 - acc: 0.5216 - val_loss: 1.0041 - val_acc: 0.5888\n","Epoch 19/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0380 - acc: 0.5334 - val_loss: 1.0051 - val_acc: 0.6032\n","Epoch 20/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0314 - acc: 0.5320 - val_loss: 0.9955 - val_acc: 0.5920\n","Epoch 21/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0334 - acc: 0.5383 - val_loss: 1.0350 - val_acc: 0.5456\n","Epoch 22/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0182 - acc: 0.5354 - val_loss: 1.0089 - val_acc: 0.5600\n","Epoch 23/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0161 - acc: 0.5315 - val_loss: 1.0087 - val_acc: 0.5808\n","Epoch 24/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0151 - acc: 0.5467 - val_loss: 0.9986 - val_acc: 0.5936\n","Epoch 25/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0266 - acc: 0.5413 - val_loss: 0.9967 - val_acc: 0.5920\n","Epoch 26/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0267 - acc: 0.5364 - val_loss: 1.0106 - val_acc: 0.5552\n","Epoch 27/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0170 - acc: 0.5295 - val_loss: 1.0130 - val_acc: 0.5904\n","Epoch 28/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0230 - acc: 0.5305 - val_loss: 1.1156 - val_acc: 0.5024\n","Epoch 29/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0216 - acc: 0.5383 - val_loss: 1.0316 - val_acc: 0.5664\n","Epoch 30/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0210 - acc: 0.5433 - val_loss: 1.0083 - val_acc: 0.5712\n","Epoch 31/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0068 - acc: 0.5265 - val_loss: 1.0268 - val_acc: 0.5472\n","Epoch 32/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0049 - acc: 0.5344 - val_loss: 1.0502 - val_acc: 0.5456\n","Epoch 33/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0082 - acc: 0.5408 - val_loss: 0.9937 - val_acc: 0.6000\n","Epoch 34/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0040 - acc: 0.5497 - val_loss: 1.0052 - val_acc: 0.6016\n","Epoch 35/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0112 - acc: 0.5398 - val_loss: 0.9919 - val_acc: 0.5824\n","Epoch 36/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0107 - acc: 0.5359 - val_loss: 1.0204 - val_acc: 0.5728\n","Epoch 37/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0040 - acc: 0.5423 - val_loss: 1.0051 - val_acc: 0.5616\n","Epoch 38/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0068 - acc: 0.5428 - val_loss: 0.9983 - val_acc: 0.5824\n","Epoch 39/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0093 - acc: 0.5482 - val_loss: 0.9956 - val_acc: 0.5888\n","Epoch 40/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9950 - acc: 0.5506 - val_loss: 1.0149 - val_acc: 0.5728\n","Epoch 41/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0148 - acc: 0.5379 - val_loss: 1.0403 - val_acc: 0.5552\n","Epoch 42/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0021 - acc: 0.5408 - val_loss: 1.0353 - val_acc: 0.5744\n","Epoch 43/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0299 - acc: 0.5388 - val_loss: 0.9828 - val_acc: 0.5936\n","Epoch 44/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0131 - acc: 0.5428 - val_loss: 0.9910 - val_acc: 0.5824\n","Epoch 45/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9932 - acc: 0.5521 - val_loss: 1.0011 - val_acc: 0.5904\n","Epoch 46/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9990 - acc: 0.5364 - val_loss: 1.0010 - val_acc: 0.5824\n","Epoch 47/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0006 - acc: 0.5320 - val_loss: 1.0062 - val_acc: 0.5792\n","Epoch 48/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9928 - acc: 0.5477 - val_loss: 0.9825 - val_acc: 0.5824\n","Epoch 49/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9841 - acc: 0.5428 - val_loss: 0.9891 - val_acc: 0.5904\n","Epoch 50/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0055 - acc: 0.5359 - val_loss: 0.9904 - val_acc: 0.5888\n","Epoch 51/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9796 - acc: 0.5501 - val_loss: 1.0060 - val_acc: 0.5888\n","Epoch 52/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9824 - acc: 0.5526 - val_loss: 0.9917 - val_acc: 0.5856\n","Epoch 53/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9946 - acc: 0.5492 - val_loss: 0.9850 - val_acc: 0.5856\n","Epoch 54/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9854 - acc: 0.5506 - val_loss: 0.9703 - val_acc: 0.5936\n","Epoch 55/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9808 - acc: 0.5497 - val_loss: 0.9927 - val_acc: 0.5904\n","Epoch 56/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9780 - acc: 0.5413 - val_loss: 0.9980 - val_acc: 0.5872\n","Epoch 57/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9856 - acc: 0.5383 - val_loss: 1.0042 - val_acc: 0.5840\n","Epoch 58/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9796 - acc: 0.5605 - val_loss: 0.9728 - val_acc: 0.5952\n","Epoch 59/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9930 - acc: 0.5477 - val_loss: 0.9918 - val_acc: 0.6112\n","Epoch 60/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9755 - acc: 0.5526 - val_loss: 0.9803 - val_acc: 0.5920\n","Epoch 61/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9684 - acc: 0.5442 - val_loss: 0.9848 - val_acc: 0.6000\n","Epoch 62/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9872 - acc: 0.5379 - val_loss: 0.9881 - val_acc: 0.6016\n","Epoch 63/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9690 - acc: 0.5506 - val_loss: 0.9789 - val_acc: 0.6080\n","Epoch 64/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0098 - acc: 0.5462 - val_loss: 1.0057 - val_acc: 0.5792\n","Epoch 65/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9992 - acc: 0.5349 - val_loss: 0.9986 - val_acc: 0.6016\n","Epoch 66/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9824 - acc: 0.5442 - val_loss: 0.9887 - val_acc: 0.6000\n","Epoch 67/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9674 - acc: 0.5565 - val_loss: 0.9787 - val_acc: 0.6016\n","Epoch 68/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9619 - acc: 0.5482 - val_loss: 1.0129 - val_acc: 0.6064\n","Epoch 69/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 1.0027 - acc: 0.5531 - val_loss: 1.0965 - val_acc: 0.5440\n","Epoch 70/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9778 - acc: 0.5467 - val_loss: 0.9811 - val_acc: 0.5888\n","Epoch 71/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9665 - acc: 0.5506 - val_loss: 0.9676 - val_acc: 0.5984\n","Epoch 72/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9514 - acc: 0.5575 - val_loss: 0.9756 - val_acc: 0.5984\n","Epoch 73/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9675 - acc: 0.5703 - val_loss: 0.9865 - val_acc: 0.5984\n","Epoch 74/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9933 - acc: 0.5428 - val_loss: 0.9704 - val_acc: 0.5984\n","Epoch 75/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9743 - acc: 0.5388 - val_loss: 0.9869 - val_acc: 0.5888\n","Epoch 76/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9555 - acc: 0.5521 - val_loss: 0.9734 - val_acc: 0.6064\n","Epoch 77/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9553 - acc: 0.5497 - val_loss: 1.0078 - val_acc: 0.5488\n","Epoch 78/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9909 - acc: 0.5482 - val_loss: 0.9671 - val_acc: 0.6048\n","Epoch 79/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9504 - acc: 0.5610 - val_loss: 0.9659 - val_acc: 0.6064\n","Epoch 80/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9692 - acc: 0.5664 - val_loss: 0.9643 - val_acc: 0.6064\n","Epoch 81/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9351 - acc: 0.5742 - val_loss: 0.9714 - val_acc: 0.6000\n","Epoch 82/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9505 - acc: 0.5624 - val_loss: 0.9621 - val_acc: 0.6032\n","Epoch 83/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9544 - acc: 0.5624 - val_loss: 0.9817 - val_acc: 0.5968\n","Epoch 84/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9537 - acc: 0.5664 - val_loss: 1.0973 - val_acc: 0.5408\n","Epoch 85/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9560 - acc: 0.5644 - val_loss: 0.9499 - val_acc: 0.6128\n","Epoch 86/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9793 - acc: 0.5575 - val_loss: 0.9739 - val_acc: 0.6000\n","Epoch 87/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9680 - acc: 0.5487 - val_loss: 0.9820 - val_acc: 0.6160\n","Epoch 88/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9622 - acc: 0.5526 - val_loss: 0.9599 - val_acc: 0.6112\n","Epoch 89/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9352 - acc: 0.5678 - val_loss: 0.9595 - val_acc: 0.6128\n","Epoch 90/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9357 - acc: 0.5723 - val_loss: 0.9604 - val_acc: 0.6032\n","Epoch 91/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9338 - acc: 0.5757 - val_loss: 0.9387 - val_acc: 0.6320\n","Epoch 92/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9178 - acc: 0.5806 - val_loss: 0.9763 - val_acc: 0.6112\n","Epoch 93/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9399 - acc: 0.5777 - val_loss: 1.0111 - val_acc: 0.6000\n","Epoch 94/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9241 - acc: 0.5669 - val_loss: 0.9600 - val_acc: 0.6112\n","Epoch 95/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9838 - acc: 0.5600 - val_loss: 0.9661 - val_acc: 0.6080\n","Epoch 96/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9954 - acc: 0.5536 - val_loss: 0.9385 - val_acc: 0.6016\n","Epoch 97/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9242 - acc: 0.5693 - val_loss: 0.9613 - val_acc: 0.6256\n","Epoch 98/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9156 - acc: 0.5796 - val_loss: 1.0259 - val_acc: 0.5840\n","Epoch 99/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9188 - acc: 0.5742 - val_loss: 0.9857 - val_acc: 0.6064\n","Epoch 100/100\n","2034/2034 [==============================] - 30s 15ms/step - loss: 0.9258 - acc: 0.5777 - val_loss: 0.9650 - val_acc: 0.6176\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pxYMc0_KCzjE","colab_type":"code","colab":{}},"source":["def make_model():\n","    in_layer = Input(shape=(201, 300,1))\n","    x = Conv2D(32,(5,5), activation = 'elu')(in_layer)  \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(64,(5,5), activation = 'elu')(x)         \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(64,(5,5), activation = 'elu')(x)         \n","    x = Dropout(0.5)(x)\n","    x = Conv2D(128, (5,5))(x)                           \n","    x = GlobalAveragePooling2D()(x)                     \n","    x = Dense(64,activation='elu')(x)\n","    x = Dropout(0.5)(x)\n","    output_layer = Dense(4, activation = \"softmax\")(x) # softmax output\n","    model = Model(inputs = in_layer, outputs=output_layer)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s3nQfyaIC47x","colab_type":"code","outputId":"d259d271-7ccc-4204-ae91-258a1e842a7b","executionInfo":{"status":"ok","timestamp":1551810195342,"user_tz":-330,"elapsed":707340,"user":{"displayName":"Rahul Kumar","photoUrl":"","userId":"17651844698397356196"}},"colab":{"base_uri":"https://localhost:8080/","height":6787}},"source":["model  =  make_model()\n","model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\",\n","                    metrics=[\"accuracy\"])\n","m_check = keras.callbacks.ModelCheckpoint(filepath = './cnn_spectrogram.h5', monitor='val_acc', save_best_only=True, mode='max', verbose=1 )\n","hist = model.fit(X_train, y_train, \n","                 batch_size=32, validation_data=(X_test,y_test),nb_epoch=100, verbose=1, shuffle = True,callbacks=[m_check] \n","                )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \n"],"name":"stderr"},{"output_type":"stream","text":["Train on 2034 samples, validate on 625 samples\n","Epoch 1/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 3.6331 - acc: 0.3648 - val_loss: 1.1435 - val_acc: 0.4720\n","\n","Epoch 00001: val_acc improved from -inf to 0.47200, saving model to ./cnn_spectrogram.h5\n","Epoch 2/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.2538 - acc: 0.4695 - val_loss: 1.0985 - val_acc: 0.5216\n","\n","Epoch 00002: val_acc improved from 0.47200 to 0.52160, saving model to ./cnn_spectrogram.h5\n","Epoch 3/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.1979 - acc: 0.4636 - val_loss: 1.1112 - val_acc: 0.5152\n","\n","Epoch 00003: val_acc did not improve from 0.52160\n","Epoch 4/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.1898 - acc: 0.4739 - val_loss: 1.0796 - val_acc: 0.5088\n","\n","Epoch 00004: val_acc did not improve from 0.52160\n","Epoch 5/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.1549 - acc: 0.4848 - val_loss: 1.0637 - val_acc: 0.5344\n","\n","Epoch 00005: val_acc improved from 0.52160 to 0.53440, saving model to ./cnn_spectrogram.h5\n","Epoch 6/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.1296 - acc: 0.4887 - val_loss: 1.0651 - val_acc: 0.5440\n","\n","Epoch 00006: val_acc improved from 0.53440 to 0.54400, saving model to ./cnn_spectrogram.h5\n","Epoch 7/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.1270 - acc: 0.5113 - val_loss: 1.4626 - val_acc: 0.3440\n","\n","Epoch 00007: val_acc did not improve from 0.54400\n","Epoch 8/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.1053 - acc: 0.5241 - val_loss: 1.0877 - val_acc: 0.5296\n","\n","Epoch 00008: val_acc did not improve from 0.54400\n","Epoch 9/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.1007 - acc: 0.5177 - val_loss: 1.0252 - val_acc: 0.5696\n","\n","Epoch 00009: val_acc improved from 0.54400 to 0.56960, saving model to ./cnn_spectrogram.h5\n","Epoch 10/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.0965 - acc: 0.5152 - val_loss: 1.0942 - val_acc: 0.5120\n","\n","Epoch 00010: val_acc did not improve from 0.56960\n","Epoch 11/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.0425 - acc: 0.5334 - val_loss: 1.1375 - val_acc: 0.5712\n","\n","Epoch 00011: val_acc improved from 0.56960 to 0.57120, saving model to ./cnn_spectrogram.h5\n","Epoch 12/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.0486 - acc: 0.5265 - val_loss: 1.0274 - val_acc: 0.5744\n","\n","Epoch 00012: val_acc improved from 0.57120 to 0.57440, saving model to ./cnn_spectrogram.h5\n","Epoch 13/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.0478 - acc: 0.5334 - val_loss: 1.1183 - val_acc: 0.5456\n","\n","Epoch 00013: val_acc did not improve from 0.57440\n","Epoch 14/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.0010 - acc: 0.5320 - val_loss: 1.0950 - val_acc: 0.5120\n","\n","Epoch 00014: val_acc did not improve from 0.57440\n","Epoch 15/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.0830 - acc: 0.5197 - val_loss: 1.0616 - val_acc: 0.5600\n","\n","Epoch 00015: val_acc did not improve from 0.57440\n","Epoch 16/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.0164 - acc: 0.5482 - val_loss: 1.0276 - val_acc: 0.5632\n","\n","Epoch 00016: val_acc did not improve from 0.57440\n","Epoch 17/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.0184 - acc: 0.5605 - val_loss: 1.0255 - val_acc: 0.5888\n","\n","Epoch 00017: val_acc improved from 0.57440 to 0.58880, saving model to ./cnn_spectrogram.h5\n","Epoch 18/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 1.0092 - acc: 0.5600 - val_loss: 1.0023 - val_acc: 0.6112\n","\n","Epoch 00018: val_acc improved from 0.58880 to 0.61120, saving model to ./cnn_spectrogram.h5\n","Epoch 19/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9916 - acc: 0.5659 - val_loss: 1.0299 - val_acc: 0.6032\n","\n","Epoch 00019: val_acc did not improve from 0.61120\n","Epoch 20/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9720 - acc: 0.5644 - val_loss: 0.9934 - val_acc: 0.6000\n","\n","Epoch 00020: val_acc did not improve from 0.61120\n","Epoch 21/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9707 - acc: 0.5747 - val_loss: 0.9822 - val_acc: 0.6272\n","\n","Epoch 00021: val_acc improved from 0.61120 to 0.62720, saving model to ./cnn_spectrogram.h5\n","Epoch 22/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9745 - acc: 0.5664 - val_loss: 1.0396 - val_acc: 0.5696\n","\n","Epoch 00022: val_acc did not improve from 0.62720\n","Epoch 23/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9421 - acc: 0.5757 - val_loss: 0.9749 - val_acc: 0.6096\n","\n","Epoch 00023: val_acc did not improve from 0.62720\n","Epoch 24/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9129 - acc: 0.6037 - val_loss: 0.9657 - val_acc: 0.5984\n","\n","Epoch 00024: val_acc did not improve from 0.62720\n","Epoch 25/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9696 - acc: 0.5796 - val_loss: 0.9583 - val_acc: 0.5952\n","\n","Epoch 00025: val_acc did not improve from 0.62720\n","Epoch 26/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9376 - acc: 0.5728 - val_loss: 0.9801 - val_acc: 0.5888\n","\n","Epoch 00026: val_acc did not improve from 0.62720\n","Epoch 27/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9286 - acc: 0.5973 - val_loss: 0.9554 - val_acc: 0.6400\n","\n","Epoch 00027: val_acc improved from 0.62720 to 0.64000, saving model to ./cnn_spectrogram.h5\n","Epoch 28/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9154 - acc: 0.5841 - val_loss: 0.9414 - val_acc: 0.6176\n","\n","Epoch 00028: val_acc did not improve from 0.64000\n","Epoch 29/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9247 - acc: 0.5939 - val_loss: 0.9202 - val_acc: 0.6320\n","\n","Epoch 00029: val_acc did not improve from 0.64000\n","Epoch 30/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9325 - acc: 0.5870 - val_loss: 0.9897 - val_acc: 0.5984\n","\n","Epoch 00030: val_acc did not improve from 0.64000\n","Epoch 31/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9134 - acc: 0.5801 - val_loss: 0.9289 - val_acc: 0.6224\n","\n","Epoch 00031: val_acc did not improve from 0.64000\n","Epoch 32/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9212 - acc: 0.5924 - val_loss: 1.1203 - val_acc: 0.5392\n","\n","Epoch 00032: val_acc did not improve from 0.64000\n","Epoch 33/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9060 - acc: 0.6028 - val_loss: 1.0150 - val_acc: 0.6176\n","\n","Epoch 00033: val_acc did not improve from 0.64000\n","Epoch 34/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9167 - acc: 0.5964 - val_loss: 0.9395 - val_acc: 0.6256\n","\n","Epoch 00034: val_acc did not improve from 0.64000\n","Epoch 35/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8928 - acc: 0.5973 - val_loss: 1.0529 - val_acc: 0.5776\n","\n","Epoch 00035: val_acc did not improve from 0.64000\n","Epoch 36/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9005 - acc: 0.5924 - val_loss: 1.0601 - val_acc: 0.5728\n","\n","Epoch 00036: val_acc did not improve from 0.64000\n","Epoch 37/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9088 - acc: 0.6013 - val_loss: 0.9366 - val_acc: 0.6208\n","\n","Epoch 00037: val_acc did not improve from 0.64000\n","Epoch 38/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9089 - acc: 0.5934 - val_loss: 0.9252 - val_acc: 0.6432\n","\n","Epoch 00038: val_acc improved from 0.64000 to 0.64320, saving model to ./cnn_spectrogram.h5\n","Epoch 39/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9077 - acc: 0.5880 - val_loss: 0.9658 - val_acc: 0.6320\n","\n","Epoch 00039: val_acc did not improve from 0.64320\n","Epoch 40/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9164 - acc: 0.5910 - val_loss: 1.0130 - val_acc: 0.6080\n","\n","Epoch 00040: val_acc did not improve from 0.64320\n","Epoch 41/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9076 - acc: 0.5969 - val_loss: 1.0194 - val_acc: 0.6128\n","\n","Epoch 00041: val_acc did not improve from 0.64320\n","Epoch 42/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8897 - acc: 0.6047 - val_loss: 0.9914 - val_acc: 0.6256\n","\n","Epoch 00042: val_acc did not improve from 0.64320\n","Epoch 43/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8849 - acc: 0.6037 - val_loss: 1.0034 - val_acc: 0.6288\n","\n","Epoch 00043: val_acc did not improve from 0.64320\n","Epoch 44/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8564 - acc: 0.6254 - val_loss: 1.0362 - val_acc: 0.6192\n","\n","Epoch 00044: val_acc did not improve from 0.64320\n","Epoch 45/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8752 - acc: 0.6121 - val_loss: 0.9204 - val_acc: 0.6288\n","\n","Epoch 00045: val_acc did not improve from 0.64320\n","Epoch 46/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8701 - acc: 0.6136 - val_loss: 0.9410 - val_acc: 0.6448\n","\n","Epoch 00046: val_acc improved from 0.64320 to 0.64480, saving model to ./cnn_spectrogram.h5\n","Epoch 47/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8593 - acc: 0.6205 - val_loss: 0.9998 - val_acc: 0.6144\n","\n","Epoch 00047: val_acc did not improve from 0.64480\n","Epoch 48/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8764 - acc: 0.6082 - val_loss: 0.9277 - val_acc: 0.6208\n","\n","Epoch 00048: val_acc did not improve from 0.64480\n","Epoch 49/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8641 - acc: 0.6180 - val_loss: 0.9857 - val_acc: 0.6080\n","\n","Epoch 00049: val_acc did not improve from 0.64480\n","Epoch 50/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8906 - acc: 0.6141 - val_loss: 0.9684 - val_acc: 0.6336\n","\n","Epoch 00050: val_acc did not improve from 0.64480\n","Epoch 51/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8832 - acc: 0.5944 - val_loss: 1.0371 - val_acc: 0.5936\n","\n","Epoch 00051: val_acc did not improve from 0.64480\n","Epoch 52/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8673 - acc: 0.6106 - val_loss: 0.9396 - val_acc: 0.6256\n","\n","Epoch 00052: val_acc did not improve from 0.64480\n","Epoch 53/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8528 - acc: 0.6278 - val_loss: 1.0759 - val_acc: 0.5808\n","\n","Epoch 00053: val_acc did not improve from 0.64480\n","Epoch 54/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8585 - acc: 0.6082 - val_loss: 0.9763 - val_acc: 0.6224\n","\n","Epoch 00054: val_acc did not improve from 0.64480\n","Epoch 55/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8751 - acc: 0.6155 - val_loss: 1.0281 - val_acc: 0.6080\n","\n","Epoch 00055: val_acc did not improve from 0.64480\n","Epoch 56/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8697 - acc: 0.6126 - val_loss: 0.9501 - val_acc: 0.6320\n","\n","Epoch 00056: val_acc did not improve from 0.64480\n","Epoch 57/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.9085 - acc: 0.5969 - val_loss: 0.9694 - val_acc: 0.6160\n","\n","Epoch 00057: val_acc did not improve from 0.64480\n","Epoch 58/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8505 - acc: 0.6180 - val_loss: 0.9118 - val_acc: 0.6256\n","\n","Epoch 00058: val_acc did not improve from 0.64480\n","Epoch 59/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8540 - acc: 0.6200 - val_loss: 0.9084 - val_acc: 0.6432\n","\n","Epoch 00059: val_acc did not improve from 0.64480\n","Epoch 60/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8383 - acc: 0.6254 - val_loss: 0.9785 - val_acc: 0.6304\n","\n","Epoch 00060: val_acc did not improve from 0.64480\n","Epoch 61/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8439 - acc: 0.6224 - val_loss: 0.9262 - val_acc: 0.6368\n","\n","Epoch 00061: val_acc did not improve from 0.64480\n","Epoch 62/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8569 - acc: 0.6318 - val_loss: 0.9277 - val_acc: 0.6240\n","\n","Epoch 00062: val_acc did not improve from 0.64480\n","Epoch 63/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8419 - acc: 0.6313 - val_loss: 0.9570 - val_acc: 0.6208\n","\n","Epoch 00063: val_acc did not improve from 0.64480\n","Epoch 64/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8208 - acc: 0.6441 - val_loss: 1.0263 - val_acc: 0.5920\n","\n","Epoch 00064: val_acc did not improve from 0.64480\n","Epoch 65/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8347 - acc: 0.6386 - val_loss: 0.9191 - val_acc: 0.6336\n","\n","Epoch 00065: val_acc did not improve from 0.64480\n","Epoch 66/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8447 - acc: 0.6342 - val_loss: 0.9967 - val_acc: 0.6176\n","\n","Epoch 00066: val_acc did not improve from 0.64480\n","Epoch 67/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8323 - acc: 0.6254 - val_loss: 0.9638 - val_acc: 0.6224\n","\n","Epoch 00067: val_acc did not improve from 0.64480\n","Epoch 68/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8174 - acc: 0.6362 - val_loss: 0.9511 - val_acc: 0.6368\n","\n","Epoch 00068: val_acc did not improve from 0.64480\n","Epoch 69/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8442 - acc: 0.6254 - val_loss: 0.9365 - val_acc: 0.6304\n","\n","Epoch 00069: val_acc did not improve from 0.64480\n","Epoch 70/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8204 - acc: 0.6313 - val_loss: 0.9979 - val_acc: 0.6368\n","\n","Epoch 00070: val_acc did not improve from 0.64480\n","Epoch 71/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.7900 - acc: 0.6554 - val_loss: 1.0035 - val_acc: 0.6096\n","\n","Epoch 00071: val_acc did not improve from 0.64480\n","Epoch 72/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8145 - acc: 0.6421 - val_loss: 0.9349 - val_acc: 0.6112\n","\n","Epoch 00072: val_acc did not improve from 0.64480\n","Epoch 73/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8338 - acc: 0.6367 - val_loss: 0.9797 - val_acc: 0.6112\n","\n","Epoch 00073: val_acc did not improve from 0.64480\n","Epoch 74/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8160 - acc: 0.6396 - val_loss: 0.9180 - val_acc: 0.6464\n","\n","Epoch 00074: val_acc improved from 0.64480 to 0.64640, saving model to ./cnn_spectrogram.h5\n","Epoch 75/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8055 - acc: 0.6426 - val_loss: 0.9465 - val_acc: 0.6176\n","\n","Epoch 00075: val_acc did not improve from 0.64640\n","Epoch 76/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8318 - acc: 0.6318 - val_loss: 0.9012 - val_acc: 0.6192\n","\n","Epoch 00076: val_acc did not improve from 0.64640\n","Epoch 77/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8294 - acc: 0.6273 - val_loss: 0.9355 - val_acc: 0.6208\n","\n","Epoch 00077: val_acc did not improve from 0.64640\n","Epoch 78/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8365 - acc: 0.6244 - val_loss: 0.9904 - val_acc: 0.6240\n","\n","Epoch 00078: val_acc did not improve from 0.64640\n","Epoch 79/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8189 - acc: 0.6332 - val_loss: 0.9765 - val_acc: 0.6256\n","\n","Epoch 00079: val_acc did not improve from 0.64640\n","Epoch 80/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8302 - acc: 0.6406 - val_loss: 0.8959 - val_acc: 0.6320\n","\n","Epoch 00080: val_acc did not improve from 0.64640\n","Epoch 81/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8430 - acc: 0.6249 - val_loss: 0.9633 - val_acc: 0.6240\n","\n","Epoch 00081: val_acc did not improve from 0.64640\n","Epoch 82/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8428 - acc: 0.6342 - val_loss: 1.0976 - val_acc: 0.6128\n","\n","Epoch 00082: val_acc did not improve from 0.64640\n","Epoch 83/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8341 - acc: 0.6308 - val_loss: 0.9334 - val_acc: 0.6208\n","\n","Epoch 00083: val_acc did not improve from 0.64640\n","Epoch 84/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8315 - acc: 0.6318 - val_loss: 1.0564 - val_acc: 0.6064\n","\n","Epoch 00084: val_acc did not improve from 0.64640\n","Epoch 85/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8330 - acc: 0.6318 - val_loss: 0.9560 - val_acc: 0.6272\n","\n","Epoch 00085: val_acc did not improve from 0.64640\n","Epoch 86/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.7992 - acc: 0.6504 - val_loss: 1.1176 - val_acc: 0.5888\n","\n","Epoch 00086: val_acc did not improve from 0.64640\n","Epoch 87/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8140 - acc: 0.6391 - val_loss: 0.9566 - val_acc: 0.6464\n","\n","Epoch 00087: val_acc did not improve from 0.64640\n","Epoch 88/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.7898 - acc: 0.6529 - val_loss: 1.0689 - val_acc: 0.5808\n","\n","Epoch 00088: val_acc did not improve from 0.64640\n","Epoch 89/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.8088 - acc: 0.6480 - val_loss: 0.9474 - val_acc: 0.6512\n","\n","Epoch 00089: val_acc improved from 0.64640 to 0.65120, saving model to ./cnn_spectrogram.h5\n","Epoch 90/100\n","2034/2034 [==============================] - 102s 50ms/step - loss: 0.7912 - acc: 0.6504 - val_loss: 0.9744 - val_acc: 0.6352\n","\n","Epoch 00090: val_acc did not improve from 0.65120\n","Epoch 91/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8057 - acc: 0.6352 - val_loss: 0.9939 - val_acc: 0.6240\n","\n","Epoch 00091: val_acc did not improve from 0.65120\n","Epoch 92/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8056 - acc: 0.6367 - val_loss: 0.9712 - val_acc: 0.6208\n","\n","Epoch 00092: val_acc did not improve from 0.65120\n","Epoch 93/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8403 - acc: 0.6386 - val_loss: 1.0847 - val_acc: 0.5344\n","\n","Epoch 00093: val_acc did not improve from 0.65120\n","Epoch 94/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8192 - acc: 0.6357 - val_loss: 0.9328 - val_acc: 0.6320\n","\n","Epoch 00094: val_acc did not improve from 0.65120\n","Epoch 95/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.7944 - acc: 0.6465 - val_loss: 0.9497 - val_acc: 0.6288\n","\n","Epoch 00095: val_acc did not improve from 0.65120\n","Epoch 96/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8054 - acc: 0.6382 - val_loss: 0.9251 - val_acc: 0.6192\n","\n","Epoch 00096: val_acc did not improve from 0.65120\n","Epoch 97/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8057 - acc: 0.6377 - val_loss: 0.9345 - val_acc: 0.6304\n","\n","Epoch 00097: val_acc did not improve from 0.65120\n","Epoch 98/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.7853 - acc: 0.6588 - val_loss: 0.9850 - val_acc: 0.6288\n","\n","Epoch 00098: val_acc did not improve from 0.65120\n","Epoch 99/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.7707 - acc: 0.6554 - val_loss: 1.0786 - val_acc: 0.5856\n","\n","Epoch 00099: val_acc did not improve from 0.65120\n","Epoch 100/100\n","2034/2034 [==============================] - 101s 50ms/step - loss: 0.8165 - acc: 0.6445 - val_loss: 0.9419 - val_acc: 0.5888\n","\n","Epoch 00100: val_acc did not improve from 0.65120\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"98JoRejkHx4y","colab_type":"code","outputId":"12d9f5dc-6141-4e5f-c47a-308408593196","executionInfo":{"status":"ok","timestamp":1554218507272,"user_tz":-330,"elapsed":6922,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":188}},"source":["best_model = load_model('./cnn_spectrogram.h5')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-zsY8S21VNr3","colab_type":"code","colab":{}},"source":["y_pred = best_model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0G6lOstrVd8V","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report, accuracy_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTeRPFirWRB1","colab_type":"code","colab":{}},"source":["for i in range(len(y_pred)):\n","  for j in range(len(y_pred[i])) :\n","    if y_pred[i][j]==max(y_pred[i]) :\n","      y_pred[i][j] = 1\n","    else:\n","      y_pred[i][j]=0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C01qBWAkW4T8","colab_type":"code","outputId":"a2ec257e-82bb-422b-c658-b458ee22747f","executionInfo":{"status":"ok","timestamp":1553971869158,"user_tz":-330,"elapsed":3362,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["print(y_pred)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0. 0. 1. 0.]\n"," [1. 0. 0. 0.]\n"," [1. 0. 0. 0.]\n"," ...\n"," [0. 0. 1. 0.]\n"," [0. 0. 1. 0.]\n"," [0. 1. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gpLk_uYlV_Su","colab_type":"code","outputId":"57b72d92-9306-42ee-c41f-299b6178eb9b","executionInfo":{"status":"ok","timestamp":1551810757359,"user_tz":-330,"elapsed":1276,"user":{"displayName":"Rahul Kumar","photoUrl":"","userId":"17651844698397356196"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.34      0.45      0.39        31\n","           1       0.65      0.48      0.55       174\n","           2       0.65      0.78      0.71       287\n","           3       0.77      0.64      0.70       133\n","\n","   micro avg       0.65      0.65      0.65       625\n","   macro avg       0.60      0.59      0.59       625\n","weighted avg       0.66      0.65      0.65       625\n"," samples avg       0.65      0.65      0.65       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B-Opj0t0Y2Z8","colab_type":"code","outputId":"f2224932-b379-4f36-d394-54f57bb24038","executionInfo":{"status":"ok","timestamp":1551811276766,"user_tz":-330,"elapsed":2300,"user":{"displayName":"Rahul Kumar","photoUrl":"","userId":"17651844698397356196"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["accuracy_score(y_pred, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6512"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"M7P2k5ynO9Rc","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PuWMXIPOA8OB","colab_type":"code","colab":{}},"source":["def lda_loss(n_components, margin):\n","    \"\"\"\n","    The main loss function (inner_lda_objective) is wrapped in this function due to\n","    the constraints imposed by Keras on objective functions\n","    \"\"\"\n","\n","    def inner_lda_objective(y_true, y_pred):\n","        \"\"\"\n","        It is the loss function of LDA as introduced in the original paper.\n","        It is adopted from the the original implementation in the following link:\n","        https://github.com/CPJKU/deep_lda\n","        Note: it is implemented by Theano tensor operations, and does not work on Tensorflow backend\n","        \"\"\"\n","        r = 1e-4\n","\n","        # init groups\n","        # yt = tf.cast(tf.contrib.layers.flatten(y_true), tf.float32)\n","        # indexes = tf.argmax (y_true, axis=-1)\n","        locations = tf.where(tf.equal(y_true, 1))\n","        indices = locations[:, 1]\n","        y, idx = tf.unique(indices)\n","\n","        def fn(unique, indexes, preds):\n","            u_indexes = tf.where(tf.equal(unique, indexes))\n","            u_indexes = tf.reshape(u_indexes, (1, -1))\n","            X = tf.gather(preds, u_indexes)\n","            X_mean = X - tf.reduce_mean(X, axis=0)\n","            m = tf.cast(tf.shape(X_mean)[1], tf.float32)\n","            return (1 / (m - 1)) * tf.matmul(tf.transpose(X_mean[0]), X_mean[0])\n","\n","        # scan over groups\n","        covs_t = tf.map_fn(lambda x: fn(x, indices, y_pred), y, dtype=tf.float32)\n","\n","        # compute average covariance matrix (within scatter)\n","        Sw_t = tf.reduce_mean(covs_t, axis=0)\n","\n","        # compute total scatter\n","        Xt_bar = y_pred - tf.reduce_mean(y_pred, axis=0)\n","        m = tf.cast(tf.shape(Xt_bar)[1], tf.float32)\n","        St_t = (1 / (m - 1)) * tf.matmul(tf.transpose(Xt_bar), Xt_bar)\n","\n","        # compute between scatter\n","        dim = tf.shape(y)[0]\n","        Sb_t = St_t - Sw_t\n","\n","        # cope for numerical instability (regularize)\n","\n","        Sw_t += tf.eye(dim) * r\n","\n","        ''' START : COMPLICATED PART WHERE TENSORFLOW HAS TROUBLE'''\n","\n","        cho = tf.cholesky(St_t + tf.eye(dim) * r)\n","        inv_cho = tf.matrix_inverse(cho)\n","        evals_t = tf.linalg.eigvalsh(inv_cho * Sb_t * tf.transpose(inv_cho + tf.eye(dim) * r))  # Sb_t, St_t # SIMPLIFICATION OF THE EQP USING cholesky\n","        #evals_t = tf.abs(tf.linalg.eigvalsh(tf.matrix_inverse(Sw_t) * Sb_t )) # INVERSED EQUATION\n","        top_k_evals = evals_t[-n_components:]\n","\n","        ''' END : COMPLICATED PART WHERE TENSORFLOW HAS TROUBLE'''\n","\n","        # index_max = tf.argmax(top_k_evals, 0)\n","        # thresh_max = top_k_evals[index_max] - margin\n","\n","        index_min = tf.argmin(top_k_evals, 0)\n","        thresh_min = top_k_evals[index_min] + margin\n","        # thresh = tf.contrib.distributions.percentile(top_k_evals, 33) # TRY TO TAKE A PERCENTILE INSTEAD THAN A THRESOLD\n","        # mask_max = top_k_evals > thresh_max\n","        mask_min = top_k_evals < thresh_min\n","\n","        # cost_max = tf.boolean_mask(top_k_evals, mask_max)\n","        cost_min = tf.boolean_mask(top_k_evals, mask_min)\n","\n","        return - tf.reduce_mean(cost_min)\n","\n","    return inner_lda_objective\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0QKGss5gA6Xe","colab_type":"code","outputId":"7f147b43-b976-4bba-90ad-4c6b5cf72d4b","executionInfo":{"status":"error","timestamp":1558674534562,"user_tz":-330,"elapsed":5526,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":525}},"source":["model  =  make_model()\n","model.compile(optimizer = \"adam\", loss = lda_loss(3,1.0),\n","                    metrics=[\"accuracy\"])\n","m_check = keras.callbacks.ModelCheckpoint(filepath = './cnn_spectrogram_lda.h5', monitor='val_acc', save_best_only=True, mode='max', verbose=1 )\n","hist = model.fit(X_train, y_train, \n","                 batch_size=32, validation_data=(X_test,y_test),nb_epoch=100, verbose=1, shuffle = True,callbacks=[m_check] \n","                )"],"execution_count":21,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 2034 samples, validate on 625 samples\n","Epoch 1/100\n","  96/2034 [>.............................] - ETA: 1:00 - loss: -1.1485 - acc: 0.2708"],"name":"stdout"},{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-bfbdeba26e2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mm_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./cnn_spectrogram_lda.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m hist = model.fit(X_train, y_train, \n\u001b[0;32m----> 6\u001b[0;31m                  \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm_check\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                 )\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Got info = 3 for batch index 0, expected info = 0. Debug_info = heevd\n\t [[{{node loss_3/dense_8_loss/SelfAdjointEigV2}}]]\n\t [[{{node loss_3/mul}}]]"]}]},{"cell_type":"code","metadata":{"id":"O3Z_WK5cpa4U","colab_type":"code","colab":{}},"source":["model = best_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"28-3z24RVNpP","colab_type":"code","colab":{}},"source":["from keras.models import Model\n","\n","layer_name = 'global_average_pooling2d_7'\n","intermediate_layer_model = Model(inputs=model.input,\n","                                 outputs=model.get_layer(layer_name).output)\n","output_train = intermediate_layer_model.predict(X_train)\n","output_test =  intermediate_layer_model.predict(X_test)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NodYNJTAxLRZ","colab_type":"code","outputId":"4762fde6-f00c-4e9e-fdcc-641c886f91d2","executionInfo":{"status":"ok","timestamp":1553970000087,"user_tz":-330,"elapsed":2540,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["print(output_train.shape)\n","print(output_test.shape)\n","print(y_train.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2034, 128)\n","(625, 128)\n","(2034, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DzOkgq8I1P8N","colab_type":"code","colab":{}},"source":["labelencoder = LabelEncoder()\n","y_train = labelencoder.fit_transform(Y_train)\n","y_test = labelencoder.transform(Y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OxPjVLNM__lz","colab_type":"code","outputId":"9e2d4d70-e227-4fe0-f4cd-35426afa7cdc","executionInfo":{"status":"ok","timestamp":1554039973019,"user_tz":-330,"elapsed":1192,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["y_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034,)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"qHv3MDCAykqP","colab_type":"code","colab":{}},"source":["from xgboost import XGBClassifier\n","frxom xgboost import plot_importance\n","from sklearn.feature_selection import SelectFromModel\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssplSzhgy3-I","colab_type":"code","colab":{}},"source":["xg_model = XGBClassifier(n_estimators=100,learning_rate=0.2,max_depth=7,objective = 'multi:softmax',\n","                       num_class=4,n_jobs=-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"feeWa5sHzmRD","colab_type":"code","outputId":"331ba57f-1393-4f8c-f1fe-2ed3e3f6f024","executionInfo":{"status":"ok","timestamp":1554041257936,"user_tz":-330,"elapsed":10283,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["xg_model.fit(output_train,y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","       colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n","       max_depth=7, min_child_weight=1, missing=None, n_estimators=100,\n","       n_jobs=-1, nthread=None, num_class=4, objective='multi:softprob',\n","       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n","       seed=None, silent=True, subsample=1)"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"26Ly1lhWCiRt","colab_type":"code","colab":{}},"source":["plot_importance(xg_model)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sZXfX2BHDGa2","colab_type":"code","colab":{}},"source":["thresholds = np.sort(xg_model.feature_importances_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7HTrtqHQDMuf","colab_type":"code","colab":{}},"source":["# select features using threshold\n","selection = SelectFromModel(xg_model, threshold=0.005, prefit=True)\n","X_train = selection.transform(output_train)\n","X_test = selection.transform(output_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vowSx-kEGoU","colab_type":"code","colab":{}},"source":["xg_model1 = XGBClassifier(n_estimators=100,learning_rate=0.2,max_depth=7,objective = 'multi:softmax',\n","                       num_class=4,n_jobs=-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uyt9tRRfENRV","colab_type":"code","outputId":"ea021eba-a78a-4612-bb19-ccab04877b3f","executionInfo":{"status":"ok","timestamp":1554041319404,"user_tz":-330,"elapsed":8136,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["xg_model1.fit(X_train,y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","       colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n","       max_depth=7, min_child_weight=1, missing=None, n_estimators=100,\n","       n_jobs=-1, nthread=None, num_class=4, objective='multi:softprob',\n","       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n","       seed=None, silent=True, subsample=1)"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"vllJ4a_dEV6I","colab_type":"code","colab":{}},"source":["y_pred = xg_model1.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"csjndJ7lEmzA","colab_type":"code","outputId":"6e0d17eb-92f3-4bc4-af0b-f9fc89ba5fb5","executionInfo":{"status":"ok","timestamp":1554041292290,"user_tz":-330,"elapsed":1351,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034, 114)"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"KeORDK-0EgWD","colab_type":"code","outputId":"98f7b1b1-db64-4add-f220-2b44f6d3be84","executionInfo":{"status":"ok","timestamp":1554041331067,"user_tz":-330,"elapsed":1102,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.20      0.26      0.22        31\n","           1       0.64      0.44      0.52       174\n","           2       0.63      0.69      0.66       287\n","           3       0.64      0.71      0.67       133\n","\n","   micro avg       0.60      0.60      0.60       625\n","   macro avg       0.53      0.52      0.52       625\n","weighted avg       0.61      0.60      0.60       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bw34TJnSy3yW","colab_type":"code","colab":{}},"source":["y_pred = xg_model.predict(output_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-n5JEZxR4OcE","colab_type":"code","outputId":"119415b4-4b54-4bd1-a414-ca6ea5828367","executionInfo":{"status":"ok","timestamp":1553972240881,"user_tz":-330,"elapsed":1930,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.23      0.29      0.26        31\n","           1       0.62      0.44      0.51       174\n","           2       0.63      0.68      0.65       287\n","           3       0.63      0.72      0.67       133\n","\n","   micro avg       0.60      0.60      0.60       625\n","   macro avg       0.53      0.53      0.52       625\n","weighted avg       0.61      0.60      0.60       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRaIvOWzAjTo","colab_type":"code","colab":{}},"source":["# Fitting Random Forest Classification to the Training set\n","from sklearn.ensemble import RandomForestClassifier\n","classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0,n_jobs=-1)\n","#classifier.fit(output_train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mm32c--oBRJH","colab_type":"code","colab":{}},"source":["y_pred = classifier.predict(output_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nGeLqCwJBoZG","colab_type":"code","outputId":"6661c282-dedd-4879-c201-6bece0ef9400","executionInfo":{"status":"ok","timestamp":1554041388593,"user_tz":-330,"elapsed":1859,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.24      0.26      0.25        31\n","           1       0.63      0.45      0.52       174\n","           2       0.65      0.72      0.68       287\n","           3       0.67      0.74      0.70       133\n","\n","   micro avg       0.63      0.63      0.63       625\n","   macro avg       0.55      0.54      0.54       625\n","weighted avg       0.63      0.63      0.62       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IwmeZ7OBFpL6","colab_type":"code","colab":{}},"source":["from mlxtend.evaluate import confusion_matrix\n","m = confusion_matrix(y_target=y_test, \n","                      y_predicted=y_pred, \n","                      binary=False)\n","print(m)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ayCfbRlZFs2R","colab_type":"code","colab":{}},"source":["# Applying Grid Search to find the best model and the best parameters\n","from sklearn.model_selection import GridSearchCV\n","parameters = {'bootstrap': [True, False],\n"," 'max_depth': [10, 20, 40,None],\n"," 'max_features': ['auto', 'sqrt'],\n"," 'n_estimators': [80,100,150,400]}\n","grid_search = GridSearchCV(estimator = classifier,\n","                           param_grid = parameters,\n","                           scoring = 'accuracy',\n","                           cv = 10,\n","                           n_jobs = -1)\n","grid_search = grid_search.fit(output_train, y_train)\n","best_accuracy = grid_search.best_score_\n","best_parameters = grid_search.best_params_\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DXVhzY8lk8Ou","colab_type":"code","outputId":"774077f5-8206-438a-a561-0b4b5af9dd4f","executionInfo":{"status":"ok","timestamp":1554222011254,"user_tz":-330,"elapsed":771381,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["best_parameters"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bootstrap': True,\n"," 'max_depth': 20,\n"," 'max_features': 'auto',\n"," 'n_estimators': 80}"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"vKHc8leSEwLQ","colab_type":"code","outputId":"a2bac56d-6dc1-4012-b46b-09c05974aa5e","executionInfo":{"status":"ok","timestamp":1554225781286,"user_tz":-330,"elapsed":4030,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["best_accuracy"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6647000983284169"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"SbK_rhZsE4kd","colab_type":"code","outputId":"8d2ffcb7-047c-4580-99c5-0a4fb634fb77","executionInfo":{"status":"ok","timestamp":1554225966955,"user_tz":-330,"elapsed":5148,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["classifier = RandomForestClassifier(n_estimators = 80, bootstrap=True,criterion = 'entropy', max_depth=20,max_features='auto',n_jobs=-1)\n","classifier.fit(output_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","            max_depth=20, max_features='auto', max_leaf_nodes=None,\n","            min_impurity_decrease=0.0, min_impurity_split=None,\n","            min_samples_leaf=1, min_samples_split=2,\n","            min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=-1,\n","            oob_score=False, random_state=None, verbose=0,\n","            warm_start=False)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"wsc67rvAFUwb","colab_type":"code","colab":{}},"source":["y_pred = classifier.predict(output_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZYToa7mBFoK_","colab_type":"code","outputId":"56eb6c74-06b3-4ceb-ce5c-fc070f15ae07","executionInfo":{"status":"ok","timestamp":1554226034384,"user_tz":-330,"elapsed":4051,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.24      0.26      0.25        31\n","           1       0.64      0.43      0.51       174\n","           2       0.64      0.73      0.68       287\n","           3       0.66      0.73      0.70       133\n","\n","   micro avg       0.62      0.62      0.62       625\n","   macro avg       0.55      0.54      0.53       625\n","weighted avg       0.62      0.62      0.62       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WDvOGt6AHUph","colab_type":"code","colab":{}},"source":["# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train_scaled = sc.fit_transform(output_train)\n","X_test_scaled = sc.transform(output_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rV4NuPziIKUq","colab_type":"code","colab":{}},"source":["from sklearn.svm import SVC\n","classifier = SVC(kernel = 'rbf', random_state = 0)\n","#classifier.fit(X_train_scaled, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6H-Ld7BIdpl","colab_type":"code","colab":{}},"source":["y_pred = classifier.predict(X_test_scaled)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jNWu9thcIqi3","colab_type":"code","outputId":"fd2241bb-5502-4261-d2cc-3c8050063b36","executionInfo":{"status":"ok","timestamp":1554226826594,"user_tz":-330,"elapsed":5021,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.30      0.23      0.26        31\n","           1       0.65      0.41      0.50       174\n","           2       0.62      0.76      0.69       287\n","           3       0.67      0.72      0.70       133\n","\n","   micro avg       0.63      0.63      0.63       625\n","   macro avg       0.56      0.53      0.54       625\n","weighted avg       0.62      0.63      0.61       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kRHYjop8JHhX","colab_type":"code","outputId":"fa0eddb7-5279-486e-e15c-c9ff2b72f901","executionInfo":{"status":"ok","timestamp":1554230827690,"user_tz":-330,"elapsed":3883285,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["# Applying Grid Search to find the best model and the best parameters\n","from sklearn.model_selection import GridSearchCV\n","parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n","              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n","grid_search = GridSearchCV(estimator = classifier,\n","                           param_grid = parameters,\n","                           scoring = 'accuracy',\n","                           cv = 10,\n","                           n_jobs = -1)\n","grid_search = grid_search.fit(X_train_scaled, y_train)\n","best_accuracy = grid_search.best_score_\n","best_parameters = grid_search.best_params_"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n","  DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"k1GB7NM6ZuJW","colab_type":"code","outputId":"5912bb8e-b8cb-442d-b5ef-d28e58dd1862","executionInfo":{"status":"ok","timestamp":1554231272008,"user_tz":-330,"elapsed":3481,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["best_parameters"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'C': 1, 'kernel': 'linear'}"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"M4Jq3n-mZXgy","colab_type":"code","outputId":"76307d9d-6391-44cb-8889-ec241fcbe316","executionInfo":{"status":"ok","timestamp":1554231282577,"user_tz":-330,"elapsed":2885,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["from sklearn.svm import SVC\n","classifier = SVC(kernel = 'linear', C=1)\n","classifier.fit(X_train_scaled, y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n","  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n","  kernel='linear', max_iter=-1, probability=False, random_state=None,\n","  shrinking=True, tol=0.001, verbose=False)"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"fAqmsFXFZ14a","colab_type":"code","colab":{}},"source":["y_pred = classifier.predict(X_test_scaled)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"np3Bhx0oZ88r","colab_type":"code","outputId":"04bbf180-82a5-4148-ae96-07978ceefebe","executionInfo":{"status":"ok","timestamp":1554231321543,"user_tz":-330,"elapsed":2156,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.38      0.42      0.40        31\n","           1       0.74      0.36      0.49       174\n","           2       0.61      0.78      0.69       287\n","           3       0.65      0.70      0.67       133\n","\n","   micro avg       0.63      0.63      0.63       625\n","   macro avg       0.60      0.56      0.56       625\n","weighted avg       0.65      0.63      0.61       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bwin4oJnUqdX","colab_type":"code","outputId":"1fac52d4-484a-4f63-e416-313d89ceaeb2","executionInfo":{"status":"error","timestamp":1554179621074,"user_tz":-330,"elapsed":2061,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["import pickle\n","with open(filename, ‘wb’) as f:\n","    pickle.dump(y_train, f)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-e60395f05fb9>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    with open(filename, ‘wb’) as f:\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"]}]},{"cell_type":"code","metadata":{"id":"ZyO3zq1yM3_H","colab_type":"code","colab":{}},"source":["best_model = load_model('./cnn_logfilter_default_40.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NTQAM_EWNDwg","colab_type":"code","colab":{}},"source":["y_pred = best_model.predict(X_test)\n","from sklearn.metrics import classification_report, accuracy_score\n","flag = 0\n","for i in range(len(y_pred)):\n","    flag=0\n","    for j in range(len(y_pred[i])) :\n","        if y_pred[i][j]==max(y_pred[i]) and flag==0:\n","            y_pred[i][j] = 1\n","            flag=1\n","        else:\n","            y_pred[i][j]=0\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zlsQ01BHOsyI","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"adG_FQMINDjG","colab_type":"code","outputId":"0dcfbae8-4965-4771-a586-86c3037cd375","executionInfo":{"status":"ok","timestamp":1554967425228,"user_tz":-330,"elapsed":3244,"user":{"displayName":"Ravi Kant","photoUrl":"https://lh6.googleusercontent.com/-dW0ZO5Vgd1E/AAAAAAAAAAI/AAAAAAAA8rU/LfLVvZDQ6gk/s64/photo.jpg","userId":"10753314378323181478"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00        31\n","           1       0.65      0.47      0.54       174\n","           2       0.62      0.78      0.69       287\n","           3       0.70      0.74      0.72       133\n","\n","   micro avg       0.65      0.65      0.65       625\n","   macro avg       0.49      0.50      0.49       625\n","weighted avg       0.62      0.65      0.62       625\n"," samples avg       0.65      0.65      0.65       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YU7r0UXqNDVL","colab_type":"code","colab":{}},"source":["def lda_loss(n_components, margin):\n","    \"\"\"\n","    The main loss function (inner_lda_objective) is wrapped in this function due to\n","    the constraints imposed by Keras on objective functions\n","    \"\"\"\n","\n","    def inner_lda_objective(y_true, y_pred):\n","        \"\"\"\n","        It is the loss function of LDA as introduced in the original paper.\n","        It is adopted from the the original implementation in the following link:\n","        https://github.com/CPJKU/deep_lda\n","        Note: it is implemented by Theano tensor operations, and does not work on Tensorflow backend\n","        \"\"\"\n","        r = 1e-4\n","\n","        # init groups\n","        # yt = tf.cast(tf.contrib.layers.flatten(y_true), tf.float32)\n","        # indexes = tf.argmax (y_true, axis=-1)\n","        locations = tf.where(tf.equal(y_true, 1))\n","        indices = locations[:, 1]\n","        y, idx = tf.unique(indices)\n","\n","        def fn(unique, indexes, preds):\n","            u_indexes = tf.where(tf.equal(unique, indexes))\n","            u_indexes = tf.reshape(u_indexes, (1, -1))\n","            X = tf.gather(preds, u_indexes)\n","            X_mean = X - tf.reduce_mean(X, axis=0)\n","            m = tf.cast(tf.shape(X_mean)[1], tf.float32)\n","            return (1 / (m - 1)) * tf.matmul(tf.transpose(X_mean[0]), X_mean[0])\n","\n","        # scan over groups\n","        covs_t = tf.map_fn(lambda x: fn(x, indices, y_pred), y, dtype=tf.float32)\n","\n","        # compute average covariance matrix (within scatter)\n","        Sw_t = tf.reduce_mean(covs_t, axis=0)\n","\n","        # compute total scatter\n","        Xt_bar = y_pred - tf.reduce_mean(y_pred, axis=0)\n","        m = tf.cast(tf.shape(Xt_bar)[1], tf.float32)\n","        St_t = (1 / (m - 1)) * tf.matmul(tf.transpose(Xt_bar), Xt_bar)\n","\n","        # compute between scatter\n","        dim = tf.shape(y)[0]\n","        Sb_t = St_t - Sw_t\n","\n","        # cope for numerical instability (regularize)\n","\n","        Sw_t += tf.eye(dim) * r\n","\n","        ''' START : COMPLICATED PART WHERE TENSORFLOW HAS TROUBLE'''\n","\n","        cho = tf.cholesky(St_t + tf.eye(dim) * r)\n","        inv_cho = tf.matrix_inverse(cho)\n","        evals_t = tf.linalg.eigvalsh(inv_cho * Sb_t * tf.transpose(inv_cho + tf.eye(dim) * r))  # Sb_t, St_t # SIMPLIFICATION OF THE EQP USING cholesky\n","        #evals_t = tf.abs(tf.linalg.eigvalsh(tf.matrix_inverse(Sw_t) * Sb_t )) # INVERSED EQUATION\n","        top_k_evals = evals_t[-n_components:]\n","\n","        ''' END : COMPLICATED PART WHERE TENSORFLOW HAS TROUBLE'''\n","\n","        # index_max = tf.argmax(top_k_evals, 0)\n","        # thresh_max = top_k_evals[index_max] - margin\n","\n","        index_min = tf.argmin(top_k_evals, 0)\n","        thresh_min = top_k_evals[index_min] + margin\n","        # thresh = tf.contrib.distributions.percentile(top_k_evals, 33) # TRY TO TAKE A PERCENTILE INSTEAD THAN A THRESOLD\n","        # mask_max = top_k_evals > thresh_max\n","        mask_min = top_k_evals < thresh_min\n","\n","        # cost_max = tf.boolean_mask(top_k_evals, mask_max)\n","        cost_min = tf.boolean_mask(top_k_evals, mask_min)\n","\n","        return - tf.reduce_mean(cost_min)\n","\n","    return inner_lda_objective\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"e5CnbtKGOZAn","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uvd2Aep0NCsO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}