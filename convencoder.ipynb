{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"convencoder.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2eWlqu5oOGR5","colab_type":"code","outputId":"1fccb13a-226c-4668-c661-480da2fa1d6b","executionInfo":{"status":"ok","timestamp":1555326113255,"user_tz":-330,"elapsed":1251,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YOwUmTTgOKK-","colab_type":"code","outputId":"b9f43f18-e00d-45cd-b81e-d312f976816a","executionInfo":{"status":"ok","timestamp":1555326120343,"user_tz":-330,"elapsed":1042,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["cd /content/drive/My Drive/Emotion Recogition/code/python_files"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Emotion Recogition/code/python_files\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pO4SIxQTOKIF","colab_type":"code","outputId":"0819a127-c9b3-40ed-978f-a550e51a21dc","executionInfo":{"status":"ok","timestamp":1555326126170,"user_tz":-330,"elapsed":3657,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import os\n","import sys\n","import pandas as pd\n","import wave\n","import librosa\n","from keras.callbacks import EarlyStopping\n","from sklearn.utils import class_weight\n","from sklearn.utils.class_weight import compute_class_weight\n","import keras\n","from keras.models import Sequential, Model\n","from keras.layers.core import Dense, Activation\n","from keras.layers import LSTM, Input, Flatten,Dropout,GlobalAveragePooling2D,MaxPooling2D\n","from keras.layers.convolutional import Conv2D\n","from keras.models import load_model\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing import sequence\n","from scipy import signal\n","import matplotlib.pyplot as plot\n","from helper import *\n","from features import *\n","from sklearn.preprocessing import LabelEncoder\n","from keras import backend as K"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"koWvKufzOKE_","colab_type":"code","colab":{}},"source":["\n","code_path = os.path.dirname(os.path.realpath(os.getcwd()))\n","emotions_used = np.array(['ang', 'exc', 'neu', 'sad'])\n","data_path = code_path + \"/../data/sessions/\"\n","sessions = ['Session1', 'Session2', 'Session3', 'Session4', 'Session5']\n","framerate = 16000"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"G7Nr_oXDOKDa","colab_type":"code","colab":{}},"source":["import pickle\n","with open(code_path + '/../data/'+'data_collected.pickle', 'rb') as handle:\n","    data2 = pickle.load(handle)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6TlRZayT3ZZJ","colab_type":"code","outputId":"16debd42-1d10-4c94-ca40-4d2cf54b2b97","executionInfo":{"status":"ok","timestamp":1555326158924,"user_tz":-330,"elapsed":5000,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!pip install python_speech_features  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: python_speech_features in /usr/local/lib/python3.6/dist-packages (0.6)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QBelnw-z3iH5","colab_type":"code","colab":{}},"source":["from python_speech_features import mfcc\n","from python_speech_features import logfbank\n","from sklearn.preprocessing import scale\n","import scipy.io.wavfile as wav"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1wRMJtGc3rEI","colab_type":"code","outputId":"01d83794-a5db-4b00-b66a-5affe40665f7","executionInfo":{"status":"ok","timestamp":1555326215080,"user_tz":-330,"elapsed":45275,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["X_train = []# speaker INdependent data creation\n","X_test = []\n","Y_train = []\n","Y_test = []\n","fs = 16e3\n","counter = 0\n","counter1 = 0\n","for ses_mod in data2:\n","    if 'impro' in ses_mod['id'] and ses_mod['emotion'] in emotions_used:\n","        fbank_feat = logfbank(ses_mod['signal'],nfilt=40)\n","        Sxx = np.transpose(fbank_feat)\n","        Sxx = pad_sequence_into_array(Sxx,maxlen=600,value=0)\n","        Sxx = np.transpose(Sxx)\n","        Sxx = scale(Sxx)\n","        Sxx = np.transpose(Sxx)\n","       \n","        \n","        if ses_mod['id'][:5]==\"Ses05\":\n","            counter+=1\n","            X_test.append(Sxx)\n","            Y_test.append(ses_mod['emotion'])\n","        else:\n","            counter1+=1\n","            X_train.append(Sxx)\n","            Y_train.append(ses_mod['emotion'])\n","        \n","print(counter)\n","print(counter1)\n","\n","X_test = np.array(X_test)\n","X_train = np.array(X_train)\n","print(X_train.shape)\n","print(X_test.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["625\n","2034\n","(2034, 40, 300)\n","(625, 40, 300)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J5JkGL0uWZXw","colab_type":"code","outputId":"c621baaf-3fac-44b8-895e-4a3a86237577","executionInfo":{"status":"error","timestamp":1557749431882,"user_tz":-330,"elapsed":1813,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":237}},"source":["# speaker dependent data creation\n","X_train = []\n","Y_train = []\n","fs = 16e3\n","counter1 = 0\n","for ses_mod in data2:\n","    if 'impro' in ses_mod['id'] and ses_mod['emotion'] in emotions_used:\n","        fbank_feat = logfbank(ses_mod['signal'],nfilt=40)\n","        Sxx = np.transpose(fbank_feat)\n","        Sxx = pad_sequence_into_array(Sxx,maxlen=300,value=0)\n","        Sxx = scale(Sxx)\n","        counter1+=1\n","        X_train.append(Sxx)\n","        Y_train.append(ses_mod['emotion'])\n","        \n","print(counter)\n","print(counter1)\n","X_train = np.array(X_train)\n","print(X_train.shape)\n"],"execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-42e9b0d019f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16e3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcounter1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mses_mod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'impro'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mses_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mses_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memotions_used\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfbank_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogfbank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mses_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'signal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfilt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'data2' is not defined"]}]},{"cell_type":"code","metadata":{"id":"JpLVTvEsdoJu","colab_type":"code","colab":{}},"source":["X_train = X_train.reshape(-1,40,300,1)\n","X_test = X_test.reshape(-1,40,300,1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7mn5E2IEd0fu","colab_type":"code","colab":{}},"source":["X_train = []\n","X_test = []\n","Y_train = []\n","Y_test = []\n","fs = 16e3\n","counter = 0\n","counter1 = 0\n","for ses_mod in data2:\n","    if 'impro' in ses_mod['id'] and ses_mod['emotion'] in emotions_used:\n","        f, t, Sxx = signal.spectrogram(ses_mod['signal'], fs, nperseg=400,noverlap=200)\n","        Sxx = pad_sequence_into_array(Sxx,maxlen=300,value=0)\n","        \n","        if ses_mod['id'][:5]==\"Ses05\":\n","            counter+=1\n","            X_test.append(Sxx[0:200,:])\n","            Y_test.append(ses_mod['emotion'])\n","        else:\n","            counter1+=1\n","            X_train.append(Sxx[0:200,:])\n","            Y_train.append(ses_mod['emotion'])\n","        \n","print(counter)\n","print(counter1)\n","\n","X_test = np.array(X_test)\n","X_train = np.array(X_train)\n","print(X_train.shape)\n","print(X_test.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"13c_s6Wxd1_c","colab_type":"code","colab":{}},"source":["X_train = X_train.reshape(-1,200,300,1)\n","X_test = X_test.reshape(-1,200,300,1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dxdQKqJ8YSYh","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,Y_train,Y_test = train_test_split(X_train, Y_train, test_size =0.2, random_state=42)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"4khtgwl4SDNS","colab":{}},"source":["def noise_mix(y,sig): # noise mixing code\n","  n=y[:len(sig)]\n","  n=n-np.mean(n)\n","  n=n/np.sqrt(np.var(n))\n","  vs=np.var(sig)\n","  vn = vs/(np.power(10,(5/10)))#SNR level, here 8dB\n","  n=n*np.sqrt(vn)\n","  nsp=sig+n\n","  nsp=nsp/(max(abs(nsp)*1.01))\n","  return nsp\n","  \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9WNROmop3zVg","colab_type":"code","colab":{}},"source":["y  = pd.get_dummies(Y_train+Y_test)\n","y_train = y[0:len(Y_train)]\n","y_test = y[len(Y_train):]\n","y_train = np.array(y_train)\n","y_test = np.array(y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mfzV3pkkgvha","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":393},"outputId":"dffc5a3a-42dc-4f92-fbd7-5868037e3e98","executionInfo":{"status":"error","timestamp":1557750125843,"user_tz":-330,"elapsed":1991,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}}},"source":["import keras\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import gzip\n","from keras.models import Model\n","from keras.optimizers import RMSprop\n","from keras.layers import Input,Dense,Flatten,Dropout,merge,Reshape,Conv2D,MaxPooling2D,UpSampling2D,Conv2DTranspose\n","from keras.layers.normalization import BatchNormalization,Masking\n","from keras.models import Model,Sequential\n","from keras.callbacks import ModelCheckpoint\n","from keras.optimizers import Adadelta, RMSprop,SGD,Adam\n","from keras import regularizers\n","from keras import backend as K\n","from keras.utils import to_categorical"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"error","ename":"ImportError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-0bcaef8a83d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mReshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mUpSampling2D\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mConv2DTranspose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mMasking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: cannot import name 'Masking'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"code","metadata":{"id":"DCSeGbEJJhyi","colab_type":"code","colab":{}},"source":["batch_size = 64\n","epochs = 50\n","input_i = Input(shape=(40,300,1))\n","num_classes = 4"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JQdDkxYbeTu0","colab_type":"code","colab":{}},"source":["def encoder(input_i):\n","    #encoder\n","    #input = 28 x 28 x 1 (wide and thin)\n","    in_layer = Masking(mask_value=0)(in_layer)\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_i) #28 x 28 x 32\n","    conv1 = BatchNormalization()(conv1)\n","    #conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n","    #conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n","    conv2 = BatchNormalization()(conv2)\n","    #conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n","    #conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n","    conv3 = BatchNormalization()(conv3)\n","    #conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n","    #conv3 = BatchNormalization()(conv3)\n","    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n","    conv4 = BatchNormalization()(conv4)\n","    #conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n","    #conv4 = BatchNormalization()(conv4)\n","    return conv4\n","\n","def decoder(conv4):    \n","    #decoder\n","    conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv4) #7 x 7 x 128\n","    conv5 = BatchNormalization()(conv5)\n","    #conv5 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv5)\n","    #conv5 = BatchNormalization()(conv5)\n","    conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5) #7 x 7 x 64\n","    conv6 = BatchNormalization()(conv6)\n","    #conv6 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv6)\n","    #conv6 = BatchNormalization()(conv6)\n","    up1 = UpSampling2D((2,2))(conv6) #14 x 14 x 64\n","    conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(up1) # 14 x 14 x 32\n","    conv7 = BatchNormalization()(conv7)\n","    #conv7 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv7)\n","    #conv7 = BatchNormalization()(conv7)\n","    up2 = UpSampling2D((2,2))(conv7) # 28 x 28 x 32\n","    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(up2) # 28 x 28 x 1\n","    return decoded"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0i9WZVh3KTjL","colab_type":"code","outputId":"5285317c-b8bf-4bdd-dce0-9f1747abfcbf","executionInfo":{"status":"ok","timestamp":1555328063748,"user_tz":-330,"elapsed":2517,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":833}},"source":["autoencoder_model = Model(input_i,decoder(encoder(input_i)))\n","\n","autoencoder_model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 40, 300, 1)        0         \n","_________________________________________________________________\n","conv2d_30 (Conv2D)           (None, 40, 300, 32)       320       \n","_________________________________________________________________\n","batch_normalization_27 (Batc (None, 40, 300, 32)       128       \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 20, 150, 32)       0         \n","_________________________________________________________________\n","conv2d_31 (Conv2D)           (None, 20, 150, 64)       18496     \n","_________________________________________________________________\n","batch_normalization_28 (Batc (None, 20, 150, 64)       256       \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 10, 75, 64)        0         \n","_________________________________________________________________\n","conv2d_32 (Conv2D)           (None, 10, 75, 128)       73856     \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 10, 75, 128)       512       \n","_________________________________________________________________\n","conv2d_33 (Conv2D)           (None, 10, 75, 256)       295168    \n","_________________________________________________________________\n","batch_normalization_30 (Batc (None, 10, 75, 256)       1024      \n","_________________________________________________________________\n","conv2d_34 (Conv2D)           (None, 10, 75, 128)       295040    \n","_________________________________________________________________\n","batch_normalization_31 (Batc (None, 10, 75, 128)       512       \n","_________________________________________________________________\n","conv2d_35 (Conv2D)           (None, 10, 75, 64)        73792     \n","_________________________________________________________________\n","batch_normalization_32 (Batc (None, 10, 75, 64)        256       \n","_________________________________________________________________\n","up_sampling2d_3 (UpSampling2 (None, 20, 150, 64)       0         \n","_________________________________________________________________\n","conv2d_36 (Conv2D)           (None, 20, 150, 32)       18464     \n","_________________________________________________________________\n","batch_normalization_33 (Batc (None, 20, 150, 32)       128       \n","_________________________________________________________________\n","up_sampling2d_4 (UpSampling2 (None, 40, 300, 32)       0         \n","_________________________________________________________________\n","conv2d_37 (Conv2D)           (None, 40, 300, 1)        289       \n","=================================================================\n","Total params: 778,241\n","Trainable params: 776,833\n","Non-trainable params: 1,408\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"TmA46WyLFhFp","colab_type":"code","outputId":"43f52c48-de34-494c-a2c0-2c27883b37d3","executionInfo":{"status":"ok","timestamp":1555328486521,"user_tz":-330,"elapsed":415162,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":3508}},"source":["autoencoder_model.compile(loss='mean_squared_error', optimizer='Adam')\n","early_stopping_monitor = EarlyStopping( monitor='val_loss',patience=20,verbose=1)\n","m_check = keras.callbacks.ModelCheckpoint(filepath = './cnn_encoder.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1 )\n","autoencoder_train = autoencoder_model.fit(X_train, X_train, batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_test, X_test),shuffle = True,callbacks=[m_check,early_stopping_monitor])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 2034 samples, validate on 625 samples\n","Epoch 1/50\n","2034/2034 [==============================] - 11s 6ms/step - loss: 0.6819 - val_loss: 0.5860\n","\n","Epoch 00001: val_loss improved from inf to 0.58603, saving model to ./cnn_encoder.h5\n","Epoch 2/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.6165 - val_loss: 0.5697\n","\n","Epoch 00002: val_loss improved from 0.58603 to 0.56972, saving model to ./cnn_encoder.h5\n","Epoch 3/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.6036 - val_loss: 0.5658\n","\n","Epoch 00003: val_loss improved from 0.56972 to 0.56583, saving model to ./cnn_encoder.h5\n","Epoch 4/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5953 - val_loss: 0.5583\n","\n","Epoch 00004: val_loss improved from 0.56583 to 0.55827, saving model to ./cnn_encoder.h5\n","Epoch 5/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5895 - val_loss: 0.5522\n","\n","Epoch 00005: val_loss improved from 0.55827 to 0.55219, saving model to ./cnn_encoder.h5\n","Epoch 6/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5855 - val_loss: 0.5491\n","\n","Epoch 00006: val_loss improved from 0.55219 to 0.54909, saving model to ./cnn_encoder.h5\n","Epoch 7/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5827 - val_loss: 0.5451\n","\n","Epoch 00007: val_loss improved from 0.54909 to 0.54513, saving model to ./cnn_encoder.h5\n","Epoch 8/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5808 - val_loss: 0.5439\n","\n","Epoch 00008: val_loss improved from 0.54513 to 0.54393, saving model to ./cnn_encoder.h5\n","Epoch 9/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5789 - val_loss: 0.5411\n","\n","Epoch 00009: val_loss improved from 0.54393 to 0.54113, saving model to ./cnn_encoder.h5\n","Epoch 10/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5776 - val_loss: 0.5398\n","\n","Epoch 00010: val_loss improved from 0.54113 to 0.53981, saving model to ./cnn_encoder.h5\n","Epoch 11/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5769 - val_loss: 0.5393\n","\n","Epoch 00011: val_loss improved from 0.53981 to 0.53928, saving model to ./cnn_encoder.h5\n","Epoch 12/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5757 - val_loss: 0.5378\n","\n","Epoch 00012: val_loss improved from 0.53928 to 0.53782, saving model to ./cnn_encoder.h5\n","Epoch 13/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5748 - val_loss: 0.5368\n","\n","Epoch 00013: val_loss improved from 0.53782 to 0.53682, saving model to ./cnn_encoder.h5\n","Epoch 14/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5741 - val_loss: 0.5362\n","\n","Epoch 00014: val_loss improved from 0.53682 to 0.53620, saving model to ./cnn_encoder.h5\n","Epoch 15/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5734 - val_loss: 0.5356\n","\n","Epoch 00015: val_loss improved from 0.53620 to 0.53564, saving model to ./cnn_encoder.h5\n","Epoch 16/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5730 - val_loss: 0.5353\n","\n","Epoch 00016: val_loss improved from 0.53564 to 0.53534, saving model to ./cnn_encoder.h5\n","Epoch 17/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5725 - val_loss: 0.5352\n","\n","Epoch 00017: val_loss improved from 0.53534 to 0.53523, saving model to ./cnn_encoder.h5\n","Epoch 18/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5721 - val_loss: 0.5346\n","\n","Epoch 00018: val_loss improved from 0.53523 to 0.53462, saving model to ./cnn_encoder.h5\n","Epoch 19/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5716 - val_loss: 0.5340\n","\n","Epoch 00019: val_loss improved from 0.53462 to 0.53401, saving model to ./cnn_encoder.h5\n","Epoch 20/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5713 - val_loss: 0.5336\n","\n","Epoch 00020: val_loss improved from 0.53401 to 0.53362, saving model to ./cnn_encoder.h5\n","Epoch 21/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5708 - val_loss: 0.5333\n","\n","Epoch 00021: val_loss improved from 0.53362 to 0.53327, saving model to ./cnn_encoder.h5\n","Epoch 22/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5706 - val_loss: 0.5341\n","\n","Epoch 00022: val_loss did not improve from 0.53327\n","Epoch 23/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5703 - val_loss: 0.5329\n","\n","Epoch 00023: val_loss improved from 0.53327 to 0.53288, saving model to ./cnn_encoder.h5\n","Epoch 24/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5699 - val_loss: 0.5324\n","\n","Epoch 00024: val_loss improved from 0.53288 to 0.53240, saving model to ./cnn_encoder.h5\n","Epoch 25/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5698 - val_loss: 0.5323\n","\n","Epoch 00025: val_loss improved from 0.53240 to 0.53229, saving model to ./cnn_encoder.h5\n","Epoch 26/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5694 - val_loss: 0.5326\n","\n","Epoch 00026: val_loss did not improve from 0.53229\n","Epoch 27/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5692 - val_loss: 0.5318\n","\n","Epoch 00027: val_loss improved from 0.53229 to 0.53176, saving model to ./cnn_encoder.h5\n","Epoch 28/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5690 - val_loss: 0.5317\n","\n","Epoch 00028: val_loss improved from 0.53176 to 0.53168, saving model to ./cnn_encoder.h5\n","Epoch 29/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5688 - val_loss: 0.5316\n","\n","Epoch 00029: val_loss improved from 0.53168 to 0.53160, saving model to ./cnn_encoder.h5\n","Epoch 30/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5686 - val_loss: 0.5314\n","\n","Epoch 00030: val_loss improved from 0.53160 to 0.53136, saving model to ./cnn_encoder.h5\n","Epoch 31/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5683 - val_loss: 0.5311\n","\n","Epoch 00031: val_loss improved from 0.53136 to 0.53108, saving model to ./cnn_encoder.h5\n","Epoch 32/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5684 - val_loss: 0.5311\n","\n","Epoch 00032: val_loss did not improve from 0.53108\n","Epoch 33/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5681 - val_loss: 0.5308\n","\n","Epoch 00033: val_loss improved from 0.53108 to 0.53077, saving model to ./cnn_encoder.h5\n","Epoch 34/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5679 - val_loss: 0.5310\n","\n","Epoch 00034: val_loss did not improve from 0.53077\n","Epoch 35/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5678 - val_loss: 0.5307\n","\n","Epoch 00035: val_loss improved from 0.53077 to 0.53072, saving model to ./cnn_encoder.h5\n","Epoch 36/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5676 - val_loss: 0.5303\n","\n","Epoch 00036: val_loss improved from 0.53072 to 0.53032, saving model to ./cnn_encoder.h5\n","Epoch 37/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5675 - val_loss: 0.5307\n","\n","Epoch 00037: val_loss did not improve from 0.53032\n","Epoch 38/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5675 - val_loss: 0.5307\n","\n","Epoch 00038: val_loss did not improve from 0.53032\n","Epoch 39/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5673 - val_loss: 0.5300\n","\n","Epoch 00039: val_loss improved from 0.53032 to 0.53005, saving model to ./cnn_encoder.h5\n","Epoch 40/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5671 - val_loss: 0.5299\n","\n","Epoch 00040: val_loss improved from 0.53005 to 0.52985, saving model to ./cnn_encoder.h5\n","Epoch 41/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5669 - val_loss: 0.5299\n","\n","Epoch 00041: val_loss did not improve from 0.52985\n","Epoch 42/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5668 - val_loss: 0.5300\n","\n","Epoch 00042: val_loss did not improve from 0.52985\n","Epoch 43/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5668 - val_loss: 0.5299\n","\n","Epoch 00043: val_loss did not improve from 0.52985\n","Epoch 44/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5667 - val_loss: 0.5297\n","\n","Epoch 00044: val_loss improved from 0.52985 to 0.52974, saving model to ./cnn_encoder.h5\n","Epoch 45/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5666 - val_loss: 0.5293\n","\n","Epoch 00045: val_loss improved from 0.52974 to 0.52934, saving model to ./cnn_encoder.h5\n","Epoch 46/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5663 - val_loss: 0.5297\n","\n","Epoch 00046: val_loss did not improve from 0.52934\n","Epoch 47/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5664 - val_loss: 0.5294\n","\n","Epoch 00047: val_loss did not improve from 0.52934\n","Epoch 48/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5663 - val_loss: 0.5291\n","\n","Epoch 00048: val_loss improved from 0.52934 to 0.52914, saving model to ./cnn_encoder.h5\n","Epoch 49/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5661 - val_loss: 0.5289\n","\n","Epoch 00049: val_loss improved from 0.52914 to 0.52890, saving model to ./cnn_encoder.h5\n","Epoch 50/50\n","2034/2034 [==============================] - 8s 4ms/step - loss: 0.5659 - val_loss: 0.5289\n","\n","Epoch 00050: val_loss did not improve from 0.52890\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tP6_hrS-DC5L","colab_type":"code","colab":{}},"source":["model = load_model('cnn_encoder.h5')\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0SlwHD0vDj2B","colab_type":"code","colab":{}},"source":["from keras.models import Model\n","\n","layer_name = 'lstm_9'\n","intermediate_layer_model = Model(inputs=model.input,\n","                                 outputs=model.get_layer(layer_name).output)\n","output_train = intermediate_layer_model.predict(X_train)\n","output_test =  intermediate_layer_model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q0fA5z5zDt9M","colab_type":"code","outputId":"b599a72a-103c-4558-fdff-bffe0d610373","executionInfo":{"status":"ok","timestamp":1555221113118,"user_tz":-330,"elapsed":1068,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["print(output_train.shape)\n","print(output_test.shape)\n","print(y_train.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(2034, 8)\n","(625, 8)\n","(2034, 4)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2PbwQhCoVtk-","colab_type":"code","outputId":"ef24ad7c-043d-4c4e-8f8c-9c55bb780cc4","executionInfo":{"status":"ok","timestamp":1555150602591,"user_tz":-330,"elapsed":8793,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":281}},"source":["loss = autoencoder_train.history['loss']\n","val_loss = autoencoder_train.history['val_loss']\n","epochs = range(2)\n","plot.figure()\n","plot.plot(epochs, loss, 'bo', label='Training loss')\n","plot.plot(epochs, val_loss, 'b', label='Validation loss')\n","plot.title('Training and validation loss')\n","plot.legend()\n","plot.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYQAAAEICAYAAABfz4NwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIJiZWcoBwczMAAcEMzNL/X8klGVyKRiU2AAAAABJRU5ErkJggg==\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"aldw3hhSV_XO","colab_type":"code","colab":{}},"source":["autoencoder_model.save_weights('autoencoder.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zxQ6L5zhEGxC","colab_type":"code","colab":{}},"source":["def encoder(input_i):\n","    #encoder\n","    #input = 28 x 28 x 1 (wide and thin)\n","    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(input_i) #28 x 28 x 32\n","    conv1 = BatchNormalization()(conv1)\n","    #conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n","    #conv1 = BatchNormalization()(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1) #14 x 14 x 32\n","    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1) #14 x 14 x 64\n","    conv2 = BatchNormalization()(conv2)\n","    #conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n","    #conv2 = BatchNormalization()(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2) #7 x 7 x 64\n","    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2) #7 x 7 x 128 (small and thick)\n","    conv3 = BatchNormalization()(conv3)\n","    #conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n","    #conv3 = BatchNormalization()(conv3)\n","    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3) #7 x 7 x 256 (small and thick)\n","    conv4 = BatchNormalization()(conv4)\n","    #conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n","    #conv4 = BatchNormalization()(conv4)\n","    return conv4"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9hA2fttXOtU","colab_type":"code","colab":{}},"source":["def fc(enco):\n","    flat = Flatten()(enco)\n","    den = Dense(64, activation='relu')(flat)\n","    out = Dense(num_classes, activation='softmax')(den)\n","    return out\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pXNgt65PXQN8","colab_type":"code","colab":{}},"source":["encode = encoder(input_i)\n","full_model = Model(input_i,fc(encode))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mzl0nlLwXUj7","colab_type":"code","colab":{}},"source":["for l1,l2 in zip(full_model.layers[:11],autoencoder_model.layers[0:11]):\n","    l1.set_weights(l2.get_weights())\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tXfTHhoLXY-k","colab_type":"code","outputId":"7cb638b6-cdc6-4381-d206-dcc0df31c819","executionInfo":{"status":"ok","timestamp":1555328931520,"user_tz":-330,"elapsed":1085,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":486}},"source":["autoencoder_model.get_weights()[0][1]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[-0.03381157, -0.01543381,  0.13758959, -0.059755  ,\n","         -0.04564874,  0.06945912, -0.05326904, -0.06326246,\n","          0.12757613,  0.0448797 , -0.02894594, -0.0928357 ,\n","          0.04501045,  0.08550222, -0.02697727,  0.19930366,\n","         -0.00052803, -0.1428507 ,  0.08509213, -0.0152761 ,\n","          0.1400934 ,  0.08349174,  0.02838436, -0.04363441,\n","         -0.05313318, -0.06314511, -0.10586615, -0.07677697,\n","         -0.03427925,  0.06861374, -0.0773773 ,  0.17546473]],\n","\n","       [[-0.10136758, -0.11091016,  0.16236265, -0.0157314 ,\n","          0.00623128,  0.07726742, -0.11009747, -0.03052339,\n","          0.10430571,  0.03728704, -0.11145773, -0.10389713,\n","         -0.07812285, -0.03966625,  0.12041695,  0.2075295 ,\n","          0.09912615, -0.0891383 ,  0.09436707, -0.04796574,\n","          0.03532767,  0.08839517,  0.0270032 , -0.01433109,\n","          0.05892213, -0.09213899, -0.09767716,  0.13671322,\n","          0.04478288,  0.40107328, -0.12421656,  0.13670164]],\n","\n","       [[-0.07687876, -0.1071704 ,  0.06399614,  0.01947568,\n","         -0.03247869, -0.04901   , -0.15311348,  0.02086991,\n","          0.00732874,  0.10768223, -0.08496174,  0.0848007 ,\n","         -0.04178352, -0.09798437, -0.03931471,  0.02893796,\n","          0.14890008, -0.04386022,  0.09163249, -0.07122257,\n","          0.03218373,  0.05651495,  0.01846276, -0.15210353,\n","          0.1274294 , -0.05419602,  0.0227683 ,  0.15481198,\n","         -0.04560858,  0.09002307, -0.08274614, -0.13213974]]],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":64}]},{"cell_type":"code","metadata":{"id":"v1vYVTExXeNU","colab_type":"code","outputId":"2ccfc8cb-36d3-4f91-9bbd-91817ce9bc84","executionInfo":{"status":"ok","timestamp":1555328939660,"user_tz":-330,"elapsed":1342,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":486}},"source":["full_model.get_weights()[0][1]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[-0.03381157, -0.01543381,  0.13758959, -0.059755  ,\n","         -0.04564874,  0.06945912, -0.05326904, -0.06326246,\n","          0.12757613,  0.0448797 , -0.02894594, -0.0928357 ,\n","          0.04501045,  0.08550222, -0.02697727,  0.19930366,\n","         -0.00052803, -0.1428507 ,  0.08509213, -0.0152761 ,\n","          0.1400934 ,  0.08349174,  0.02838436, -0.04363441,\n","         -0.05313318, -0.06314511, -0.10586615, -0.07677697,\n","         -0.03427925,  0.06861374, -0.0773773 ,  0.17546473]],\n","\n","       [[-0.10136758, -0.11091016,  0.16236265, -0.0157314 ,\n","          0.00623128,  0.07726742, -0.11009747, -0.03052339,\n","          0.10430571,  0.03728704, -0.11145773, -0.10389713,\n","         -0.07812285, -0.03966625,  0.12041695,  0.2075295 ,\n","          0.09912615, -0.0891383 ,  0.09436707, -0.04796574,\n","          0.03532767,  0.08839517,  0.0270032 , -0.01433109,\n","          0.05892213, -0.09213899, -0.09767716,  0.13671322,\n","          0.04478288,  0.40107328, -0.12421656,  0.13670164]],\n","\n","       [[-0.07687876, -0.1071704 ,  0.06399614,  0.01947568,\n","         -0.03247869, -0.04901   , -0.15311348,  0.02086991,\n","          0.00732874,  0.10768223, -0.08496174,  0.0848007 ,\n","         -0.04178352, -0.09798437, -0.03931471,  0.02893796,\n","          0.14890008, -0.04386022,  0.09163249, -0.07122257,\n","          0.03218373,  0.05651495,  0.01846276, -0.15210353,\n","          0.1274294 , -0.05419602,  0.0227683 ,  0.15481198,\n","         -0.04560858,  0.09002307, -0.08274614, -0.13213974]]],\n","      dtype=float32)"]},"metadata":{"tags":[]},"execution_count":65}]},{"cell_type":"code","metadata":{"id":"ukBdVSpeXkzb","colab_type":"code","colab":{}},"source":["for layer in full_model.layers[0:11]:\n","    layer.trainable = False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"h7iIHRBuXs1M","colab_type":"code","colab":{}},"source":["full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uxf2aE40X2c7","colab_type":"code","outputId":"3416014c-aedc-48bb-ea4a-33126680fa1b","executionInfo":{"status":"ok","timestamp":1555328950947,"user_tz":-330,"elapsed":1162,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":625}},"source":["full_model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_3 (InputLayer)         (None, 40, 300, 1)        0         \n","_________________________________________________________________\n","conv2d_46 (Conv2D)           (None, 40, 300, 32)       320       \n","_________________________________________________________________\n","batch_normalization_42 (Batc (None, 40, 300, 32)       128       \n","_________________________________________________________________\n","max_pooling2d_13 (MaxPooling (None, 20, 150, 32)       0         \n","_________________________________________________________________\n","conv2d_47 (Conv2D)           (None, 20, 150, 64)       18496     \n","_________________________________________________________________\n","batch_normalization_43 (Batc (None, 20, 150, 64)       256       \n","_________________________________________________________________\n","max_pooling2d_14 (MaxPooling (None, 10, 75, 64)        0         \n","_________________________________________________________________\n","conv2d_48 (Conv2D)           (None, 10, 75, 128)       73856     \n","_________________________________________________________________\n","batch_normalization_44 (Batc (None, 10, 75, 128)       512       \n","_________________________________________________________________\n","conv2d_49 (Conv2D)           (None, 10, 75, 256)       295168    \n","_________________________________________________________________\n","batch_normalization_45 (Batc (None, 10, 75, 256)       1024      \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 192000)            0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 64)                12288064  \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 4)                 260       \n","=================================================================\n","Total params: 12,678,084\n","Trainable params: 12,288,324\n","Non-trainable params: 389,760\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VTUJDR0MX3tr","colab_type":"code","outputId":"c5654269-95ec-40ea-9753-3f0e717c4c28","executionInfo":{"status":"ok","timestamp":1555329050278,"user_tz":-330,"elapsed":63045,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":1511}},"source":["Y_label = ( [np.where(r==1)[0][0] for r in y_train] )\n","early_stopping_monitor = EarlyStopping( monitor='val_loss',patience=20,verbose=1)\n","m_check = keras.callbacks.ModelCheckpoint(filepath = './lstm_encoder.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1 )\n","classify_train = full_model.fit(X_train, y_train, batch_size=64,epochs=50,verbose=1,validation_data=(X_test, y_test),shuffle = True,callbacks=[m_check,early_stopping_monitor],class_weight = class_weight.compute_class_weight(\"balanced\", np.unique(Y_label), Y_label))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 2034 samples, validate on 625 samples\n","Epoch 1/50\n","2034/2034 [==============================] - 6s 3ms/step - loss: 9.4774 - acc: 0.3918 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00001: val_loss improved from inf to 8.71667, saving model to ./lstm_encoder.h5\n","Epoch 2/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00002: val_loss did not improve from 8.71667\n","Epoch 3/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00003: val_loss did not improve from 8.71667\n","Epoch 4/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00004: val_loss did not improve from 8.71667\n","Epoch 5/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00005: val_loss did not improve from 8.71667\n","Epoch 6/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00006: val_loss did not improve from 8.71667\n","Epoch 7/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00007: val_loss did not improve from 8.71667\n","Epoch 8/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00008: val_loss did not improve from 8.71667\n","Epoch 9/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00009: val_loss did not improve from 8.71667\n","Epoch 10/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00010: val_loss did not improve from 8.71667\n","Epoch 11/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00011: val_loss did not improve from 8.71667\n","Epoch 12/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00012: val_loss did not improve from 8.71667\n","Epoch 13/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00013: val_loss did not improve from 8.71667\n","Epoch 14/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00014: val_loss did not improve from 8.71667\n","Epoch 15/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00015: val_loss did not improve from 8.71667\n","Epoch 16/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00016: val_loss did not improve from 8.71667\n","Epoch 17/50\n","2034/2034 [==============================] - 3s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00017: val_loss did not improve from 8.71667\n","Epoch 18/50\n","2034/2034 [==============================] - 2s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00018: val_loss did not improve from 8.71667\n","Epoch 19/50\n","2034/2034 [==============================] - 2s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00019: val_loss did not improve from 8.71667\n","Epoch 20/50\n","2034/2034 [==============================] - 2s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00020: val_loss did not improve from 8.71667\n","Epoch 21/50\n","2034/2034 [==============================] - 2s 1ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00021: val_loss did not improve from 8.71667\n","Epoch 00021: early stopping\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_-Gn6NGvkQvB","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"MeLbF1_0X-hG","colab_type":"code","colab":{}},"source":["full_model.save_weights('autoencoder_classification.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P2Fzkn0TYE4U","colab_type":"code","colab":{}},"source":["for layer in full_model.layers[0:11]:\n","    layer.trainable = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q1ZvtxE7YJWt","colab_type":"code","colab":{}},"source":["full_model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(),metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Z61RKQZYSEz","colab_type":"code","outputId":"9a6e153b-befe-43fc-9e62-902b3e8e4ea8","executionInfo":{"status":"ok","timestamp":1555328848798,"user_tz":-330,"elapsed":113946,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":1511}},"source":["Y_label = ( [np.where(r==1)[0][0] for r in y_train] )\n","early_stopping_monitor = EarlyStopping( monitor='val_loss',patience=20,verbose=1)\n","m_check = keras.callbacks.ModelCheckpoint(filepath = './lstm_encoder.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1 )\n","classify_train = full_model.fit(X_train, y_train, batch_size=64,epochs=50,verbose=1,validation_data=(X_test, y_test),shuffle = True,callbacks=[m_check,early_stopping_monitor],class_weight = class_weight.compute_class_weight(\"balanced\", np.unique(Y_label), Y_label))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train on 2034 samples, validate on 625 samples\n","Epoch 1/50\n","2034/2034 [==============================] - 9s 4ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00001: val_loss improved from inf to 8.71667, saving model to ./lstm_encoder.h5\n","Epoch 2/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00002: val_loss did not improve from 8.71667\n","Epoch 3/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00003: val_loss did not improve from 8.71667\n","Epoch 4/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00004: val_loss did not improve from 8.71667\n","Epoch 5/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00005: val_loss did not improve from 8.71667\n","Epoch 6/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00006: val_loss did not improve from 8.71667\n","Epoch 7/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00007: val_loss did not improve from 8.71667\n","Epoch 8/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00008: val_loss did not improve from 8.71667\n","Epoch 9/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00009: val_loss did not improve from 8.71667\n","Epoch 10/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00010: val_loss did not improve from 8.71667\n","Epoch 11/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00011: val_loss did not improve from 8.71667\n","Epoch 12/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00012: val_loss did not improve from 8.71667\n","Epoch 13/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00013: val_loss did not improve from 8.71667\n","Epoch 14/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00014: val_loss did not improve from 8.71667\n","Epoch 15/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00015: val_loss did not improve from 8.71667\n","Epoch 16/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00016: val_loss did not improve from 8.71667\n","Epoch 17/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00017: val_loss did not improve from 8.71667\n","Epoch 18/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00018: val_loss did not improve from 8.71667\n","Epoch 19/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00019: val_loss did not improve from 8.71667\n","Epoch 20/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00020: val_loss did not improve from 8.71667\n","Epoch 21/50\n","2034/2034 [==============================] - 5s 2ms/step - loss: 9.6835 - acc: 0.3992 - val_loss: 8.7167 - val_acc: 0.4592\n","\n","Epoch 00021: val_loss did not improve from 8.71667\n","Epoch 00021: early stopping\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eZnT0-cAYRzS","colab_type":"code","colab":{}},"source":["full_model.save_weights('classification_complete.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LPdG9KApYhve","colab_type":"code","outputId":"31b7b15b-567a-4d46-a38d-1d31bf330b4d","executionInfo":{"status":"ok","timestamp":1555152295259,"user_tz":-330,"elapsed":2097,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":545}},"source":["accuracy = classify_train.history['acc']\n","val_accuracy = classify_train.history['val_acc']\n","loss = classify_train.history['loss']\n","val_loss = classify_train.history['val_loss']\n","epochs = range(len(accuracy))\n","plot.plot(epochs, accuracy, 'bo', label='Training accuracy')\n","plot.plot(epochs, val_accuracy, 'b', label='Validation accuracy')\n","plot.title('Training and validation accuracy')\n","plot.legend()\n","plot.figure()\n","plot.plot(epochs, loss, 'bo', label='Training loss')\n","plot.plot(epochs, val_loss, 'b', label='Validation loss')\n","plot.title('Training and validation loss')\n","plot.legend()\n","plot.show()"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nle7vAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"oZ695D8zAjv6","colab_type":"code","outputId":"9c7d1b59-a177-417b-8bca-598609d98271","executionInfo":{"status":"error","timestamp":1555239198458,"user_tz":-330,"elapsed":17478,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":231}},"source":["X_test = [] #noisyy_testdata\n","fs = 16e3\n","counter = 0\n","counter1 = 0\n","y, sr =librosa.load('SIGNAL003-20kHz.wav')\n","y = librosa.resample(y, sr, 16000)\n","for ses_mod in data2:\n","    if 'impro' in ses_mod['id'] and ses_mod['emotion'] in emotions_used:\n","        if ses_mod['id'][:5]==\"Ses05\":\n","            noise = noise_mix(y,ses_mod['signal'])\n","            fbank_feat = logfbank(noise,nfilt=40)\n","            Sxx = np.transpose(fbank_feat)\n","            Sxx = pad_sequence_into_array(Sxx,maxlen=300,value=0)\n","            Sxx = scale(Sxx)\n","            Sxx = np.transpose(Sxx)\n","            counter+=1\n","            X_test.append(Sxx)\n","            \n","      \n","print(counter)\n","\n","X_test = np.array(X_test)\n","print(X_test.shape)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-2f807db6cff9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'impro'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mses_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mses_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'emotion'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0memotions_used\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mses_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"Ses05\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnoise_mix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mses_mod\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'signal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mfbank_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogfbank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnfilt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mSxx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbank_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'noise_mix' is not defined"]}]},{"cell_type":"code","metadata":{"id":"0G6lOstrVd8V","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report, accuracy_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UTeRPFirWRB1","colab_type":"code","colab":{}},"source":["for i in range(len(y_pred)):\n","  for j in range(len(y_pred[i])) :\n","    if y_pred[i][j]==max(y_pred[i]) :\n","      y_pred[i][j] = 1\n","    else:\n","      y_pred[i][j]=0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C01qBWAkW4T8","colab_type":"code","outputId":"a2ec257e-82bb-422b-c658-b458ee22747f","executionInfo":{"status":"ok","timestamp":1553971869158,"user_tz":-330,"elapsed":3362,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["print(y_pred)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0. 0. 1. 0.]\n"," [1. 0. 0. 0.]\n"," [1. 0. 0. 0.]\n"," ...\n"," [0. 0. 1. 0.]\n"," [0. 0. 1. 0.]\n"," [0. 1. 0. 0.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gpLk_uYlV_Su","colab_type":"code","outputId":"57b72d92-9306-42ee-c41f-299b6178eb9b","executionInfo":{"status":"ok","timestamp":1551810757359,"user_tz":-330,"elapsed":1276,"user":{"displayName":"Rahul Kumar","photoUrl":"","userId":"17651844698397356196"}},"colab":{"base_uri":"https://localhost:8080/","height":218}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.34      0.45      0.39        31\n","           1       0.65      0.48      0.55       174\n","           2       0.65      0.78      0.71       287\n","           3       0.77      0.64      0.70       133\n","\n","   micro avg       0.65      0.65      0.65       625\n","   macro avg       0.60      0.59      0.59       625\n","weighted avg       0.66      0.65      0.65       625\n"," samples avg       0.65      0.65      0.65       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B-Opj0t0Y2Z8","colab_type":"code","outputId":"f2224932-b379-4f36-d394-54f57bb24038","executionInfo":{"status":"ok","timestamp":1551811276766,"user_tz":-330,"elapsed":2300,"user":{"displayName":"Rahul Kumar","photoUrl":"","userId":"17651844698397356196"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["accuracy_score(y_pred, y_test)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6512"]},"metadata":{"tags":[]},"execution_count":75}]},{"cell_type":"code","metadata":{"id":"DzOkgq8I1P8N","colab_type":"code","colab":{}},"source":["labelencoder = LabelEncoder()\n","y_train = labelencoder.fit_transform(Y_train)\n","y_test = labelencoder.transform(Y_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qHv3MDCAykqP","colab_type":"code","colab":{}},"source":["from xgboost import XGBClassifier\n","from xgboost import plot_importance\n","from sklearn.feature_selection import SelectFromModel\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ssplSzhgy3-I","colab_type":"code","colab":{}},"source":["xg_model = XGBClassifier(n_estimators=100,learning_rate=0.2,max_depth=7,objective = 'multi:softmax',\n","                       num_class=4,n_jobs=-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"feeWa5sHzmRD","colab_type":"code","outputId":"331ba57f-1393-4f8c-f1fe-2ed3e3f6f024","executionInfo":{"status":"ok","timestamp":1554041257936,"user_tz":-330,"elapsed":10283,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["xg_model.fit(output_train,y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","       colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n","       max_depth=7, min_child_weight=1, missing=None, n_estimators=100,\n","       n_jobs=-1, nthread=None, num_class=4, objective='multi:softprob',\n","       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n","       seed=None, silent=True, subsample=1)"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"26Ly1lhWCiRt","colab_type":"code","colab":{}},"source":["plot_importance(xg_model)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sZXfX2BHDGa2","colab_type":"code","colab":{}},"source":["thresholds = np.sort(xg_model.feature_importances_)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7HTrtqHQDMuf","colab_type":"code","colab":{}},"source":["# select features using threshold\n","selection = SelectFromModel(xg_model, threshold=0.005, prefit=True)\n","X_train = selection.transform(output_train)\n","X_test = selection.transform(output_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vowSx-kEGoU","colab_type":"code","colab":{}},"source":["xg_model1 = XGBClassifier(n_estimators=100,learning_rate=0.2,max_depth=7,objective = 'multi:softmax',\n","                       num_class=4,n_jobs=-1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uyt9tRRfENRV","colab_type":"code","outputId":"ea021eba-a78a-4612-bb19-ccab04877b3f","executionInfo":{"status":"ok","timestamp":1554041319404,"user_tz":-330,"elapsed":8136,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"source":["xg_model1.fit(X_train,y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n","       colsample_bytree=1, gamma=0, learning_rate=0.2, max_delta_step=0,\n","       max_depth=7, min_child_weight=1, missing=None, n_estimators=100,\n","       n_jobs=-1, nthread=None, num_class=4, objective='multi:softprob',\n","       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n","       seed=None, silent=True, subsample=1)"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"vllJ4a_dEV6I","colab_type":"code","colab":{}},"source":["y_pred = xg_model1.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"csjndJ7lEmzA","colab_type":"code","outputId":"6e0d17eb-92f3-4bc4-af0b-f9fc89ba5fb5","executionInfo":{"status":"ok","timestamp":1554041292290,"user_tz":-330,"elapsed":1351,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["X_train.shape"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(2034, 114)"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"code","metadata":{"id":"KeORDK-0EgWD","colab_type":"code","outputId":"98f7b1b1-db64-4add-f220-2b44f6d3be84","executionInfo":{"status":"ok","timestamp":1554041331067,"user_tz":-330,"elapsed":1102,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.20      0.26      0.22        31\n","           1       0.64      0.44      0.52       174\n","           2       0.63      0.69      0.66       287\n","           3       0.64      0.71      0.67       133\n","\n","   micro avg       0.60      0.60      0.60       625\n","   macro avg       0.53      0.52      0.52       625\n","weighted avg       0.61      0.60      0.60       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bw34TJnSy3yW","colab_type":"code","colab":{}},"source":["y_pred = xg_model.predict(output_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-n5JEZxR4OcE","colab_type":"code","outputId":"119415b4-4b54-4bd1-a414-ca6ea5828367","executionInfo":{"status":"ok","timestamp":1553972240881,"user_tz":-330,"elapsed":1930,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.23      0.29      0.26        31\n","           1       0.62      0.44      0.51       174\n","           2       0.63      0.68      0.65       287\n","           3       0.63      0.72      0.67       133\n","\n","   micro avg       0.60      0.60      0.60       625\n","   macro avg       0.53      0.53      0.52       625\n","weighted avg       0.61      0.60      0.60       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SRaIvOWzAjTo","colab_type":"code","colab":{}},"source":["# Fitting Random Forest Classification to the Training set\n","from sklearn.ensemble import RandomForestClassifier\n","classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0,n_jobs=-1)\n","#classifier.fit(output_train, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mm32c--oBRJH","colab_type":"code","colab":{}},"source":["y_pred = classifier.predict(output_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nGeLqCwJBoZG","colab_type":"code","outputId":"6661c282-dedd-4879-c201-6bece0ef9400","executionInfo":{"status":"ok","timestamp":1554041388593,"user_tz":-330,"elapsed":1859,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.24      0.26      0.25        31\n","           1       0.63      0.45      0.52       174\n","           2       0.65      0.72      0.68       287\n","           3       0.67      0.74      0.70       133\n","\n","   micro avg       0.63      0.63      0.63       625\n","   macro avg       0.55      0.54      0.54       625\n","weighted avg       0.63      0.63      0.62       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IwmeZ7OBFpL6","colab_type":"code","colab":{}},"source":["from mlxtend.evaluate import confusion_matrix\n","m = confusion_matrix(y_target=y_test, \n","                      y_predicted=y_pred, \n","                      binary=False)\n","print(m)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ayCfbRlZFs2R","colab_type":"code","colab":{}},"source":["# Applying Grid Search to find the best model and the best parameters\n","from sklearn.model_selection import GridSearchCV\n","parameters = {'bootstrap': [True, False],\n"," 'max_depth': [10, 20, 40,None],\n"," 'max_features': ['auto', 'sqrt'],\n"," 'n_estimators': [80,100,150,400]}\n","grid_search = GridSearchCV(estimator = classifier,\n","                           param_grid = parameters,\n","                           scoring = 'accuracy',\n","                           cv = 10,\n","                           n_jobs = -1)\n","grid_search = grid_search.fit(output_train, y_train)\n","best_accuracy = grid_search.best_score_\n","best_parameters = grid_search.best_params_\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DXVhzY8lk8Ou","colab_type":"code","outputId":"774077f5-8206-438a-a561-0b4b5af9dd4f","executionInfo":{"status":"ok","timestamp":1554222011254,"user_tz":-330,"elapsed":771381,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["best_parameters"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'bootstrap': True,\n"," 'max_depth': 20,\n"," 'max_features': 'auto',\n"," 'n_estimators': 80}"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"vKHc8leSEwLQ","colab_type":"code","outputId":"a2bac56d-6dc1-4012-b46b-09c05974aa5e","executionInfo":{"status":"ok","timestamp":1554225781286,"user_tz":-330,"elapsed":4030,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["best_accuracy"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.6647000983284169"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"SbK_rhZsE4kd","colab_type":"code","outputId":"8d2ffcb7-047c-4580-99c5-0a4fb634fb77","executionInfo":{"status":"ok","timestamp":1554225966955,"user_tz":-330,"elapsed":5148,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":134}},"source":["classifier = RandomForestClassifier(n_estimators = 80, bootstrap=True,criterion = 'entropy', max_depth=20,max_features='auto',n_jobs=-1)\n","classifier.fit(output_train, y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n","            max_depth=20, max_features='auto', max_leaf_nodes=None,\n","            min_impurity_decrease=0.0, min_impurity_split=None,\n","            min_samples_leaf=1, min_samples_split=2,\n","            min_weight_fraction_leaf=0.0, n_estimators=80, n_jobs=-1,\n","            oob_score=False, random_state=None, verbose=0,\n","            warm_start=False)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"code","metadata":{"id":"wsc67rvAFUwb","colab_type":"code","colab":{}},"source":["y_pred = classifier.predict(output_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZYToa7mBFoK_","colab_type":"code","outputId":"56eb6c74-06b3-4ceb-ce5c-fc070f15ae07","executionInfo":{"status":"ok","timestamp":1554226034384,"user_tz":-330,"elapsed":4051,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.24      0.26      0.25        31\n","           1       0.64      0.43      0.51       174\n","           2       0.64      0.73      0.68       287\n","           3       0.66      0.73      0.70       133\n","\n","   micro avg       0.62      0.62      0.62       625\n","   macro avg       0.55      0.54      0.53       625\n","weighted avg       0.62      0.62      0.62       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WDvOGt6AHUph","colab_type":"code","colab":{}},"source":["# Feature Scaling\n","from sklearn.preprocessing import StandardScaler\n","sc = StandardScaler()\n","X_train_scaled = sc.fit_transform(output_train)\n","X_test_scaled = sc.transform(output_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rV4NuPziIKUq","colab_type":"code","colab":{}},"source":["from sklearn.svm import SVC\n","classifier = SVC(kernel = 'rbf', random_state = 0)\n","#classifier.fit(X_train_scaled, y_train)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"T6H-Ld7BIdpl","colab_type":"code","colab":{}},"source":["y_pred = classifier.predict(X_test_scaled)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jNWu9thcIqi3","colab_type":"code","outputId":"fd2241bb-5502-4261-d2cc-3c8050063b36","executionInfo":{"status":"ok","timestamp":1554226826594,"user_tz":-330,"elapsed":5021,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.30      0.23      0.26        31\n","           1       0.65      0.41      0.50       174\n","           2       0.62      0.76      0.69       287\n","           3       0.67      0.72      0.70       133\n","\n","   micro avg       0.63      0.63      0.63       625\n","   macro avg       0.56      0.53      0.54       625\n","weighted avg       0.62      0.63      0.61       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kRHYjop8JHhX","colab_type":"code","outputId":"fa0eddb7-5279-486e-e15c-c9ff2b72f901","executionInfo":{"status":"ok","timestamp":1554230827690,"user_tz":-330,"elapsed":3883285,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":70}},"source":["# Applying Grid Search to find the best model and the best parameters\n","from sklearn.model_selection import GridSearchCV\n","parameters = [{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n","              {'C': [1, 10, 100, 1000], 'kernel': ['rbf'], 'gamma': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}]\n","grid_search = GridSearchCV(estimator = classifier,\n","                           param_grid = parameters,\n","                           scoring = 'accuracy',\n","                           cv = 10,\n","                           n_jobs = -1)\n","grid_search = grid_search.fit(X_train_scaled, y_train)\n","best_accuracy = grid_search.best_score_\n","best_parameters = grid_search.best_params_"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n","  DeprecationWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"k1GB7NM6ZuJW","colab_type":"code","outputId":"5912bb8e-b8cb-442d-b5ef-d28e58dd1862","executionInfo":{"status":"ok","timestamp":1554231272008,"user_tz":-330,"elapsed":3481,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["best_parameters"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'C': 1, 'kernel': 'linear'}"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"id":"M4Jq3n-mZXgy","colab_type":"code","outputId":"76307d9d-6391-44cb-8889-ec241fcbe316","executionInfo":{"status":"ok","timestamp":1554231282577,"user_tz":-330,"elapsed":2885,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"source":["from sklearn.svm import SVC\n","classifier = SVC(kernel = 'linear', C=1)\n","classifier.fit(X_train_scaled, y_train)"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n","  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n","  kernel='linear', max_iter=-1, probability=False, random_state=None,\n","  shrinking=True, tol=0.001, verbose=False)"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"fAqmsFXFZ14a","colab_type":"code","colab":{}},"source":["y_pred = classifier.predict(X_test_scaled)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"np3Bhx0oZ88r","colab_type":"code","outputId":"04bbf180-82a5-4148-ae96-07978ceefebe","executionInfo":{"status":"ok","timestamp":1554231321543,"user_tz":-330,"elapsed":2156,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.38      0.42      0.40        31\n","           1       0.74      0.36      0.49       174\n","           2       0.61      0.78      0.69       287\n","           3       0.65      0.70      0.67       133\n","\n","   micro avg       0.63      0.63      0.63       625\n","   macro avg       0.60      0.56      0.56       625\n","weighted avg       0.65      0.63      0.61       625\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Bwin4oJnUqdX","colab_type":"code","outputId":"1fac52d4-484a-4f63-e416-313d89ceaeb2","executionInfo":{"status":"error","timestamp":1554179621074,"user_tz":-330,"elapsed":2061,"user":{"displayName":"Rahul Kumar","photoUrl":"https://lh6.googleusercontent.com/-sipN3JvLZqw/AAAAAAAAAAI/AAAAAAAAARc/PRMPLKAQSf4/s64/photo.jpg","userId":"13729899591725078352"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["import pickle\n","with open(filename, wb) as f:\n","    pickle.dump(y_train, f)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-e60395f05fb9>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    with open(filename, wb) as f:\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character in identifier\n"]}]},{"cell_type":"code","metadata":{"id":"Fj-osMvtYAdM","colab_type":"code","colab":{}},"source":["def lstm_model():\n","    model = Sequential()\n","    model.add(LSTM(256, return_sequences=True, input_shape=(300, 40)))\n","    model.add(LSTM(256, return_sequences=False))\n","    model.add(Dense(512))\n","    model.add(Activation('relu'))\n","    model.add(Dense(4))\n","    model.add(Activation('softmax'))\n","\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","    return model\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"12YUDGtsYKoU","colab_type":"code","outputId":"90dcd42c-b625-4ad8-d722-2ebfd6a3eee1","executionInfo":{"status":"ok","timestamp":1554985879646,"user_tz":-330,"elapsed":2251,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":347}},"source":["model = lstm_model()\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","lstm_3 (LSTM)                (None, 300, 256)          304128    \n","_________________________________________________________________\n","lstm_4 (LSTM)                (None, 256)               525312    \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 512)               131584    \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 512)               0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 4)                 2052      \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 4)                 0         \n","=================================================================\n","Total params: 963,076\n","Trainable params: 963,076\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xpiWrk_1YO0M","colab_type":"code","outputId":"4a248b92-ff42-4f90-bd6d-296bfa88e728","executionInfo":{"status":"ok","timestamp":1554990257945,"user_tz":-330,"elapsed":4256402,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":3615}},"source":["model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\",\n","                    metrics=[\"accuracy\"])\n","m_check = keras.callbacks.ModelCheckpoint(filepath = './lstm_spectrogram.h5', monitor='val_acc', save_best_only=True, mode='max', verbose=1 )\n","hist = model.fit(X_train, y_train, \n","                 batch_size=32, validation_data=(X_test,y_test),nb_epoch=50, verbose=1, shuffle = True,callbacks=[m_check] \n","                )"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \"\"\"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 2034 samples, validate on 625 samples\n","Epoch 1/50\n","2034/2034 [==============================] - 93s 46ms/step - loss: 1.2372 - acc: 0.4459 - val_loss: 1.2145 - val_acc: 0.4416\n","\n","Epoch 00001: val_acc improved from -inf to 0.44160, saving model to ./lstm_spectrogram.h5\n","Epoch 2/50\n","2034/2034 [==============================] - 89s 44ms/step - loss: 1.1896 - acc: 0.4582 - val_loss: 1.1444 - val_acc: 0.4032\n","\n","Epoch 00002: val_acc did not improve from 0.44160\n","Epoch 3/50\n","2034/2034 [==============================] - 89s 44ms/step - loss: 1.1742 - acc: 0.4695 - val_loss: 1.1453 - val_acc: 0.5136\n","\n","Epoch 00003: val_acc improved from 0.44160 to 0.51360, saving model to ./lstm_spectrogram.h5\n","Epoch 4/50\n","2034/2034 [==============================] - 90s 44ms/step - loss: 1.1823 - acc: 0.4479 - val_loss: 1.2146 - val_acc: 0.4688\n","\n","Epoch 00004: val_acc did not improve from 0.51360\n","Epoch 5/50\n","2034/2034 [==============================] - 89s 44ms/step - loss: 1.1166 - acc: 0.4956 - val_loss: 1.1100 - val_acc: 0.4896\n","\n","Epoch 00005: val_acc did not improve from 0.51360\n","Epoch 6/50\n","2034/2034 [==============================] - 87s 43ms/step - loss: 1.0416 - acc: 0.5098 - val_loss: 1.0685 - val_acc: 0.5008\n","\n","Epoch 00006: val_acc did not improve from 0.51360\n","Epoch 7/50\n","2034/2034 [==============================] - 87s 43ms/step - loss: 1.0884 - acc: 0.5093 - val_loss: 1.1059 - val_acc: 0.5264\n","\n","Epoch 00007: val_acc improved from 0.51360 to 0.52640, saving model to ./lstm_spectrogram.h5\n","Epoch 8/50\n","2034/2034 [==============================] - 87s 43ms/step - loss: 1.1232 - acc: 0.4730 - val_loss: 1.2589 - val_acc: 0.2400\n","\n","Epoch 00008: val_acc did not improve from 0.52640\n","Epoch 9/50\n","2034/2034 [==============================] - 86s 42ms/step - loss: 1.1852 - acc: 0.4612 - val_loss: 1.1140 - val_acc: 0.5056\n","\n","Epoch 00009: val_acc did not improve from 0.52640\n","Epoch 10/50\n","2034/2034 [==============================] - 86s 42ms/step - loss: 1.0678 - acc: 0.5029 - val_loss: 1.1443 - val_acc: 0.4272\n","\n","Epoch 00010: val_acc did not improve from 0.52640\n","Epoch 11/50\n","2034/2034 [==============================] - 87s 43ms/step - loss: 1.0554 - acc: 0.5216 - val_loss: 1.2858 - val_acc: 0.5040\n","\n","Epoch 00011: val_acc did not improve from 0.52640\n","Epoch 12/50\n","2034/2034 [==============================] - 87s 43ms/step - loss: 1.0865 - acc: 0.4951 - val_loss: 1.1355 - val_acc: 0.4720\n","\n","Epoch 00012: val_acc did not improve from 0.52640\n","Epoch 13/50\n","2034/2034 [==============================] - 87s 43ms/step - loss: 1.0542 - acc: 0.4897 - val_loss: 1.1217 - val_acc: 0.4384\n","\n","Epoch 00013: val_acc did not improve from 0.52640\n","Epoch 14/50\n","2034/2034 [==============================] - 84s 41ms/step - loss: 1.0023 - acc: 0.5113 - val_loss: 1.0227 - val_acc: 0.5296\n","\n","Epoch 00014: val_acc improved from 0.52640 to 0.52960, saving model to ./lstm_spectrogram.h5\n","Epoch 15/50\n","2034/2034 [==============================] - 82s 40ms/step - loss: 1.0268 - acc: 0.5344 - val_loss: 1.0649 - val_acc: 0.5328\n","\n","Epoch 00015: val_acc improved from 0.52960 to 0.53280, saving model to ./lstm_spectrogram.h5\n","Epoch 16/50\n","2034/2034 [==============================] - 81s 40ms/step - loss: 1.0122 - acc: 0.5172 - val_loss: 1.1701 - val_acc: 0.4560\n","\n","Epoch 00016: val_acc did not improve from 0.53280\n","Epoch 17/50\n","2034/2034 [==============================] - 81s 40ms/step - loss: 0.9918 - acc: 0.5447 - val_loss: 1.0254 - val_acc: 0.5776\n","\n","Epoch 00017: val_acc improved from 0.53280 to 0.57760, saving model to ./lstm_spectrogram.h5\n","Epoch 18/50\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.9773 - acc: 0.5590 - val_loss: 1.0248 - val_acc: 0.5696\n","\n","Epoch 00018: val_acc did not improve from 0.57760\n","Epoch 19/50\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.9320 - acc: 0.5678 - val_loss: 1.0618 - val_acc: 0.5168\n","\n","Epoch 00019: val_acc did not improve from 0.57760\n","Epoch 20/50\n","2034/2034 [==============================] - 81s 40ms/step - loss: 0.9690 - acc: 0.5482 - val_loss: 1.0478 - val_acc: 0.5008\n","\n","Epoch 00020: val_acc did not improve from 0.57760\n","Epoch 21/50\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.9300 - acc: 0.5787 - val_loss: 1.1094 - val_acc: 0.5344\n","\n","Epoch 00021: val_acc did not improve from 0.57760\n","Epoch 22/50\n","2034/2034 [==============================] - 83s 41ms/step - loss: 0.9197 - acc: 0.5654 - val_loss: 1.0309 - val_acc: 0.5552\n","\n","Epoch 00022: val_acc did not improve from 0.57760\n","Epoch 23/50\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.9295 - acc: 0.5737 - val_loss: 1.0899 - val_acc: 0.5376\n","\n","Epoch 00023: val_acc did not improve from 0.57760\n","Epoch 24/50\n","2034/2034 [==============================] - 83s 41ms/step - loss: 0.9090 - acc: 0.5949 - val_loss: 1.0068 - val_acc: 0.5856\n","\n","Epoch 00024: val_acc improved from 0.57760 to 0.58560, saving model to ./lstm_spectrogram.h5\n","Epoch 25/50\n","2034/2034 [==============================] - 84s 41ms/step - loss: 0.9363 - acc: 0.5737 - val_loss: 0.9929 - val_acc: 0.6064\n","\n","Epoch 00025: val_acc improved from 0.58560 to 0.60640, saving model to ./lstm_spectrogram.h5\n","Epoch 26/50\n","2034/2034 [==============================] - 84s 41ms/step - loss: 0.8996 - acc: 0.5885 - val_loss: 1.0312 - val_acc: 0.5728\n","\n","Epoch 00026: val_acc did not improve from 0.60640\n","Epoch 27/50\n","2034/2034 [==============================] - 82s 41ms/step - loss: 0.8931 - acc: 0.5959 - val_loss: 1.0839 - val_acc: 0.5264\n","\n","Epoch 00027: val_acc did not improve from 0.60640\n","Epoch 28/50\n","2034/2034 [==============================] - 83s 41ms/step - loss: 0.8756 - acc: 0.6023 - val_loss: 1.0359 - val_acc: 0.5712\n","\n","Epoch 00028: val_acc did not improve from 0.60640\n","Epoch 29/50\n","2034/2034 [==============================] - 83s 41ms/step - loss: 0.8527 - acc: 0.6268 - val_loss: 1.0317 - val_acc: 0.5648\n","\n","Epoch 00029: val_acc did not improve from 0.60640\n","Epoch 30/50\n","2034/2034 [==============================] - 84s 41ms/step - loss: 0.8368 - acc: 0.6352 - val_loss: 1.0539 - val_acc: 0.5760\n","\n","Epoch 00030: val_acc did not improve from 0.60640\n","Epoch 31/50\n","2034/2034 [==============================] - 85s 42ms/step - loss: 0.9175 - acc: 0.5939 - val_loss: 1.0666 - val_acc: 0.5632\n","\n","Epoch 00031: val_acc did not improve from 0.60640\n","Epoch 32/50\n","2034/2034 [==============================] - 85s 42ms/step - loss: 0.8875 - acc: 0.6047 - val_loss: 1.0070 - val_acc: 0.6016\n","\n","Epoch 00032: val_acc did not improve from 0.60640\n","Epoch 33/50\n","2034/2034 [==============================] - 87s 43ms/step - loss: 0.9077 - acc: 0.5851 - val_loss: 1.0265 - val_acc: 0.6016\n","\n","Epoch 00033: val_acc did not improve from 0.60640\n","Epoch 34/50\n","2034/2034 [==============================] - 86s 42ms/step - loss: 0.9039 - acc: 0.5885 - val_loss: 1.0434 - val_acc: 0.5728\n","\n","Epoch 00034: val_acc did not improve from 0.60640\n","Epoch 35/50\n","2034/2034 [==============================] - 86s 42ms/step - loss: 0.9089 - acc: 0.5796 - val_loss: 1.0089 - val_acc: 0.5744\n","\n","Epoch 00035: val_acc did not improve from 0.60640\n","Epoch 36/50\n","2034/2034 [==============================] - 87s 43ms/step - loss: 0.8932 - acc: 0.6018 - val_loss: 1.0484 - val_acc: 0.5712\n","\n","Epoch 00036: val_acc did not improve from 0.60640\n","Epoch 37/50\n","2034/2034 [==============================] - 87s 43ms/step - loss: 0.8553 - acc: 0.6116 - val_loss: 1.1217 - val_acc: 0.5472\n","\n","Epoch 00037: val_acc did not improve from 0.60640\n","Epoch 38/50\n","2034/2034 [==============================] - 87s 43ms/step - loss: 0.8384 - acc: 0.6249 - val_loss: 1.0761 - val_acc: 0.5840\n","\n","Epoch 00038: val_acc did not improve from 0.60640\n","Epoch 39/50\n","2034/2034 [==============================] - 88s 43ms/step - loss: 0.8000 - acc: 0.6549 - val_loss: 1.0983 - val_acc: 0.5760\n","\n","Epoch 00039: val_acc did not improve from 0.60640\n","Epoch 40/50\n","2034/2034 [==============================] - 86s 42ms/step - loss: 0.7825 - acc: 0.6588 - val_loss: 1.0880 - val_acc: 0.5552\n","\n","Epoch 00040: val_acc did not improve from 0.60640\n","Epoch 41/50\n","2034/2034 [==============================] - 83s 41ms/step - loss: 0.7607 - acc: 0.6824 - val_loss: 1.1234 - val_acc: 0.5712\n","\n","Epoch 00041: val_acc did not improve from 0.60640\n","Epoch 42/50\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.7455 - acc: 0.6844 - val_loss: 1.0594 - val_acc: 0.6128\n","\n","Epoch 00042: val_acc improved from 0.60640 to 0.61280, saving model to ./lstm_spectrogram.h5\n","Epoch 43/50\n","2034/2034 [==============================] - 83s 41ms/step - loss: 0.7294 - acc: 0.6853 - val_loss: 1.0964 - val_acc: 0.5760\n","\n","Epoch 00043: val_acc did not improve from 0.61280\n","Epoch 44/50\n","2034/2034 [==============================] - 83s 41ms/step - loss: 0.7152 - acc: 0.7070 - val_loss: 1.1661 - val_acc: 0.5840\n","\n","Epoch 00044: val_acc did not improve from 0.61280\n","Epoch 45/50\n","2034/2034 [==============================] - 82s 40ms/step - loss: 0.6829 - acc: 0.7104 - val_loss: 1.2104 - val_acc: 0.5344\n","\n","Epoch 00045: val_acc did not improve from 0.61280\n","Epoch 46/50\n","2034/2034 [==============================] - 83s 41ms/step - loss: 0.6551 - acc: 0.7296 - val_loss: 1.2247 - val_acc: 0.5120\n","\n","Epoch 00046: val_acc did not improve from 0.61280\n","Epoch 47/50\n","2034/2034 [==============================] - 84s 41ms/step - loss: 0.7481 - acc: 0.6981 - val_loss: 1.1088 - val_acc: 0.5568\n","\n","Epoch 00047: val_acc did not improve from 0.61280\n","Epoch 48/50\n","2034/2034 [==============================] - 85s 42ms/step - loss: 0.6619 - acc: 0.7119 - val_loss: 1.1948 - val_acc: 0.5440\n","\n","Epoch 00048: val_acc did not improve from 0.61280\n","Epoch 49/50\n","2034/2034 [==============================] - 85s 42ms/step - loss: 0.5997 - acc: 0.7424 - val_loss: 1.2396 - val_acc: 0.5584\n","\n","Epoch 00049: val_acc did not improve from 0.61280\n","Epoch 50/50\n","2034/2034 [==============================] - 85s 42ms/step - loss: 0.6343 - acc: 0.7375 - val_loss: 1.2117 - val_acc: 0.5632\n","\n","Epoch 00050: val_acc did not improve from 0.61280\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0l8M7trNp7mS","colab_type":"code","colab":{}},"source":["best_model = load_model('./lstm_spectrogram.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cRLSOa_QpIfs","colab_type":"code","colab":{}},"source":["y_pred = best_model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1pyZYxbzpfLi","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report, accuracy_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XzzNg7b9ph6D","colab_type":"code","colab":{}},"source":["for i in range(len(y_pred)):\n","  for j in range(len(y_pred[i])) :\n","    if y_pred[i][j]==max(y_pred[i]) :\n","      y_pred[i][j] = 1\n","    else:\n","      y_pred[i][j]=0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fnRJygGKplWZ","colab_type":"code","outputId":"a465b9de-4ce6-46cb-a014-ee20f156d750","executionInfo":{"status":"ok","timestamp":1554990530742,"user_tz":-330,"elapsed":2597,"user":{"displayName":"Shah Fahad","photoUrl":"","userId":"07260500457103866977"}},"colab":{"base_uri":"https://localhost:8080/","height":225}},"source":["print(classification_report(y_test,y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.12      0.03      0.05        31\n","           1       0.65      0.41      0.50       174\n","           2       0.58      0.80      0.67       287\n","           3       0.73      0.62      0.67       133\n","\n","   micro avg       0.61      0.61      0.61       625\n","   macro avg       0.52      0.46      0.47       625\n","weighted avg       0.61      0.61      0.59       625\n"," samples avg       0.61      0.61      0.61       625\n","\n"],"name":"stdout"}]}]}